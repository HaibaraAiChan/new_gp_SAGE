main start at this time 1656028504.8862689
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 0.12115478515625
global_2_local spend time (sec) 0.34494686126708984
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.01959705352783203
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 922590, 20: 186421, 14: 695, 15: 673, 7: 655, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 19: 584, 12: 583, 9: 576, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.06264352798461914
auxiliary_graph
Graph(num_nodes=1119161, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.5367882251739502
remove nodes length  922590

auxiliary_graph.remove_nodes spent  2.146200180053711
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  1.4616692066192627

the counter of shared neighbor distribution
Counter({1.0: 31135406, 2.0: 3552592, 3.0: 936932, 4.0: 353502, 5.0: 159904, 6.0: 75186, 7.0: 40668, 8.0: 21746, 9.0: 14870, 10.0: 9568, 11.0: 6274, 12.0: 4756, 15.0: 4752, 14.0: 4072, 13.0: 3450, 18.0: 2810, 16.0: 2680, 17.0: 1584, 19.0: 1406, 20.0: 1276})
36333434
Convert a graph into a bidirected graph: 1.944 seconds
Metis partitioning: 8.279 seconds
Split the graph: 2.673 seconds
Construct subgraphs: 0.057 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  12.968164920806885
65995
66805
63771
total k batches seeds list generation spend  24.22049117088318
after graph partition
graph partition algorithm spend time 24.836108922958374
65995
66805
63771
partition_len_list
[382160, 438924, 432273]
REG selection method  spend 25.402066946029663
time for parepare:  0.23478150367736816
local_output_nid generation:  0.010249614715576172
local_in_edges_tensor generation:  0.015269994735717773
mini_batch_src_global generation:  0.040090084075927734
r_  generation:  0.5312013626098633
local_output_nid generation:  0.013111114501953125
local_in_edges_tensor generation:  0.023400306701660156
mini_batch_src_global generation:  0.05130267143249512
r_  generation:  0.629281759262085
local_output_nid generation:  0.01428079605102539
local_in_edges_tensor generation:  0.01432037353515625
mini_batch_src_global generation:  0.043402910232543945
r_  generation:  0.5874896049499512
----------------------check_connections_block total spend ----------------------------- 2.5573463439941406
generate_one_block  2.045370101928711
generate_one_block  0.7241659164428711
generate_one_block  0.6333250999450684
----------===============-------------===============-------------the number of batches *****---- 3

original number of batches:  3
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

connection checking time:  2.5573463439941406
block generation total time  3.4028611183166504
average batch blocks generation time:  1.1342870394388835
block dataloader generation time/epoch 31.72407579421997
pseudo mini batch 0 input nodes size: 382160
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.1600341796875 GB
    Memory Allocated: 0.1429157257080078  GigaBytes
Max Memory Allocated: 0.1429157257080078  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.1600341796875 GB
    Memory Allocated: 0.14340782165527344  GigaBytes
Max Memory Allocated: 0.14340782165527344  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.1600341796875 GB
    Memory Allocated: 0.14340782165527344  GigaBytes
Max Memory Allocated: 0.14340782165527344  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.15295982360839844  GigaBytes
Max Memory Allocated: 0.15295982360839844  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.15295982360839844  GigaBytes
Max Memory Allocated: 0.15295982360839844  GigaBytes

torch.Size([65995, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 7.46759557723999  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 7.479151725769043  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.1750788688659668  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

pseudo mini batch 1 input nodes size: 438924
----------------------------------------before load block subtensor 
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.15530157089233398  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.15530157089233398  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.3188138008117676  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.31931161880493164  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.17624139785766602  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.18608617782592773  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 9.7166748046875 GB
    Memory Allocated: 0.18608617782592773  GigaBytes
Max Memory Allocated: 8.38462209701538  GigaBytes

torch.Size([66805, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 7.692084789276123  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 7.703782081604004  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.1963214874267578  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

pseudo mini batch 2 input nodes size: 432273
----------------------------------------before load block subtensor 
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.17638301849365234  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.17638301849365234  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.3374176025390625  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.337893009185791  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.17388296127319336  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.18310308456420898  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.18310308456420898  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

torch.Size([63771, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 7.214758396148682  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 7.225924491882324  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.1920299530029297  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.1927051544189453  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 15.8670654296875 GB
    Memory Allocated: 0.1927051544189453  GigaBytes
Max Memory Allocated: 8.656867980957031  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.129132350285848 |0.10512312253316243 |0.22262199719746908 |0.00019025802612304688 |0.0909418265024821 |0.0038611888885498047 |
----------------------------------------------------------pseudo_mini_loss sum 4.791060924530029
Total (block generation + training)time/epoch 33.3899199962616
Training time/epoch 1.6655807495117188
Training time without block to device /epoch 1.3502113819122314
Training time without total dataloading part /epoch 0.9451234340667725
load block tensor time/epoch 0.38739705085754395
block to device time/epoch 0.3153693675994873
input features size transfer per epoch 4.023313522338867e-07
blocks size to device per epoch 2.682209014892578e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1253357
Number of first layer input nodes during this epoch:  1253357
Number of first layer output nodes during this epoch:  196571
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(100, 100, batch_first=True)
      (fc_self): Linear(in_features=100, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  90200
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([400, 100])
layers.0.lstm.weight_hh_l0, torch.Size([400, 100])
layers.0.lstm.bias_ih_l0, torch.Size([400])
layers.0.lstm.bias_hh_l0, torch.Size([400])
layers.0.fc_self.weight, torch.Size([47, 100])
layers.0.fc_neigh.weight, torch.Size([47, 100])
----------------------------------------
un-trainable parameters
