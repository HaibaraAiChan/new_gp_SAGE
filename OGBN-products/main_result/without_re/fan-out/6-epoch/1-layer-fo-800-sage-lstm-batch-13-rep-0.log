main start at this time 1656321230.164463
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 1.4007267951965332
global_2_local spend time (sec) 0.6275551319122314
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.32323360443115234
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1658093, 800: 3460, 77: 1190, 79: 1185, 81: 1185, 88: 1183, 84: 1177, 75: 1169, 78: 1169, 83: 1165, 85: 1164, 82: 1160, 67: 1158, 87: 1156, 91: 1154, 86: 1151, 76: 1145, 89: 1142, 92: 1119, 80: 1117, 90: 1108, 69: 1107, 93: 1088, 71: 1080, 73: 1080, 94: 1069, 74: 1069, 70: 1068, 68: 1053, 72: 1052, 99: 1042, 97: 1034, 96: 1020, 95: 1017, 102: 1006, 54: 996, 65: 994, 61: 981, 66: 977, 98: 963, 52: 959, 62: 959, 48: 958, 58: 957, 100: 957, 63: 955, 101: 954, 64: 953, 59: 950, 107: 949, 104: 947, 106: 945, 105: 942, 103: 939, 43: 933, 60: 930, 51: 928, 47: 927, 57: 923, 56: 913, 53: 907, 55: 907, 108: 898, 112: 887, 45: 884, 49: 879, 50: 877, 109: 867, 41: 861, 115: 857, 111: 853, 40: 852, 110: 850, 113: 848, 120: 844, 117: 838, 114: 835, 122: 825, 39: 816, 119: 816, 42: 813, 121: 810, 46: 807, 44: 806, 118: 798, 33: 793, 37: 791, 128: 782, 38: 775, 116: 775, 28: 768, 125: 756, 35: 754, 136: 752, 126: 747, 124: 744, 123: 741, 36: 741, 32: 727, 138: 722, 127: 722, 130: 716, 129: 711, 133: 706, 135: 704, 134: 703, 132: 702, 14: 695, 31: 691, 30: 689, 140: 689, 34: 677, 145: 673, 15: 673, 25: 671, 26: 659, 7: 655, 131: 654, 139: 654, 137: 654, 141: 652, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 150: 633, 143: 629, 11: 624, 144: 620, 142: 617, 13: 615, 16: 614, 148: 612, 147: 612, 146: 605, 18: 604, 149: 602, 22: 592, 155: 587, 21: 586, 19: 584, 12: 583, 154: 580, 152: 579, 151: 577, 157: 577, 9: 576, 153: 575, 20: 572, 17: 556, 6: 550, 159: 544, 156: 541, 158: 535, 164: 527, 160: 520, 8: 512, 165: 508, 169: 507, 161: 505, 172: 503, 163: 497, 166: 495, 170: 492, 168: 486, 162: 484, 171: 482, 167: 476, 177: 463, 4: 456, 179: 453, 180: 447, 175: 446, 5: 445, 182: 438, 173: 435, 181: 435, 185: 429, 176: 428, 184: 427, 174: 423, 178: 421, 199: 400, 187: 391, 188: 389, 186: 387, 193: 386, 190: 386, 192: 381, 189: 377, 191: 375, 3: 374, 183: 370, 195: 369, 208: 369, 196: 369, 194: 365, 198: 363, 204: 350, 203: 340, 209: 340, 197: 339, 200: 338, 207: 337, 202: 336, 206: 335, 201: 333, 213: 327, 214: 320, 211: 316, 224: 309, 231: 308, 216: 306, 215: 305, 219: 304, 205: 303, 218: 302, 210: 301, 221: 299, 228: 293, 217: 291, 212: 291, 225: 289, 222: 284, 220: 282, 223: 275, 233: 273, 226: 273, 230: 271, 227: 268, 239: 268, 238: 259, 244: 259, 249: 258, 234: 258, 237: 257, 229: 254, 240: 253, 235: 252, 246: 252, 232: 246, 236: 246, 247: 244, 241: 243, 245: 239, 242: 235, 257: 234, 243: 233, 250: 232, 255: 227, 2: 221, 248: 221, 252: 219, 264: 219, 254: 214, 259: 210, 267: 209, 268: 206, 251: 202, 253: 201, 258: 201, 266: 199, 260: 196, 269: 195, 273: 190, 265: 190, 270: 189, 263: 189, 278: 188, 277: 187, 262: 183, 276: 182, 261: 182, 282: 182, 256: 179, 274: 179, 285: 178, 272: 178, 271: 177, 280: 175, 299: 175, 284: 174, 1: 173, 290: 169, 291: 168, 303: 165, 295: 165, 287: 164, 279: 160, 288: 159, 315: 159, 286: 159, 298: 157, 294: 156, 300: 155, 292: 154, 283: 152, 297: 152, 302: 151, 301: 151, 289: 149, 305: 148, 275: 147, 293: 147, 306: 147, 281: 147, 312: 146, 307: 146, 311: 145, 316: 144, 313: 140, 310: 139, 296: 134, 304: 133, 309: 133, 318: 132, 320: 131, 314: 131, 308: 130, 319: 127, 332: 127, 342: 123, 326: 123, 328: 123, 323: 120, 321: 120, 322: 119, 333: 119, 317: 118, 344: 115, 351: 114, 327: 114, 340: 114, 331: 113, 324: 113, 336: 110, 325: 109, 355: 108, 349: 107, 365: 105, 341: 105, 329: 105, 353: 104, 345: 104, 330: 103, 338: 103, 339: 103, 359: 102, 357: 102, 334: 101, 381: 100, 378: 100, 362: 100, 371: 99, 383: 99, 337: 99, 348: 99, 380: 99, 356: 98, 360: 98, 350: 98, 370: 97, 354: 97, 363: 96, 343: 96, 372: 95, 385: 94, 335: 93, 347: 92, 376: 92, 352: 92, 374: 92, 375: 91, 368: 91, 361: 91, 373: 91, 366: 90, 346: 90, 393: 89, 369: 88, 364: 87, 384: 86, 377: 82, 390: 81, 386: 81, 416: 80, 395: 80, 398: 80, 387: 80, 392: 79, 407: 79, 397: 79, 389: 79, 358: 78, 419: 77, 382: 77, 421: 75, 418: 74, 402: 73, 367: 73, 400: 73, 429: 72, 401: 71, 417: 71, 408: 71, 379: 71, 450: 71, 394: 69, 406: 69, 431: 69, 453: 68, 388: 68, 391: 68, 405: 68, 427: 68, 410: 67, 409: 67, 404: 67, 411: 66, 399: 66, 467: 65, 440: 64, 433: 63, 412: 62, 413: 62, 446: 62, 447: 62, 396: 61, 434: 61, 426: 60, 451: 60, 425: 60, 475: 60, 424: 59, 432: 58, 430: 58, 415: 57, 464: 57, 454: 57, 420: 57, 460: 56, 428: 56, 441: 55, 423: 55, 484: 55, 462: 54, 514: 54, 435: 54, 461: 54, 444: 53, 445: 52, 481: 52, 468: 52, 403: 52, 459: 51, 448: 51, 443: 51, 439: 51, 422: 50, 476: 50, 437: 49, 507: 49, 436: 48, 498: 48, 472: 48, 438: 48, 442: 48, 465: 48, 478: 47, 473: 47, 458: 47, 480: 47, 489: 46, 456: 46, 494: 46, 469: 46, 455: 45, 479: 45, 477: 45, 491: 44, 519: 44, 487: 44, 500: 43, 510: 43, 414: 43, 457: 42, 471: 42, 534: 42, 470: 42, 483: 42, 518: 42, 516: 41, 564: 41, 463: 41, 526: 41, 553: 41, 540: 40, 511: 40, 536: 40, 486: 40, 517: 40, 521: 40, 499: 40, 495: 40, 520: 39, 449: 39, 541: 39, 502: 39, 466: 38, 482: 38, 505: 38, 503: 37, 538: 37, 513: 37, 535: 37, 524: 37, 598: 36, 603: 36, 555: 36, 550: 36, 474: 36, 452: 36, 532: 36, 497: 36, 506: 36, 490: 35, 530: 35, 504: 35, 527: 35, 554: 35, 563: 35, 512: 34, 488: 34, 493: 34, 515: 34, 531: 34, 492: 34, 595: 34, 556: 34, 537: 34, 565: 34, 551: 34, 559: 33, 528: 33, 496: 33, 533: 33, 548: 33, 542: 32, 523: 32, 545: 32, 612: 32, 557: 32, 501: 32, 546: 31, 525: 31, 485: 31, 588: 31, 624: 30, 529: 30, 606: 30, 577: 30, 566: 29, 575: 29, 604: 29, 586: 29, 579: 29, 509: 29, 585: 29, 600: 29, 508: 29, 617: 29, 543: 29, 539: 28, 636: 28, 522: 28, 552: 28, 569: 28, 602: 27, 642: 27, 558: 27, 580: 27, 601: 27, 570: 27, 589: 26, 596: 26, 561: 26, 547: 26, 549: 25, 576: 25, 613: 25, 560: 25, 584: 25, 582: 25, 571: 25, 726: 25, 592: 25, 616: 24, 678: 24, 626: 24, 625: 24, 581: 24, 568: 24, 544: 24, 666: 24, 620: 24, 597: 24, 619: 23, 574: 23, 628: 23, 573: 23, 594: 23, 631: 23, 638: 23, 634: 23, 629: 23, 562: 23, 665: 23, 614: 23, 658: 22, 737: 22, 609: 22, 654: 22, 702: 22, 578: 22, 641: 22, 679: 21, 650: 21, 623: 21, 667: 21, 669: 21, 591: 21, 643: 21, 607: 21, 615: 21, 653: 20, 647: 20, 583: 20, 772: 20, 711: 20, 686: 20, 676: 20, 645: 20, 567: 20, 587: 20, 646: 20, 608: 20, 627: 20, 648: 19, 724: 19, 731: 19, 590: 19, 655: 19, 611: 19, 651: 19, 688: 19, 649: 19, 572: 19, 618: 19, 751: 19, 610: 19, 719: 19, 671: 19, 663: 18, 661: 18, 630: 18, 695: 18, 681: 18, 599: 18, 687: 18, 635: 18, 769: 18, 740: 18, 644: 18, 639: 18, 664: 18, 673: 18, 698: 17, 710: 17, 763: 17, 720: 17, 680: 17, 621: 17, 709: 17, 708: 17, 700: 17, 715: 17, 730: 16, 712: 16, 745: 16, 674: 16, 714: 16, 660: 16, 652: 16, 727: 16, 697: 16, 738: 16, 716: 16, 784: 16, 593: 16, 682: 16, 670: 16, 633: 15, 699: 15, 785: 15, 668: 15, 683: 15, 692: 15, 739: 15, 605: 15, 672: 15, 734: 15, 755: 15, 684: 15, 757: 15, 729: 14, 675: 14, 728: 14, 662: 14, 632: 14, 732: 14, 722: 14, 792: 14, 689: 14, 659: 14, 637: 14, 705: 14, 797: 13, 622: 13, 788: 13, 760: 13, 768: 13, 766: 13, 775: 13, 780: 13, 640: 13, 717: 13, 756: 13, 685: 13, 677: 13, 735: 13, 721: 13, 725: 13, 754: 13, 691: 12, 791: 12, 693: 12, 749: 12, 690: 12, 713: 12, 657: 12, 656: 12, 733: 12, 765: 11, 742: 11, 758: 11, 798: 11, 741: 11, 759: 11, 776: 11, 762: 11, 782: 11, 752: 11, 701: 11, 703: 11, 750: 11, 706: 11, 799: 10, 779: 10, 767: 10, 736: 10, 790: 10, 694: 10, 743: 10, 723: 10, 773: 10, 777: 10, 744: 9, 770: 9, 771: 9, 696: 9, 718: 9, 774: 9, 783: 9, 781: 9, 704: 9, 778: 9, 786: 8, 764: 8, 707: 8, 794: 8, 796: 7, 789: 6, 747: 6, 793: 6, 795: 6, 746: 6, 753: 6, 787: 6, 761: 5, 748: 3})

A = g.adjacency_matrix() spent  0.4687643051147461
auxiliary_graph
Graph(num_nodes=1854664, num_edges=446565047,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.8109226226806641
remove nodes length  1658093

auxiliary_graph.remove_nodes spent  29.723642110824585
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=446565047,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  20.671610355377197

the counter of shared neighbor distribution
Counter({1.0: 248624276, 2.0: 67821410, 3.0: 33423694, 4.0: 20171784, 5.0: 13559670, 6.0: 9760722, 7.0: 7329294, 8.0: 5711702, 9.0: 4559684, 10.0: 3722076, 11.0: 3087022, 12.0: 2603834, 13.0: 2227414, 14.0: 1914054, 15.0: 1664634, 16.0: 1459746, 17.0: 1289206, 18.0: 1145816, 19.0: 1024652, 20.0: 919498, 21.0: 827080, 22.0: 746548, 23.0: 682674, 24.0: 621376, 25.0: 572070, 26.0: 524170, 27.0: 485232, 28.0: 449800, 29.0: 415686, 30.0: 388242, 31.0: 360986, 32.0: 339378, 33.0: 318112, 34.0: 297990, 35.0: 279232, 36.0: 264160, 37.0: 249464, 38.0: 236960, 39.0: 225780, 40.0: 212186, 41.0: 201436, 42.0: 193192, 43.0: 184212, 44.0: 175242, 45.0: 166588, 46.0: 158926, 47.0: 150880, 48.0: 145980, 49.0: 142374, 50.0: 134226, 51.0: 130482, 52.0: 123996, 53.0: 118308, 54.0: 112992, 55.0: 107826, 56.0: 103844, 57.0: 99810, 58.0: 96750, 59.0: 92122, 60.0: 88948, 61.0: 85370, 62.0: 82400, 63.0: 80182, 64.0: 75902, 65.0: 73800, 67.0: 72550, 66.0: 71436, 68.0: 66854, 69.0: 64496, 70.0: 62378, 71.0: 60244, 72.0: 58462, 73.0: 56450, 74.0: 54418, 75.0: 53352, 76.0: 51390, 77.0: 50302, 78.0: 47142, 79.0: 45670, 80.0: 44464, 81.0: 44026, 82.0: 42168, 83.0: 41008, 85.0: 39894, 84.0: 39892, 86.0: 37694, 87.0: 36228, 88.0: 35468, 89.0: 33938, 90.0: 33292, 91.0: 32400, 92.0: 31680, 93.0: 30492, 94.0: 29854, 95.0: 28824, 96.0: 28142, 97.0: 27684, 98.0: 26782, 99.0: 26202, 100.0: 25412, 101.0: 24870, 102.0: 24164, 103.0: 23724, 104.0: 22830, 105.0: 22184, 106.0: 22066, 107.0: 21274, 108.0: 20406, 109.0: 19934, 110.0: 19750, 111.0: 19198, 112.0: 18446, 113.0: 18386, 114.0: 17786, 115.0: 17178, 116.0: 16856, 117.0: 16562, 118.0: 16512, 120.0: 16306, 119.0: 16002, 121.0: 14974, 122.0: 14840, 123.0: 14252, 124.0: 13866, 126.0: 13726, 125.0: 13578, 127.0: 13294, 128.0: 12730, 129.0: 12422, 130.0: 11964, 131.0: 11940, 132.0: 11882, 133.0: 11672, 135.0: 11490, 134.0: 11472, 136.0: 10724, 137.0: 10624, 141.0: 10142, 138.0: 10130, 139.0: 9974, 140.0: 9756, 142.0: 9492, 143.0: 9322, 145.0: 9196, 144.0: 8992, 146.0: 8762, 147.0: 8580, 148.0: 8502, 149.0: 8394, 150.0: 8124, 152.0: 7992, 151.0: 7730, 153.0: 7578, 154.0: 7440, 156.0: 7300, 155.0: 7254, 157.0: 7062, 159.0: 6866, 158.0: 6846, 161.0: 6692, 160.0: 6518, 162.0: 6506, 163.0: 6354, 164.0: 6080, 165.0: 6050, 168.0: 5954, 166.0: 5954, 167.0: 5802, 169.0: 5678, 171.0: 5498, 170.0: 5410, 172.0: 5222, 174.0: 5156, 173.0: 5136, 175.0: 5006, 176.0: 4872, 179.0: 4788, 178.0: 4784, 177.0: 4766, 180.0: 4554, 182.0: 4498, 183.0: 4460, 184.0: 4404, 181.0: 4388, 186.0: 4268, 185.0: 4124, 187.0: 4064, 188.0: 3934, 191.0: 3880, 190.0: 3860, 189.0: 3784, 192.0: 3682, 194.0: 3662, 193.0: 3554, 195.0: 3502, 196.0: 3456, 197.0: 3436, 199.0: 3306, 200.0: 3238, 198.0: 3190, 201.0: 3120, 202.0: 3068, 203.0: 3004, 204.0: 2982, 205.0: 2978, 209.0: 2886, 208.0: 2878, 206.0: 2852, 207.0: 2836, 211.0: 2824, 210.0: 2784, 213.0: 2640, 212.0: 2606, 217.0: 2530, 214.0: 2520, 215.0: 2446, 218.0: 2384, 216.0: 2366, 219.0: 2328, 220.0: 2320, 224.0: 2272, 221.0: 2254, 222.0: 2236, 228.0: 2208, 223.0: 2208, 225.0: 2170, 226.0: 2048, 227.0: 1976, 229.0: 1972, 230.0: 1946, 231.0: 1938, 233.0: 1922, 237.0: 1908, 235.0: 1890, 232.0: 1858, 234.0: 1856, 236.0: 1786, 238.0: 1780, 239.0: 1758, 242.0: 1672, 243.0: 1648, 240.0: 1624, 244.0: 1610, 241.0: 1608, 247.0: 1562, 248.0: 1500, 249.0: 1488, 251.0: 1482, 246.0: 1478, 253.0: 1472, 250.0: 1472, 245.0: 1454, 252.0: 1402, 259.0: 1370, 255.0: 1338, 256.0: 1322, 257.0: 1286, 260.0: 1268, 258.0: 1250, 254.0: 1244, 262.0: 1220, 261.0: 1212, 266.0: 1172, 264.0: 1170, 265.0: 1138, 263.0: 1112, 267.0: 1108, 268.0: 1106, 269.0: 1080, 272.0: 1064, 270.0: 1062, 271.0: 1058, 276.0: 1004, 275.0: 1000, 281.0: 990, 277.0: 960, 274.0: 958, 273.0: 944, 278.0: 942, 279.0: 906, 282.0: 898, 283.0: 898, 280.0: 884, 284.0: 860, 286.0: 834, 288.0: 820, 289.0: 800, 287.0: 788, 295.0: 786, 285.0: 778, 293.0: 760, 291.0: 750, 296.0: 746, 299.0: 740, 294.0: 738, 290.0: 728, 292.0: 712, 297.0: 708, 307.0: 674, 300.0: 668, 305.0: 658, 303.0: 658, 298.0: 646, 308.0: 634, 311.0: 632, 301.0: 628, 304.0: 622, 306.0: 616, 302.0: 604, 310.0: 578, 317.0: 570, 316.0: 568, 309.0: 566, 315.0: 562, 313.0: 554, 314.0: 552, 312.0: 542, 319.0: 530, 320.0: 524, 318.0: 518, 329.0: 512, 321.0: 504, 327.0: 500, 325.0: 486, 323.0: 484, 326.0: 484, 330.0: 484, 331.0: 454, 332.0: 452, 334.0: 442, 322.0: 432, 324.0: 428, 335.0: 426, 340.0: 412, 333.0: 412, 337.0: 400, 328.0: 400, 348.0: 394, 336.0: 394, 344.0: 390, 343.0: 388, 346.0: 374, 347.0: 372, 338.0: 366, 339.0: 356, 352.0: 352, 351.0: 352, 342.0: 348, 355.0: 348, 353.0: 346, 345.0: 344, 349.0: 338, 358.0: 336, 354.0: 324, 363.0: 316, 357.0: 316, 341.0: 312, 356.0: 312, 359.0: 308, 367.0: 308, 350.0: 304, 366.0: 298, 361.0: 298, 360.0: 290, 362.0: 286, 364.0: 280, 369.0: 274, 371.0: 272, 365.0: 270, 368.0: 268, 372.0: 262, 375.0: 256, 380.0: 254, 379.0: 246, 384.0: 242, 383.0: 240, 374.0: 236, 370.0: 234, 386.0: 234, 378.0: 232, 373.0: 228, 381.0: 222, 391.0: 212, 377.0: 212, 376.0: 212, 387.0: 206, 389.0: 204, 393.0: 202, 394.0: 198, 385.0: 196, 390.0: 196, 392.0: 188, 404.0: 188, 388.0: 180, 395.0: 176, 400.0: 174, 397.0: 168, 382.0: 162, 399.0: 160, 396.0: 160, 407.0: 160, 411.0: 160, 406.0: 154, 420.0: 152, 409.0: 150, 403.0: 150, 398.0: 150, 408.0: 146, 401.0: 140, 402.0: 140, 413.0: 138, 416.0: 138, 433.0: 138, 425.0: 134, 415.0: 134, 417.0: 134, 405.0: 132, 418.0: 130, 410.0: 128, 412.0: 124, 422.0: 116, 426.0: 116, 414.0: 116, 424.0: 114, 439.0: 114, 434.0: 112, 419.0: 108, 428.0: 106, 437.0: 106, 430.0: 104, 435.0: 102, 451.0: 100, 432.0: 98, 445.0: 98, 429.0: 96, 423.0: 96, 444.0: 96, 441.0: 92, 448.0: 90, 421.0: 90, 462.0: 90, 443.0: 90, 431.0: 88, 442.0: 88, 440.0: 88, 463.0: 86, 453.0: 86, 427.0: 84, 457.0: 84, 454.0: 84, 449.0: 82, 436.0: 80, 446.0: 80, 460.0: 80, 447.0: 78, 456.0: 76, 473.0: 74, 477.0: 74, 452.0: 72, 470.0: 68, 461.0: 68, 450.0: 66, 467.0: 66, 458.0: 66, 459.0: 66, 455.0: 62, 482.0: 62, 478.0: 60, 474.0: 58, 469.0: 58, 475.0: 58, 438.0: 58, 464.0: 56, 499.0: 54, 468.0: 54, 476.0: 54, 466.0: 52, 491.0: 52, 465.0: 50, 472.0: 48, 484.0: 46, 498.0: 46, 483.0: 46, 485.0: 46, 489.0: 44, 471.0: 44, 486.0: 44, 479.0: 44, 488.0: 44, 492.0: 44, 480.0: 40, 510.0: 38, 500.0: 38, 509.0: 38, 490.0: 36, 495.0: 36, 502.0: 36, 497.0: 34, 481.0: 34, 487.0: 34, 496.0: 32, 505.0: 30, 507.0: 28, 520.0: 28, 504.0: 28, 528.0: 28, 494.0: 26, 519.0: 26, 527.0: 26, 503.0: 26, 512.0: 24, 518.0: 22, 508.0: 22, 525.0: 22, 515.0: 22, 501.0: 22, 514.0: 22, 529.0: 20, 524.0: 20, 493.0: 20, 516.0: 20, 538.0: 18, 513.0: 18, 523.0: 18, 531.0: 18, 537.0: 18, 506.0: 18, 522.0: 16, 543.0: 16, 556.0: 16, 521.0: 16, 547.0: 16, 517.0: 14, 535.0: 14, 553.0: 12, 560.0: 12, 548.0: 12, 555.0: 12, 550.0: 10, 552.0: 10, 532.0: 10, 549.0: 10, 511.0: 10, 536.0: 10, 533.0: 10, 581.0: 10, 530.0: 10, 572.0: 8, 580.0: 8, 574.0: 8, 563.0: 8, 545.0: 8, 546.0: 8, 566.0: 8, 567.0: 8, 558.0: 8, 586.0: 8, 534.0: 8, 564.0: 8, 587.0: 6, 526.0: 6, 565.0: 6, 541.0: 6, 561.0: 6, 542.0: 6, 591.0: 6, 544.0: 6, 540.0: 6, 557.0: 6, 562.0: 4, 589.0: 4, 616.0: 4, 604.0: 4, 583.0: 4, 610.0: 4, 615.0: 4, 539.0: 4, 559.0: 4, 577.0: 4, 571.0: 4, 576.0: 4, 602.0: 4, 596.0: 4, 653.0: 2, 631.0: 2, 633.0: 2, 603.0: 2, 579.0: 2, 636.0: 2, 668.0: 2, 597.0: 2, 592.0: 2, 588.0: 2, 575.0: 2, 613.0: 2, 630.0: 2, 609.0: 2, 585.0: 2, 605.0: 2, 578.0: 2, 614.0: 2, 700.0: 2, 601.0: 2, 582.0: 2, 595.0: 2, 649.0: 2, 643.0: 2, 608.0: 2, 551.0: 2})
446368476
Convert a graph into a bidirected graph: 38.268 seconds
Metis partitioning: 119.722 seconds
Split the graph: 12.399 seconds
Construct subgraphs: 0.034 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  170.59831595420837
14679
14679
15248
15528
15143
15476
14988
15476
15537
14871
15356
14679
14911
total k batches seeds list generation spend  334.87420105934143
after graph partition
graph partition algorithm spend time 338.82732462882996
14679
14679
15248
15528
15143
15476
14988
15476
15537
14871
15356
14679
14911
partition_len_list
[325608, 353310, 163084, 234024, 230465, 242721, 330768, 296557, 261915, 332178, 295874, 363433, 405366]
REG selection method  spend 339.8119740486145
time for parepare:  0.4223628044128418
local_output_nid generation:  0.005029201507568359
local_in_edges_tensor generation:  0.0676887035369873
mini_batch_src_global generation:  0.10395503044128418
r_  generation:  0.9371542930603027
local_output_nid generation:  0.0057642459869384766
local_in_edges_tensor generation:  0.07294034957885742
mini_batch_src_global generation:  0.09560894966125488
r_  generation:  0.7361185550689697
local_output_nid generation:  0.0052416324615478516
local_in_edges_tensor generation:  0.06885528564453125
mini_batch_src_global generation:  0.08211636543273926
r_  generation:  0.6186003684997559
local_output_nid generation:  0.005351066589355469
local_in_edges_tensor generation:  0.04088163375854492
mini_batch_src_global generation:  0.09073543548583984
r_  generation:  0.7159698009490967
local_output_nid generation:  0.006371021270751953
local_in_edges_tensor generation:  0.049739837646484375
mini_batch_src_global generation:  0.09264779090881348
r_  generation:  0.6483621597290039
local_output_nid generation:  0.007381916046142578
local_in_edges_tensor generation:  0.044645071029663086
mini_batch_src_global generation:  0.08122658729553223
r_  generation:  0.6518409252166748
local_output_nid generation:  0.0050466060638427734
local_in_edges_tensor generation:  0.05218386650085449
mini_batch_src_global generation:  0.07866239547729492
r_  generation:  0.6540946960449219
local_output_nid generation:  0.005719423294067383
local_in_edges_tensor generation:  0.04923677444458008
mini_batch_src_global generation:  0.08797979354858398
r_  generation:  0.6739482879638672
local_output_nid generation:  0.005093812942504883
local_in_edges_tensor generation:  0.059543609619140625
mini_batch_src_global generation:  0.10875654220581055
r_  generation:  0.8900067806243896
local_output_nid generation:  0.0049707889556884766
local_in_edges_tensor generation:  0.0566866397857666
mini_batch_src_global generation:  0.11903738975524902
r_  generation:  0.9912796020507812
local_output_nid generation:  0.005150556564331055
local_in_edges_tensor generation:  0.03791999816894531
mini_batch_src_global generation:  0.11118197441101074
r_  generation:  0.8840153217315674
local_output_nid generation:  0.005005359649658203
local_in_edges_tensor generation:  0.034967899322509766
mini_batch_src_global generation:  0.10813117027282715
r_  generation:  0.9200229644775391
local_output_nid generation:  0.005028486251831055
local_in_edges_tensor generation:  0.030385255813598633
mini_batch_src_global generation:  0.1046748161315918
r_  generation:  0.9027016162872314
----------------------check_connections_block total spend ----------------------------- 14.510558128356934
generate_one_block  2.9913761615753174
generate_one_block  1.0925722122192383
generate_one_block  0.9840517044067383
generate_one_block  1.0371344089508057
generate_one_block  0.9408955574035645
generate_one_block  0.9027962684631348
generate_one_block  0.93672776222229
generate_one_block  0.9135115146636963
generate_one_block  1.2456021308898926
generate_one_block  1.3887066841125488
generate_one_block  1.2130272388458252
generate_one_block  1.2155730724334717
generate_one_block  1.2168805599212646
----------===============-------------===============-------------the number of batches *****---- 13

original number of batches:  13
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

connection checking time:  14.510558128356934
block generation total time  16.078855276107788
average batch blocks generation time:  1.2368350212390606
block dataloader generation time/epoch 373.56688380241394
pseudo mini batch 0 input nodes size: 325608
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.1405029296875 GB
    Memory Allocated: 0.12163639068603516  GigaBytes
Max Memory Allocated: 0.12163639068603516  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.1405029296875 GB
    Memory Allocated: 0.12174606323242188  GigaBytes
Max Memory Allocated: 0.12174606323242188  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.1405029296875 GB
    Memory Allocated: 0.12174606323242188  GigaBytes
Max Memory Allocated: 0.12174606323242188  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2283935546875 GB
    Memory Allocated: 0.14518356323242188  GigaBytes
Max Memory Allocated: 0.14518356323242188  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2283935546875 GB
    Memory Allocated: 0.14518356323242188  GigaBytes
Max Memory Allocated: 0.14518356323242188  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 18.1083345413208  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 18.111233711242676  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1715846061706543  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 1 input nodes size: 353310
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12465476989746094  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12465476989746094  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.2562732696533203  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.25638294219970703  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.13497447967529297  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1522073745727539  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1522073745727539  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 13.481636047363281  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 13.484206676483154  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1694951057434082  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 2 input nodes size: 163084
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.13497447967529297  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.13497447967529297  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.19572830200195312  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.19584226608276367  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.06411409378051758  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.08048391342163086  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.08048391342163086  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15248, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 12.739001274108887  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 12.741671562194824  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09701061248779297  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 3 input nodes size: 234024
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.06421375274658203  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.06421375274658203  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.15139484405517578  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.15151071548461914  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09064292907714844  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10730552673339844  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10730552673339844  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15528, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 12.996021747589111  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 12.998741149902344  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12407541275024414  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 4 input nodes size: 230465
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09069204330444336  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09069204330444336  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.17654705047607422  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.17666006088256836  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.08936309814453125  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10470294952392578  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10470294952392578  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15143, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 11.973420143127441  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 11.976139545440674  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12003231048583984  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 5 input nodes size: 242721
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.08929586410522461  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.08929586410522461  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1797165870666504  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.17983198165893555  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09386396408081055  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10900354385375977  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10900354385375977  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15476, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 11.828133583068848  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 11.830843925476074  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12425899505615234  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 6 input nodes size: 330768
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09392213821411133  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.09392213821411133  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.21714305877685547  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.2172551155090332  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12671899795532227  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.14130926132202148  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.14130926132202148  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([14988, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 11.46650218963623  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 11.469212532043457  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.15602588653564453  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 7 input nodes size: 296557
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12678909301757812  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12678909301757812  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.23726558685302734  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.2373809814453125  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.11404800415039062  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1295318603515625  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1295318603515625  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15476, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 12.149595260620117  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 12.1523756980896  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1450033187866211  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 8 input nodes size: 261915
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.11397790908813477  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.11397790908813477  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.2115492820739746  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.21166515350341797  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.1010732650756836  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12276363372802734  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12276363372802734  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15537, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 16.487717628479004  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 16.49117422103882  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.14410114288330078  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 9 input nodes size: 332178
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10108375549316406  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.10108375549316406  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.22483015060424805  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.22494125366210938  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.12725400924682617  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.15069150924682617  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.5838623046875 GB
    Memory Allocated: 0.15069150924682617  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([14871, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 17.81407117843628  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 17.816792011260986  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.17406845092773438  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 10 input nodes size: 295874
----------------------------------------before load block subtensor 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1271376609802246  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1271376609802246  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.23735952377319336  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.2374739646911621  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1136164665222168  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.13429498672485352  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.13429498672485352  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15356, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 16.042311191558838  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 16.045000553131104  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15549755096435547  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 11 input nodes size: 363433
----------------------------------------before load block subtensor 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.11408329010009766  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.11408329010009766  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.24947309494018555  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.24958276748657227  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.13924646377563477  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15973615646362305  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15973615646362305  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 15.942577838897705  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 15.945649147033691  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1797800064086914  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

pseudo mini batch 12 input nodes size: 405366
----------------------------------------before load block subtensor 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.13874578475952148  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.13874578475952148  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.28975677490234375  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.2898678779602051  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15436840057373047  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.17317962646484375  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.17317962646484375  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([14911, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 14.680983066558838  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 14.684147834777832  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.19208765029907227  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1927628517150879  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1927628517150879  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.14744435823880708 |0.06477952003479004 |17.872396230697632 |0.00020533341627854569 |35.932772838152374 |0.06218695640563965 |
----------------------------------------------------------pseudo_mini_loss sum 4.79348087310791
Total (block generation + training)time/epoch 1077.0961246490479
Training time/epoch 703.5288202762604
Training time without block to device /epoch 702.6866865158081
Training time without total dataloading part /epoch 699.5320541858673
load block tensor time/epoch 1.9167766571044922
block to device time/epoch 0.8421337604522705
input features size transfer per epoch 1.7434358596801758e-06
blocks size to device per epoch 1.1622905731201172e-06
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  3835303
Number of first layer input nodes during this epoch:  3835303
Number of first layer output nodes during this epoch:  196571
----------------------------------------before generate dataloader block 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1927623748779297  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 1.4724674224853516
global_2_local spend time (sec) 0.7230010032653809
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.3257303237915039
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1658151, 800: 3460, 77: 1190, 79: 1185, 81: 1185, 88: 1183, 84: 1177, 75: 1169, 78: 1169, 83: 1165, 85: 1164, 82: 1160, 67: 1158, 87: 1156, 91: 1154, 86: 1151, 76: 1145, 89: 1142, 92: 1119, 80: 1117, 90: 1108, 69: 1107, 93: 1088, 73: 1080, 71: 1080, 94: 1069, 74: 1069, 70: 1068, 68: 1053, 72: 1052, 99: 1042, 97: 1034, 96: 1020, 95: 1017, 102: 1006, 54: 996, 65: 994, 61: 981, 66: 977, 98: 963, 62: 959, 52: 959, 48: 958, 58: 957, 100: 957, 63: 955, 101: 954, 64: 953, 59: 950, 107: 949, 104: 947, 106: 945, 105: 942, 103: 939, 43: 933, 60: 930, 51: 928, 47: 927, 57: 923, 56: 913, 53: 907, 55: 907, 108: 898, 112: 887, 45: 884, 49: 879, 50: 877, 109: 867, 41: 861, 115: 857, 111: 853, 40: 852, 110: 850, 113: 848, 120: 844, 117: 838, 114: 835, 122: 825, 39: 816, 119: 816, 42: 813, 121: 810, 46: 807, 44: 806, 118: 798, 33: 793, 37: 791, 128: 782, 116: 775, 38: 775, 28: 768, 125: 756, 35: 754, 136: 752, 126: 747, 124: 744, 36: 741, 123: 741, 32: 727, 127: 722, 138: 722, 130: 716, 129: 711, 133: 706, 135: 704, 134: 703, 132: 702, 14: 695, 31: 691, 30: 689, 140: 689, 34: 677, 15: 673, 145: 673, 25: 671, 26: 659, 7: 655, 131: 654, 139: 654, 137: 654, 141: 652, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 150: 633, 143: 629, 11: 624, 144: 620, 142: 617, 13: 615, 16: 614, 148: 612, 147: 612, 146: 605, 18: 604, 149: 602, 22: 592, 155: 587, 21: 586, 19: 584, 12: 583, 154: 580, 152: 579, 151: 577, 157: 577, 9: 576, 153: 575, 20: 572, 17: 556, 6: 550, 159: 544, 156: 541, 158: 535, 164: 527, 160: 520, 8: 512, 165: 508, 169: 507, 161: 505, 172: 503, 163: 497, 166: 495, 170: 492, 168: 486, 162: 484, 171: 482, 167: 476, 177: 463, 4: 456, 179: 453, 180: 447, 175: 446, 5: 445, 182: 438, 173: 435, 181: 435, 185: 429, 176: 428, 184: 427, 174: 423, 178: 421, 199: 400, 187: 391, 188: 389, 186: 387, 193: 386, 190: 386, 192: 381, 189: 377, 191: 375, 3: 374, 183: 370, 208: 369, 195: 369, 196: 369, 194: 365, 198: 363, 204: 350, 209: 340, 203: 340, 197: 339, 200: 338, 207: 337, 202: 336, 206: 335, 201: 333, 213: 327, 214: 320, 211: 316, 224: 309, 231: 308, 216: 306, 215: 305, 219: 304, 205: 303, 218: 302, 210: 301, 221: 299, 228: 293, 217: 291, 212: 291, 225: 289, 222: 284, 220: 282, 223: 275, 233: 273, 226: 273, 230: 271, 239: 268, 227: 268, 238: 259, 244: 259, 234: 258, 249: 258, 237: 257, 229: 254, 240: 253, 246: 252, 235: 252, 236: 246, 232: 246, 247: 244, 241: 243, 245: 239, 242: 235, 257: 234, 243: 233, 250: 232, 255: 227, 248: 221, 2: 221, 252: 219, 264: 219, 254: 214, 259: 210, 267: 209, 268: 206, 251: 202, 253: 201, 258: 201, 266: 199, 260: 196, 269: 195, 273: 190, 265: 190, 263: 189, 270: 189, 278: 188, 277: 187, 262: 183, 261: 182, 276: 182, 282: 182, 274: 179, 256: 179, 272: 178, 285: 178, 271: 177, 299: 175, 280: 175, 284: 174, 1: 173, 290: 169, 291: 168, 295: 165, 303: 165, 287: 164, 279: 160, 315: 159, 286: 159, 288: 159, 298: 157, 294: 156, 300: 155, 292: 154, 283: 152, 297: 152, 301: 151, 302: 151, 289: 149, 305: 148, 275: 147, 293: 147, 281: 147, 306: 147, 312: 146, 307: 146, 311: 145, 316: 144, 313: 140, 310: 139, 296: 134, 309: 133, 304: 133, 318: 132, 314: 131, 320: 131, 308: 130, 332: 127, 319: 127, 342: 123, 326: 123, 328: 123, 321: 120, 323: 120, 322: 119, 333: 119, 317: 118, 344: 115, 327: 114, 351: 114, 340: 114, 324: 113, 331: 113, 336: 110, 325: 109, 355: 108, 349: 107, 341: 105, 329: 105, 365: 105, 345: 104, 353: 104, 330: 103, 339: 103, 338: 103, 357: 102, 359: 102, 334: 101, 362: 100, 381: 100, 378: 100, 371: 99, 337: 99, 383: 99, 348: 99, 380: 99, 360: 98, 356: 98, 350: 98, 354: 97, 370: 97, 363: 96, 343: 96, 372: 95, 385: 94, 335: 93, 374: 92, 376: 92, 352: 92, 347: 92, 373: 91, 375: 91, 361: 91, 368: 91, 366: 90, 346: 90, 393: 89, 369: 88, 364: 87, 384: 86, 377: 82, 386: 81, 390: 81, 395: 80, 387: 80, 416: 80, 398: 80, 389: 79, 392: 79, 397: 79, 407: 79, 358: 78, 419: 77, 382: 77, 421: 75, 418: 74, 367: 73, 400: 73, 402: 73, 429: 72, 379: 71, 450: 71, 417: 71, 401: 71, 408: 71, 394: 69, 406: 69, 431: 69, 427: 68, 453: 68, 405: 68, 388: 68, 391: 68, 409: 67, 410: 67, 404: 67, 399: 66, 411: 66, 467: 65, 440: 64, 433: 63, 446: 62, 413: 62, 412: 62, 447: 62, 396: 61, 434: 61, 451: 60, 475: 60, 425: 60, 426: 60, 424: 59, 430: 58, 432: 58, 454: 57, 415: 57, 420: 57, 464: 57, 460: 56, 428: 56, 441: 55, 423: 55, 484: 55, 435: 54, 462: 54, 461: 54, 514: 54, 444: 53, 468: 52, 403: 52, 445: 52, 481: 52, 459: 51, 443: 51, 448: 51, 439: 51, 422: 50, 476: 50, 437: 49, 507: 49, 472: 48, 442: 48, 465: 48, 438: 48, 436: 48, 498: 48, 480: 47, 473: 47, 458: 47, 478: 47, 489: 46, 456: 46, 494: 46, 469: 46, 477: 45, 479: 45, 455: 45, 519: 44, 491: 44, 487: 44, 500: 43, 510: 43, 414: 43, 534: 42, 483: 42, 471: 42, 470: 42, 457: 42, 518: 42, 564: 41, 516: 41, 463: 41, 553: 41, 526: 41, 536: 40, 540: 40, 486: 40, 521: 40, 495: 40, 511: 40, 517: 40, 499: 40, 502: 39, 541: 39, 520: 39, 449: 39, 482: 38, 466: 38, 505: 38, 538: 37, 503: 37, 524: 37, 535: 37, 513: 37, 474: 36, 452: 36, 550: 36, 506: 36, 603: 36, 497: 36, 598: 36, 555: 36, 532: 36, 504: 35, 527: 35, 554: 35, 530: 35, 490: 35, 563: 35, 531: 34, 492: 34, 515: 34, 493: 34, 551: 34, 512: 34, 488: 34, 537: 34, 556: 34, 595: 34, 565: 34, 496: 33, 548: 33, 533: 33, 528: 33, 559: 33, 542: 32, 501: 32, 523: 32, 545: 32, 557: 32, 612: 32, 588: 31, 525: 31, 485: 31, 546: 31, 606: 30, 624: 30, 577: 30, 529: 30, 508: 29, 575: 29, 509: 29, 543: 29, 566: 29, 617: 29, 586: 29, 600: 29, 604: 29, 585: 29, 579: 29, 636: 28, 552: 28, 539: 28, 522: 28, 569: 28, 602: 27, 570: 27, 558: 27, 642: 27, 601: 27, 580: 27, 561: 26, 589: 26, 596: 26, 547: 26, 571: 25, 582: 25, 560: 25, 726: 25, 592: 25, 584: 25, 613: 25, 576: 25, 549: 25, 581: 24, 568: 24, 666: 24, 626: 24, 597: 24, 544: 24, 616: 24, 625: 24, 678: 24, 620: 24, 665: 23, 574: 23, 619: 23, 562: 23, 634: 23, 638: 23, 573: 23, 629: 23, 594: 23, 631: 23, 628: 23, 614: 23, 737: 22, 578: 22, 641: 22, 609: 22, 658: 22, 654: 22, 702: 22, 591: 21, 623: 21, 679: 21, 650: 21, 667: 21, 643: 21, 615: 21, 607: 21, 669: 21, 627: 20, 711: 20, 772: 20, 646: 20, 567: 20, 587: 20, 608: 20, 647: 20, 676: 20, 645: 20, 583: 20, 686: 20, 653: 20, 719: 19, 590: 19, 655: 19, 724: 19, 671: 19, 751: 19, 688: 19, 648: 19, 731: 19, 651: 19, 649: 19, 618: 19, 572: 19, 611: 19, 610: 19, 599: 18, 630: 18, 664: 18, 635: 18, 661: 18, 740: 18, 695: 18, 769: 18, 681: 18, 639: 18, 644: 18, 673: 18, 663: 18, 687: 18, 709: 17, 680: 17, 621: 17, 710: 17, 720: 17, 700: 17, 715: 17, 698: 17, 763: 17, 708: 17, 714: 16, 712: 16, 682: 16, 697: 16, 730: 16, 652: 16, 738: 16, 784: 16, 660: 16, 745: 16, 593: 16, 674: 16, 727: 16, 670: 16, 716: 16, 692: 15, 668: 15, 633: 15, 734: 15, 755: 15, 699: 15, 683: 15, 605: 15, 739: 15, 672: 15, 757: 15, 684: 15, 785: 15, 728: 14, 792: 14, 722: 14, 705: 14, 675: 14, 637: 14, 662: 14, 729: 14, 689: 14, 732: 14, 632: 14, 659: 14, 780: 13, 622: 13, 775: 13, 725: 13, 760: 13, 685: 13, 766: 13, 721: 13, 717: 13, 735: 13, 754: 13, 797: 13, 677: 13, 756: 13, 788: 13, 768: 13, 640: 13, 733: 12, 691: 12, 690: 12, 656: 12, 791: 12, 693: 12, 657: 12, 749: 12, 713: 12, 765: 11, 706: 11, 758: 11, 703: 11, 762: 11, 752: 11, 750: 11, 742: 11, 741: 11, 798: 11, 701: 11, 759: 11, 782: 11, 776: 11, 736: 10, 779: 10, 743: 10, 723: 10, 799: 10, 694: 10, 773: 10, 790: 10, 777: 10, 767: 10, 718: 9, 778: 9, 770: 9, 771: 9, 783: 9, 781: 9, 774: 9, 744: 9, 704: 9, 696: 9, 764: 8, 794: 8, 707: 8, 786: 8, 796: 7, 753: 6, 747: 6, 793: 6, 746: 6, 787: 6, 789: 6, 795: 6, 761: 5, 748: 3})

A = g.adjacency_matrix() spent  0.4755215644836426
auxiliary_graph
Graph(num_nodes=1854722, num_edges=446544019,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.8624627590179443
remove nodes length  1658151

auxiliary_graph.remove_nodes spent  21.21735715866089
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=446544019,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  21.275530576705933

the counter of shared neighbor distribution
Counter({1.0: 248633458, 2.0: 67803098, 3.0: 33419006, 4.0: 20170222, 5.0: 13556126, 6.0: 9760582, 7.0: 7326744, 8.0: 5711654, 9.0: 4558094, 10.0: 3722600, 11.0: 3088418, 12.0: 2603994, 13.0: 2227442, 14.0: 1913972, 15.0: 1665440, 16.0: 1459650, 17.0: 1289764, 18.0: 1146154, 19.0: 1025202, 20.0: 919114, 21.0: 827432, 22.0: 747166, 23.0: 681572, 24.0: 621436, 25.0: 572360, 26.0: 524148, 27.0: 485272, 28.0: 450222, 29.0: 415402, 30.0: 388406, 31.0: 361038, 32.0: 338834, 33.0: 318118, 34.0: 297882, 35.0: 278902, 36.0: 263834, 37.0: 249684, 38.0: 236974, 39.0: 225940, 40.0: 212300, 41.0: 201784, 42.0: 193344, 43.0: 184206, 44.0: 174846, 45.0: 166652, 46.0: 159066, 47.0: 151372, 48.0: 145350, 49.0: 142360, 50.0: 133854, 51.0: 130190, 52.0: 124482, 53.0: 117944, 54.0: 113158, 55.0: 107712, 56.0: 103558, 57.0: 99880, 58.0: 96558, 59.0: 92402, 60.0: 89072, 61.0: 85180, 62.0: 82336, 63.0: 79652, 64.0: 75748, 65.0: 73868, 67.0: 72626, 66.0: 71734, 68.0: 66682, 69.0: 64726, 70.0: 62310, 71.0: 60408, 72.0: 58660, 73.0: 56350, 74.0: 54522, 75.0: 53378, 76.0: 51358, 77.0: 50294, 78.0: 47234, 79.0: 45482, 80.0: 44168, 81.0: 44020, 82.0: 42046, 83.0: 41034, 85.0: 40038, 84.0: 39960, 86.0: 37740, 87.0: 36260, 88.0: 35222, 89.0: 34122, 90.0: 33308, 91.0: 32184, 92.0: 31540, 93.0: 30666, 94.0: 29828, 95.0: 28858, 96.0: 28214, 97.0: 27950, 98.0: 26672, 99.0: 26272, 100.0: 25346, 101.0: 24716, 102.0: 24268, 103.0: 23822, 104.0: 22890, 105.0: 22102, 106.0: 22100, 107.0: 21132, 108.0: 20320, 109.0: 19928, 110.0: 19692, 111.0: 19138, 113.0: 18620, 112.0: 18536, 114.0: 17802, 115.0: 17066, 116.0: 16908, 118.0: 16580, 117.0: 16566, 120.0: 16234, 119.0: 15844, 121.0: 15140, 122.0: 14670, 123.0: 14310, 124.0: 13750, 126.0: 13652, 125.0: 13594, 127.0: 13312, 128.0: 12618, 129.0: 12452, 131.0: 12048, 132.0: 11924, 130.0: 11752, 134.0: 11740, 135.0: 11484, 133.0: 11420, 137.0: 10656, 136.0: 10566, 138.0: 10122, 141.0: 10070, 139.0: 9916, 140.0: 9718, 142.0: 9534, 143.0: 9404, 144.0: 9254, 145.0: 9168, 146.0: 8764, 147.0: 8456, 148.0: 8430, 149.0: 8414, 150.0: 8132, 152.0: 8018, 151.0: 7858, 154.0: 7526, 153.0: 7482, 156.0: 7326, 157.0: 7156, 155.0: 7102, 158.0: 6888, 159.0: 6802, 161.0: 6658, 160.0: 6590, 162.0: 6544, 163.0: 6400, 164.0: 6042, 165.0: 6006, 168.0: 5924, 166.0: 5868, 167.0: 5802, 169.0: 5674, 170.0: 5534, 171.0: 5374, 172.0: 5282, 173.0: 5182, 174.0: 5154, 175.0: 5022, 176.0: 4832, 177.0: 4810, 179.0: 4712, 178.0: 4674, 182.0: 4514, 184.0: 4448, 181.0: 4448, 180.0: 4440, 183.0: 4390, 186.0: 4324, 185.0: 4208, 187.0: 4100, 188.0: 4056, 189.0: 3984, 191.0: 3878, 190.0: 3832, 192.0: 3672, 195.0: 3552, 193.0: 3546, 194.0: 3520, 196.0: 3444, 197.0: 3370, 198.0: 3292, 199.0: 3226, 200.0: 3164, 202.0: 3086, 206.0: 3010, 201.0: 3004, 203.0: 3000, 205.0: 2964, 204.0: 2864, 211.0: 2850, 207.0: 2820, 210.0: 2804, 208.0: 2804, 209.0: 2772, 213.0: 2696, 212.0: 2684, 214.0: 2634, 217.0: 2514, 215.0: 2488, 216.0: 2404, 218.0: 2400, 219.0: 2312, 224.0: 2288, 221.0: 2288, 220.0: 2262, 222.0: 2220, 223.0: 2212, 228.0: 2140, 225.0: 2112, 226.0: 2076, 230.0: 1992, 231.0: 1972, 227.0: 1952, 229.0: 1930, 233.0: 1926, 232.0: 1886, 235.0: 1846, 234.0: 1828, 237.0: 1824, 239.0: 1810, 236.0: 1762, 240.0: 1698, 242.0: 1686, 243.0: 1664, 238.0: 1662, 241.0: 1598, 244.0: 1552, 245.0: 1546, 251.0: 1518, 249.0: 1502, 247.0: 1496, 246.0: 1492, 250.0: 1474, 253.0: 1474, 248.0: 1464, 252.0: 1406, 256.0: 1336, 254.0: 1328, 255.0: 1300, 257.0: 1292, 258.0: 1290, 259.0: 1272, 262.0: 1232, 260.0: 1222, 261.0: 1200, 264.0: 1200, 269.0: 1170, 266.0: 1140, 265.0: 1112, 263.0: 1098, 267.0: 1092, 271.0: 1092, 268.0: 1070, 270.0: 1056, 277.0: 1040, 274.0: 1030, 272.0: 1012, 275.0: 1008, 276.0: 974, 278.0: 972, 281.0: 958, 279.0: 916, 283.0: 916, 273.0: 906, 280.0: 902, 282.0: 856, 286.0: 848, 284.0: 828, 287.0: 804, 288.0: 802, 285.0: 794, 294.0: 776, 290.0: 768, 289.0: 764, 299.0: 758, 295.0: 754, 296.0: 752, 291.0: 752, 292.0: 718, 293.0: 718, 297.0: 706, 304.0: 686, 298.0: 678, 301.0: 676, 305.0: 662, 308.0: 656, 307.0: 636, 303.0: 630, 306.0: 622, 300.0: 596, 311.0: 588, 302.0: 584, 310.0: 582, 315.0: 574, 309.0: 572, 314.0: 568, 312.0: 560, 313.0: 556, 317.0: 550, 321.0: 532, 316.0: 516, 318.0: 516, 330.0: 512, 319.0: 510, 326.0: 490, 320.0: 486, 323.0: 484, 327.0: 484, 334.0: 472, 329.0: 470, 322.0: 466, 331.0: 466, 325.0: 460, 332.0: 452, 324.0: 442, 333.0: 428, 335.0: 416, 337.0: 414, 340.0: 408, 336.0: 408, 328.0: 406, 344.0: 404, 348.0: 378, 343.0: 376, 350.0: 364, 347.0: 360, 353.0: 358, 352.0: 354, 339.0: 354, 345.0: 354, 342.0: 344, 354.0: 344, 346.0: 340, 351.0: 336, 349.0: 332, 341.0: 328, 338.0: 328, 358.0: 326, 359.0: 318, 367.0: 314, 355.0: 304, 360.0: 298, 362.0: 296, 364.0: 294, 356.0: 292, 366.0: 284, 357.0: 284, 371.0: 282, 372.0: 280, 363.0: 278, 365.0: 274, 361.0: 272, 369.0: 258, 379.0: 250, 368.0: 246, 374.0: 244, 384.0: 244, 380.0: 242, 383.0: 240, 373.0: 238, 381.0: 234, 386.0: 228, 375.0: 228, 370.0: 226, 392.0: 224, 376.0: 216, 387.0: 208, 391.0: 206, 377.0: 206, 389.0: 200, 378.0: 198, 385.0: 192, 395.0: 184, 394.0: 184, 382.0: 182, 390.0: 176, 388.0: 176, 402.0: 176, 393.0: 172, 397.0: 170, 396.0: 168, 399.0: 168, 400.0: 164, 403.0: 164, 404.0: 158, 407.0: 154, 417.0: 152, 398.0: 150, 413.0: 148, 405.0: 146, 420.0: 146, 411.0: 146, 401.0: 146, 406.0: 144, 408.0: 142, 410.0: 140, 416.0: 136, 412.0: 130, 414.0: 128, 432.0: 128, 418.0: 128, 415.0: 126, 425.0: 124, 424.0: 122, 422.0: 118, 433.0: 118, 409.0: 118, 426.0: 116, 419.0: 112, 442.0: 104, 423.0: 104, 429.0: 104, 439.0: 104, 427.0: 104, 421.0: 102, 435.0: 102, 444.0: 102, 445.0: 102, 431.0: 100, 428.0: 98, 437.0: 98, 434.0: 98, 430.0: 98, 441.0: 96, 447.0: 96, 443.0: 94, 446.0: 90, 440.0: 88, 451.0: 86, 454.0: 86, 462.0: 82, 449.0: 80, 456.0: 80, 448.0: 80, 450.0: 78, 457.0: 78, 467.0: 78, 460.0: 76, 458.0: 76, 463.0: 76, 438.0: 72, 453.0: 72, 459.0: 70, 473.0: 68, 469.0: 66, 472.0: 66, 436.0: 66, 466.0: 64, 464.0: 64, 468.0: 64, 482.0: 58, 470.0: 58, 465.0: 58, 484.0: 58, 475.0: 56, 474.0: 56, 476.0: 56, 481.0: 54, 455.0: 52, 488.0: 52, 478.0: 48, 471.0: 48, 489.0: 48, 499.0: 48, 461.0: 46, 477.0: 46, 479.0: 42, 452.0: 42, 491.0: 42, 493.0: 42, 483.0: 40, 486.0: 40, 495.0: 40, 502.0: 38, 505.0: 38, 480.0: 38, 500.0: 38, 485.0: 36, 494.0: 36, 497.0: 36, 492.0: 36, 498.0: 36, 496.0: 34, 511.0: 34, 523.0: 32, 510.0: 32, 503.0: 30, 509.0: 30, 490.0: 30, 518.0: 30, 487.0: 28, 507.0: 26, 501.0: 26, 513.0: 26, 537.0: 26, 529.0: 26, 506.0: 24, 514.0: 24, 504.0: 24, 519.0: 22, 517.0: 20, 522.0: 20, 524.0: 20, 538.0: 18, 525.0: 18, 531.0: 16, 528.0: 16, 520.0: 16, 553.0: 16, 508.0: 16, 516.0: 16, 527.0: 16, 526.0: 14, 539.0: 14, 556.0: 12, 558.0: 12, 536.0: 12, 535.0: 12, 521.0: 12, 563.0: 12, 543.0: 12, 533.0: 12, 559.0: 10, 552.0: 10, 530.0: 10, 515.0: 10, 550.0: 10, 580.0: 10, 548.0: 10, 532.0: 10, 541.0: 8, 546.0: 8, 547.0: 8, 579.0: 8, 591.0: 8, 512.0: 8, 542.0: 8, 565.0: 8, 540.0: 8, 545.0: 8, 534.0: 8, 561.0: 8, 560.0: 6, 587.0: 6, 567.0: 6, 544.0: 6, 581.0: 6, 574.0: 6, 555.0: 6, 549.0: 6, 573.0: 6, 564.0: 6, 621.0: 4, 602.0: 4, 595.0: 4, 592.0: 4, 635.0: 4, 569.0: 4, 583.0: 4, 568.0: 4, 551.0: 4, 584.0: 4, 604.0: 4, 562.0: 4, 557.0: 4, 578.0: 4, 628.0: 4, 566.0: 4, 571.0: 4, 610.0: 4, 629.0: 2, 606.0: 2, 597.0: 2, 615.0: 2, 596.0: 2, 554.0: 2, 589.0: 2, 605.0: 2, 586.0: 2, 613.0: 2, 650.0: 2, 614.0: 2, 598.0: 2, 616.0: 2, 649.0: 2, 699.0: 2, 582.0: 2, 612.0: 2, 572.0: 2, 585.0: 2, 575.0: 2, 601.0: 2, 588.0: 2, 668.0: 2, 577.0: 2})
446347448
Convert a graph into a bidirected graph: 37.105 seconds
Metis partitioning: 114.050 seconds
Split the graph: 12.307 seconds
Construct subgraphs: 0.043 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  163.71452593803406
15271
14679
15066
15572
14850
15488
15541
14775
15572
15128
15271
14679
14679
total k batches seeds list generation spend  324.62694239616394
after graph partition
graph partition algorithm spend time 328.6290674209595
15271
14679
15066
15572
14850
15488
15541
14775
15572
15128
15271
14679
14679
partition_len_list
[401100, 388343, 162959, 234096, 230664, 244644, 332547, 364851, 311265, 376268, 343648, 311711, 407693]
REG selection method  spend 329.7716703414917
time for parepare:  0.3906819820404053
local_output_nid generation:  0.007738590240478516
local_in_edges_tensor generation:  0.04368162155151367
mini_batch_src_global generation:  0.11300516128540039
r_  generation:  0.950890064239502
local_output_nid generation:  0.0070798397064208984
local_in_edges_tensor generation:  0.027922630310058594
mini_batch_src_global generation:  0.09614419937133789
r_  generation:  0.7331094741821289
local_output_nid generation:  0.007402658462524414
local_in_edges_tensor generation:  0.025152921676635742
mini_batch_src_global generation:  0.08112597465515137
r_  generation:  0.6184518337249756
local_output_nid generation:  0.00739288330078125
local_in_edges_tensor generation:  0.02247476577758789
mini_batch_src_global generation:  0.08094215393066406
r_  generation:  0.6629884243011475
local_output_nid generation:  0.007254362106323242
local_in_edges_tensor generation:  0.020545482635498047
mini_batch_src_global generation:  0.07722330093383789
r_  generation:  0.6264464855194092
local_output_nid generation:  0.00751042366027832
local_in_edges_tensor generation:  0.017599821090698242
mini_batch_src_global generation:  0.07670450210571289
r_  generation:  0.651228666305542
local_output_nid generation:  0.007448434829711914
local_in_edges_tensor generation:  0.0334169864654541
mini_batch_src_global generation:  0.09508943557739258
r_  generation:  0.7469029426574707
local_output_nid generation:  0.007139682769775391
local_in_edges_tensor generation:  0.01896190643310547
mini_batch_src_global generation:  0.08941793441772461
r_  generation:  0.7741291522979736
local_output_nid generation:  0.00748443603515625
local_in_edges_tensor generation:  0.048126220703125
mini_batch_src_global generation:  0.12130594253540039
r_  generation:  0.944598913192749
local_output_nid generation:  0.007442474365234375
local_in_edges_tensor generation:  0.020435094833374023
mini_batch_src_global generation:  0.10990095138549805
r_  generation:  0.9379677772521973
local_output_nid generation:  0.007467985153198242
local_in_edges_tensor generation:  0.027029991149902344
mini_batch_src_global generation:  0.1113424301147461
r_  generation:  0.9338541030883789
local_output_nid generation:  0.007112979888916016
local_in_edges_tensor generation:  0.017989397048950195
mini_batch_src_global generation:  0.09978508949279785
r_  generation:  0.7930271625518799
local_output_nid generation:  0.0071010589599609375
local_in_edges_tensor generation:  0.024249792098999023
mini_batch_src_global generation:  0.10198235511779785
r_  generation:  0.908289909362793
----------------------check_connections_block total spend ----------------------------- 14.2180495262146
generate_one_block  2.7832705974578857
generate_one_block  1.4963905811309814
generate_one_block  1.1275041103363037
generate_one_block  1.279550313949585
generate_one_block  1.1868517398834229
generate_one_block  1.2102227210998535
generate_one_block  1.4687724113464355
generate_one_block  1.4415152072906494
generate_one_block  1.801429033279419
generate_one_block  1.7580955028533936
generate_one_block  1.6998825073242188
generate_one_block  1.4160325527191162
generate_one_block  1.6216695308685303
----------===============-------------===============-------------the number of batches *****---- 13

original number of batches:  13
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.1927623748779297  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

connection checking time:  14.2180495262146
block generation total time  20.291186809539795
average batch blocks generation time:  1.5608605238107534
block dataloader generation time/epoch 377.972060918808
pseudo mini batch 0 input nodes size: 401100
----------------------------------------before load block subtensor 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15508365631103516  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15508365631103516  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.3045053482055664  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.30461931228637695  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.15349721908569336  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.17765474319458008  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.7322998046875 GB
    Memory Allocated: 0.17765474319458008  GigaBytes
Max Memory Allocated: 19.35911273956299  GigaBytes

torch.Size([15271, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 18.73046636581421  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 18.733482360839844  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2019333839416504  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 1 input nodes size: 388343
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15356111526489258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15356111526489258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2982301712036133  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.29833984375  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1488041877746582  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16611814498901367  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16611814498901367  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.532517433166504  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.535192012786865  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18338298797607422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 2 input nodes size: 162959
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14870023727416992  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14870023727416992  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20940732955932617  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2095198631286621  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06474113464355469  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08106327056884766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08106327056884766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15066, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.716803073883057  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.719441890716553  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09750986099243164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 3 input nodes size: 234096
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06480932235717773  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06480932235717773  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15201711654663086  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15213346481323242  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09131383895874023  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10787153244018555  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10787153244018555  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15572, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.910818576812744  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.913545608520508  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12457561492919922  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 4 input nodes size: 230664
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09140205383300781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09140205383300781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17733144760131836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1774425506591797  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.090118408203125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10520267486572266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10520267486572266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14850, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.774987697601318  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.777714729309082  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12021636962890625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 5 input nodes size: 244644
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08999204635620117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08999204635620117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18112945556640625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1812448501586914  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09520435333251953  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11023712158203125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11023712158203125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15488, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.73242473602295  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.735136985778809  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12543964385986328  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 6 input nodes size: 332547
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09531593322753906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09531593322753906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21919965744018555  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2193155288696289  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12806272506713867  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14551973342895508  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14551973342895508  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15541, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.64994192123413  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.653010845184326  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16304445266723633  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 7 input nodes size: 364851
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12807226181030273  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12807226181030273  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2639899253845215  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2641000747680664  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14010047912597656  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1567859649658203  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1567859649658203  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14775, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.088523864746094  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.091245651245117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17347097396850586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 8 input nodes size: 311265
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1400446891784668  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1400446891784668  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2560000419616699  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2561163902282715  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12008857727050781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1435260772705078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1435260772705078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15572, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.28096914291382  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.283696174621582  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16766357421875  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 9 input nodes size: 376268
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12073040008544922  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12073040008544922  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26090145111083984  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.261014461517334  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1449427604675293  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16535711288452148  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16535711288452148  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15128, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.886098861694336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.888748168945312  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18516969680786133  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 10 input nodes size: 343648
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14428424835205078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14428424835205078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.27230310440063477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2724170684814453  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13213300704956055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15372943878173828  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15372943878173828  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15271, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.09303045272827  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.096045970916748  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17451143264770508  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 11 input nodes size: 311711
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1321582794189453  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1321582794189453  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24828004837036133  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24838972091674805  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12025690078735352  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1378951072692871  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1378951072692871  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.77403736114502  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.77671194076538  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15548419952392578  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 12 input nodes size: 407693
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12015295028686523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12015295028686523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2720308303833008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2721405029296875  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15590906143188477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1746506690979004  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1746506690979004  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.648609161376953  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.651179790496826  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19344711303710938  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19344711303710938  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19344711303710938  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.16263088813194862 |0.037146531618558444 |18.198142308455246 |0.00019132173978365384 |36.62436250539926 |0.019209623336791992 |
----------------------------------------------------------pseudo_mini_loss sum 4.173886299133301
Total (block generation + training)time/epoch 1088.0967248678207
Training time/epoch 716.7197909355164
Training time without block to device /epoch 716.2368860244751
Training time without total dataloading part /epoch 712.7142593860626
load block tensor time/epoch 2.114201545715332
block to device time/epoch 0.48290491104125977
input features size transfer per epoch 1.7434358596801758e-06
blocks size to device per epoch 1.1622905731201172e-06
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  4109789
Number of first layer input nodes during this epoch:  4109789
Number of first layer output nodes during this epoch:  196571
----------------------------------------before generate dataloader block 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19344663619995117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 1.5187582969665527
global_2_local spend time (sec) 0.6400439739227295
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.3239016532897949
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1658231, 800: 3460, 77: 1190, 79: 1185, 81: 1185, 88: 1183, 84: 1177, 75: 1169, 78: 1169, 83: 1165, 85: 1164, 82: 1160, 67: 1158, 87: 1156, 91: 1154, 86: 1151, 76: 1145, 89: 1142, 92: 1119, 80: 1117, 90: 1108, 69: 1107, 93: 1088, 71: 1080, 73: 1080, 74: 1069, 94: 1069, 70: 1068, 68: 1053, 72: 1052, 99: 1042, 97: 1034, 96: 1020, 95: 1017, 102: 1006, 54: 996, 65: 994, 61: 981, 66: 977, 98: 963, 52: 959, 62: 959, 48: 958, 100: 957, 58: 957, 63: 955, 101: 954, 64: 953, 59: 950, 107: 949, 104: 947, 106: 945, 105: 942, 103: 939, 43: 933, 60: 930, 51: 928, 47: 927, 57: 923, 56: 913, 53: 907, 55: 907, 108: 898, 112: 887, 45: 884, 49: 879, 50: 877, 109: 867, 41: 861, 115: 857, 111: 853, 40: 852, 110: 850, 113: 848, 120: 844, 117: 838, 114: 835, 122: 825, 39: 816, 119: 816, 42: 813, 121: 810, 46: 807, 44: 806, 118: 798, 33: 793, 37: 791, 128: 782, 116: 775, 38: 775, 28: 768, 125: 756, 35: 754, 136: 752, 126: 747, 124: 744, 123: 741, 36: 741, 32: 727, 127: 722, 138: 722, 130: 716, 129: 711, 133: 706, 135: 704, 134: 703, 132: 702, 14: 695, 31: 691, 140: 689, 30: 689, 34: 677, 145: 673, 15: 673, 25: 671, 26: 659, 7: 655, 137: 654, 139: 654, 131: 654, 141: 652, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 150: 633, 143: 629, 11: 624, 144: 620, 142: 617, 13: 615, 16: 614, 148: 612, 147: 612, 146: 605, 18: 604, 149: 602, 22: 592, 155: 587, 21: 586, 19: 584, 12: 583, 154: 580, 152: 579, 157: 577, 151: 577, 9: 576, 153: 575, 20: 572, 17: 556, 6: 550, 159: 544, 156: 541, 158: 535, 164: 527, 160: 520, 8: 512, 165: 508, 169: 507, 161: 505, 172: 503, 163: 497, 166: 495, 170: 492, 168: 486, 162: 484, 171: 482, 167: 476, 177: 463, 4: 456, 179: 453, 180: 447, 175: 446, 5: 445, 182: 438, 181: 435, 173: 435, 185: 429, 176: 428, 184: 427, 174: 423, 178: 421, 199: 400, 187: 391, 188: 389, 186: 387, 193: 386, 190: 386, 192: 381, 189: 377, 191: 375, 3: 374, 183: 370, 208: 369, 195: 369, 196: 369, 194: 365, 198: 363, 204: 350, 209: 340, 203: 340, 197: 339, 200: 338, 207: 337, 202: 336, 206: 335, 201: 333, 213: 327, 214: 320, 211: 316, 224: 309, 231: 308, 216: 306, 215: 305, 219: 304, 205: 303, 218: 302, 210: 301, 221: 299, 228: 293, 217: 291, 212: 291, 225: 289, 222: 284, 220: 282, 223: 275, 233: 273, 226: 273, 230: 271, 239: 268, 227: 268, 238: 259, 244: 259, 234: 258, 249: 258, 237: 257, 229: 254, 240: 253, 235: 252, 246: 252, 236: 246, 232: 246, 247: 244, 241: 243, 245: 239, 242: 235, 257: 234, 243: 233, 250: 232, 255: 227, 2: 221, 248: 221, 264: 219, 252: 219, 254: 214, 259: 210, 267: 209, 268: 206, 251: 202, 253: 201, 258: 201, 266: 199, 260: 196, 269: 195, 265: 190, 273: 190, 263: 189, 270: 189, 278: 188, 277: 187, 262: 183, 276: 182, 261: 182, 282: 182, 256: 179, 274: 179, 272: 178, 285: 178, 271: 177, 299: 175, 280: 175, 284: 174, 1: 173, 290: 169, 291: 168, 303: 165, 295: 165, 287: 164, 279: 160, 288: 159, 286: 159, 315: 159, 298: 157, 294: 156, 300: 155, 292: 154, 297: 152, 283: 152, 301: 151, 302: 151, 289: 149, 305: 148, 293: 147, 281: 147, 275: 147, 306: 147, 312: 146, 307: 146, 311: 145, 316: 144, 313: 140, 310: 139, 296: 134, 309: 133, 304: 133, 318: 132, 320: 131, 314: 131, 308: 130, 332: 127, 319: 127, 342: 123, 328: 123, 326: 123, 323: 120, 321: 120, 333: 119, 322: 119, 317: 118, 344: 115, 351: 114, 327: 114, 340: 114, 324: 113, 331: 113, 336: 110, 325: 109, 355: 108, 349: 107, 365: 105, 329: 105, 341: 105, 345: 104, 353: 104, 330: 103, 339: 103, 338: 103, 357: 102, 359: 102, 334: 101, 362: 100, 378: 100, 381: 100, 337: 99, 380: 99, 383: 99, 348: 99, 371: 99, 356: 98, 360: 98, 350: 98, 354: 97, 370: 97, 363: 96, 343: 96, 372: 95, 385: 94, 335: 93, 352: 92, 376: 92, 374: 92, 347: 92, 373: 91, 375: 91, 361: 91, 368: 91, 346: 90, 366: 90, 393: 89, 369: 88, 364: 87, 384: 86, 377: 82, 390: 81, 386: 81, 395: 80, 398: 80, 416: 80, 387: 80, 389: 79, 397: 79, 407: 79, 392: 79, 358: 78, 419: 77, 382: 77, 421: 75, 418: 74, 367: 73, 402: 73, 400: 73, 429: 72, 450: 71, 408: 71, 401: 71, 379: 71, 417: 71, 394: 69, 431: 69, 406: 69, 388: 68, 427: 68, 405: 68, 453: 68, 391: 68, 410: 67, 409: 67, 404: 67, 399: 66, 411: 66, 467: 65, 440: 64, 433: 63, 447: 62, 412: 62, 413: 62, 446: 62, 434: 61, 396: 61, 425: 60, 475: 60, 451: 60, 426: 60, 424: 59, 430: 58, 432: 58, 420: 57, 454: 57, 464: 57, 415: 57, 460: 56, 428: 56, 441: 55, 423: 55, 484: 55, 462: 54, 514: 54, 435: 54, 461: 54, 444: 53, 481: 52, 445: 52, 468: 52, 403: 52, 443: 51, 459: 51, 439: 51, 448: 51, 422: 50, 476: 50, 507: 49, 437: 49, 498: 48, 465: 48, 442: 48, 438: 48, 436: 48, 472: 48, 478: 47, 480: 47, 458: 47, 473: 47, 456: 46, 489: 46, 469: 46, 494: 46, 455: 45, 477: 45, 479: 45, 487: 44, 519: 44, 491: 44, 500: 43, 414: 43, 510: 43, 534: 42, 483: 42, 457: 42, 470: 42, 471: 42, 518: 42, 553: 41, 516: 41, 463: 41, 526: 41, 564: 41, 540: 40, 495: 40, 517: 40, 499: 40, 521: 40, 511: 40, 536: 40, 486: 40, 502: 39, 520: 39, 449: 39, 541: 39, 482: 38, 466: 38, 505: 38, 513: 37, 538: 37, 503: 37, 535: 37, 524: 37, 532: 36, 598: 36, 497: 36, 555: 36, 506: 36, 474: 36, 452: 36, 550: 36, 603: 36, 504: 35, 563: 35, 527: 35, 530: 35, 554: 35, 490: 35, 595: 34, 565: 34, 531: 34, 515: 34, 488: 34, 512: 34, 551: 34, 537: 34, 556: 34, 492: 34, 493: 34, 559: 33, 548: 33, 533: 33, 496: 33, 528: 33, 545: 32, 501: 32, 557: 32, 612: 32, 523: 32, 542: 32, 546: 31, 588: 31, 485: 31, 525: 31, 606: 30, 577: 30, 624: 30, 529: 30, 543: 29, 586: 29, 585: 29, 566: 29, 600: 29, 617: 29, 604: 29, 508: 29, 575: 29, 579: 29, 509: 29, 636: 28, 522: 28, 569: 28, 552: 28, 539: 28, 642: 27, 558: 27, 580: 27, 601: 27, 570: 27, 602: 27, 561: 26, 589: 26, 547: 26, 596: 26, 549: 25, 613: 25, 560: 25, 584: 25, 576: 25, 582: 25, 726: 25, 571: 25, 592: 25, 616: 24, 544: 24, 620: 24, 597: 24, 666: 24, 678: 24, 568: 24, 626: 24, 625: 24, 581: 24, 638: 23, 634: 23, 628: 23, 614: 23, 562: 23, 594: 23, 573: 23, 629: 23, 619: 23, 665: 23, 631: 23, 574: 23, 578: 22, 737: 22, 654: 22, 658: 22, 641: 22, 702: 22, 609: 22, 615: 21, 623: 21, 643: 21, 650: 21, 591: 21, 679: 21, 667: 21, 669: 21, 607: 21, 627: 20, 647: 20, 646: 20, 686: 20, 676: 20, 653: 20, 583: 20, 587: 20, 608: 20, 567: 20, 772: 20, 645: 20, 711: 20, 648: 19, 572: 19, 671: 19, 655: 19, 590: 19, 611: 19, 688: 19, 731: 19, 751: 19, 649: 19, 618: 19, 724: 19, 719: 19, 651: 19, 610: 19, 695: 18, 630: 18, 664: 18, 740: 18, 639: 18, 635: 18, 663: 18, 599: 18, 687: 18, 644: 18, 661: 18, 673: 18, 769: 18, 681: 18, 763: 17, 708: 17, 710: 17, 720: 17, 700: 17, 621: 17, 709: 17, 680: 17, 698: 17, 715: 17, 697: 16, 670: 16, 730: 16, 714: 16, 712: 16, 716: 16, 745: 16, 727: 16, 682: 16, 660: 16, 674: 16, 738: 16, 593: 16, 652: 16, 784: 16, 757: 15, 692: 15, 668: 15, 633: 15, 672: 15, 684: 15, 734: 15, 755: 15, 739: 15, 699: 15, 605: 15, 683: 15, 785: 15, 732: 14, 792: 14, 662: 14, 689: 14, 637: 14, 722: 14, 729: 14, 632: 14, 659: 14, 675: 14, 705: 14, 728: 14, 780: 13, 775: 13, 756: 13, 717: 13, 760: 13, 797: 13, 788: 13, 685: 13, 640: 13, 725: 13, 721: 13, 677: 13, 735: 13, 622: 13, 754: 13, 766: 13, 768: 13, 690: 12, 733: 12, 713: 12, 657: 12, 656: 12, 693: 12, 749: 12, 691: 12, 791: 12, 742: 11, 759: 11, 703: 11, 706: 11, 782: 11, 798: 11, 762: 11, 701: 11, 750: 11, 765: 11, 752: 11, 758: 11, 741: 11, 776: 11, 790: 10, 736: 10, 743: 10, 694: 10, 723: 10, 773: 10, 767: 10, 779: 10, 799: 10, 777: 10, 704: 9, 781: 9, 696: 9, 783: 9, 718: 9, 770: 9, 744: 9, 778: 9, 774: 9, 771: 9, 794: 8, 764: 8, 786: 8, 707: 8, 796: 7, 795: 6, 787: 6, 746: 6, 753: 6, 747: 6, 793: 6, 789: 6, 761: 5, 748: 3})

A = g.adjacency_matrix() spent  0.4727783203125
auxiliary_graph
Graph(num_nodes=1854802, num_edges=446576835,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.8396286964416504
remove nodes length  1658231

auxiliary_graph.remove_nodes spent  21.275447368621826
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=446576835,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  22.499232292175293

the counter of shared neighbor distribution
Counter({1.0: 248657936, 2.0: 67813996, 3.0: 33421764, 4.0: 20168466, 5.0: 13555646, 6.0: 9758748, 7.0: 7326414, 8.0: 5713018, 9.0: 4557346, 10.0: 3724150, 11.0: 3087148, 12.0: 2602014, 13.0: 2228310, 14.0: 1913422, 15.0: 1665062, 16.0: 1459530, 17.0: 1289230, 18.0: 1145908, 19.0: 1024898, 20.0: 919508, 21.0: 827008, 22.0: 747884, 23.0: 682216, 24.0: 621570, 25.0: 572296, 26.0: 524240, 27.0: 485198, 28.0: 449942, 29.0: 415308, 30.0: 388228, 31.0: 361378, 32.0: 338894, 33.0: 318204, 34.0: 298028, 35.0: 279370, 36.0: 264402, 37.0: 248658, 38.0: 236852, 39.0: 226302, 40.0: 212176, 41.0: 201336, 42.0: 193440, 43.0: 183846, 44.0: 174970, 45.0: 166730, 46.0: 159036, 47.0: 150968, 48.0: 145842, 49.0: 142368, 50.0: 133916, 51.0: 130448, 52.0: 123856, 53.0: 118018, 54.0: 112942, 55.0: 107872, 56.0: 103750, 57.0: 99890, 58.0: 96288, 59.0: 92522, 60.0: 89140, 61.0: 85060, 62.0: 82382, 63.0: 80010, 64.0: 75948, 65.0: 73824, 67.0: 72398, 66.0: 71376, 68.0: 66938, 69.0: 64564, 70.0: 62332, 71.0: 60192, 72.0: 58496, 73.0: 56484, 74.0: 54476, 75.0: 53448, 76.0: 51478, 77.0: 50426, 78.0: 47394, 79.0: 45784, 80.0: 44312, 81.0: 44200, 82.0: 42198, 83.0: 40950, 84.0: 39968, 85.0: 39808, 86.0: 37554, 87.0: 36322, 88.0: 35250, 89.0: 33950, 90.0: 33130, 91.0: 32414, 92.0: 31622, 93.0: 30424, 94.0: 29690, 95.0: 29000, 96.0: 28192, 97.0: 27860, 98.0: 26890, 99.0: 26052, 100.0: 25452, 101.0: 24620, 102.0: 24186, 103.0: 23758, 104.0: 22786, 105.0: 22264, 106.0: 22036, 107.0: 21288, 108.0: 20302, 109.0: 19928, 110.0: 19726, 111.0: 19140, 113.0: 18690, 112.0: 18560, 114.0: 17620, 115.0: 17136, 116.0: 16972, 117.0: 16488, 118.0: 16384, 120.0: 16264, 119.0: 16046, 121.0: 15112, 122.0: 14664, 123.0: 14296, 126.0: 13746, 125.0: 13720, 124.0: 13716, 127.0: 13088, 128.0: 12626, 129.0: 12520, 130.0: 12050, 131.0: 11968, 132.0: 11906, 134.0: 11664, 133.0: 11548, 135.0: 11374, 137.0: 10676, 136.0: 10580, 138.0: 10174, 141.0: 10052, 139.0: 9950, 140.0: 9720, 143.0: 9518, 142.0: 9506, 144.0: 9112, 145.0: 9076, 146.0: 8726, 147.0: 8550, 149.0: 8538, 148.0: 8376, 150.0: 8068, 152.0: 8006, 151.0: 7800, 153.0: 7492, 154.0: 7436, 156.0: 7364, 155.0: 7338, 157.0: 7070, 158.0: 7026, 159.0: 6918, 162.0: 6592, 160.0: 6536, 161.0: 6488, 163.0: 6292, 164.0: 6110, 168.0: 5960, 166.0: 5956, 165.0: 5940, 169.0: 5760, 167.0: 5708, 170.0: 5496, 171.0: 5472, 172.0: 5304, 174.0: 5178, 173.0: 5114, 175.0: 5020, 177.0: 4806, 178.0: 4798, 176.0: 4782, 179.0: 4702, 180.0: 4512, 182.0: 4468, 183.0: 4454, 184.0: 4424, 181.0: 4410, 186.0: 4286, 185.0: 4206, 187.0: 4010, 191.0: 3994, 188.0: 3982, 190.0: 3942, 189.0: 3796, 192.0: 3624, 194.0: 3568, 193.0: 3470, 195.0: 3456, 196.0: 3436, 197.0: 3374, 199.0: 3192, 198.0: 3186, 201.0: 3162, 202.0: 3110, 200.0: 3106, 203.0: 3012, 204.0: 2978, 205.0: 2972, 206.0: 2970, 209.0: 2870, 208.0: 2862, 210.0: 2780, 211.0: 2778, 207.0: 2770, 212.0: 2672, 214.0: 2662, 213.0: 2616, 217.0: 2490, 218.0: 2442, 216.0: 2428, 215.0: 2428, 224.0: 2300, 219.0: 2280, 220.0: 2276, 221.0: 2272, 223.0: 2244, 222.0: 2244, 228.0: 2194, 225.0: 2168, 227.0: 2060, 229.0: 2020, 226.0: 1998, 233.0: 1940, 231.0: 1930, 230.0: 1910, 237.0: 1848, 234.0: 1838, 239.0: 1834, 235.0: 1808, 236.0: 1804, 232.0: 1804, 243.0: 1732, 238.0: 1672, 240.0: 1664, 242.0: 1620, 244.0: 1614, 241.0: 1600, 247.0: 1548, 251.0: 1526, 245.0: 1524, 248.0: 1492, 250.0: 1488, 249.0: 1486, 246.0: 1432, 253.0: 1428, 252.0: 1388, 256.0: 1364, 257.0: 1352, 255.0: 1324, 258.0: 1302, 261.0: 1268, 259.0: 1262, 260.0: 1250, 254.0: 1214, 262.0: 1182, 264.0: 1164, 263.0: 1142, 269.0: 1124, 272.0: 1120, 266.0: 1118, 268.0: 1098, 265.0: 1088, 270.0: 1084, 271.0: 1064, 277.0: 1028, 274.0: 1020, 267.0: 1020, 278.0: 986, 275.0: 974, 273.0: 952, 276.0: 914, 279.0: 906, 282.0: 904, 280.0: 888, 283.0: 880, 285.0: 876, 281.0: 872, 284.0: 850, 286.0: 830, 287.0: 796, 289.0: 794, 293.0: 790, 295.0: 778, 288.0: 770, 294.0: 760, 296.0: 744, 297.0: 734, 290.0: 730, 291.0: 726, 292.0: 710, 299.0: 700, 304.0: 692, 298.0: 686, 300.0: 684, 305.0: 658, 303.0: 656, 307.0: 654, 301.0: 626, 302.0: 624, 308.0: 608, 306.0: 606, 310.0: 604, 316.0: 600, 311.0: 594, 313.0: 586, 309.0: 582, 314.0: 580, 319.0: 558, 315.0: 550, 329.0: 538, 312.0: 536, 321.0: 530, 317.0: 518, 327.0: 518, 323.0: 506, 326.0: 486, 322.0: 482, 320.0: 474, 330.0: 470, 324.0: 466, 325.0: 466, 334.0: 450, 332.0: 434, 318.0: 432, 331.0: 428, 337.0: 420, 335.0: 414, 344.0: 402, 333.0: 400, 328.0: 398, 340.0: 390, 351.0: 384, 343.0: 378, 348.0: 378, 346.0: 368, 352.0: 358, 347.0: 358, 336.0: 354, 353.0: 354, 341.0: 352, 345.0: 348, 338.0: 346, 342.0: 344, 358.0: 338, 339.0: 336, 367.0: 336, 349.0: 330, 355.0: 322, 356.0: 316, 350.0: 316, 354.0: 312, 361.0: 306, 359.0: 304, 366.0: 298, 363.0: 298, 357.0: 298, 365.0: 296, 362.0: 290, 364.0: 278, 368.0: 276, 371.0: 270, 360.0: 262, 373.0: 262, 379.0: 254, 372.0: 252, 369.0: 250, 370.0: 236, 380.0: 230, 375.0: 230, 378.0: 226, 391.0: 224, 383.0: 224, 376.0: 224, 374.0: 222, 384.0: 214, 386.0: 206, 390.0: 206, 385.0: 206, 381.0: 204, 392.0: 204, 389.0: 202, 382.0: 202, 377.0: 202, 393.0: 192, 387.0: 190, 394.0: 190, 388.0: 188, 400.0: 182, 404.0: 180, 401.0: 178, 396.0: 166, 408.0: 162, 411.0: 162, 407.0: 158, 395.0: 158, 403.0: 158, 399.0: 158, 397.0: 156, 405.0: 156, 406.0: 152, 420.0: 152, 417.0: 146, 409.0: 144, 398.0: 136, 416.0: 136, 413.0: 134, 412.0: 128, 426.0: 126, 402.0: 122, 418.0: 122, 439.0: 122, 432.0: 122, 414.0: 122, 425.0: 118, 415.0: 118, 410.0: 116, 419.0: 116, 422.0: 116, 423.0: 110, 424.0: 110, 433.0: 108, 430.0: 108, 454.0: 108, 431.0: 106, 445.0: 104, 428.0: 102, 421.0: 102, 437.0: 100, 449.0: 100, 442.0: 100, 434.0: 98, 440.0: 98, 441.0: 96, 429.0: 96, 444.0: 94, 447.0: 90, 443.0: 88, 473.0: 84, 451.0: 84, 427.0: 82, 446.0: 82, 457.0: 82, 477.0: 80, 436.0: 80, 459.0: 78, 462.0: 78, 472.0: 76, 460.0: 76, 448.0: 74, 435.0: 74, 461.0: 70, 467.0: 70, 453.0: 70, 456.0: 70, 450.0: 70, 463.0: 66, 458.0: 66, 465.0: 66, 438.0: 62, 455.0: 62, 452.0: 60, 482.0: 58, 466.0: 58, 481.0: 56, 468.0: 56, 469.0: 56, 476.0: 56, 464.0: 54, 475.0: 52, 483.0: 52, 474.0: 50, 485.0: 48, 489.0: 48, 484.0: 48, 470.0: 48, 492.0: 46, 498.0: 44, 491.0: 44, 488.0: 44, 487.0: 42, 478.0: 42, 502.0: 42, 500.0: 42, 471.0: 40, 499.0: 40, 501.0: 38, 486.0: 38, 490.0: 38, 494.0: 36, 503.0: 34, 496.0: 34, 479.0: 34, 497.0: 32, 504.0: 32, 514.0: 30, 508.0: 30, 509.0: 28, 493.0: 28, 528.0: 28, 510.0: 28, 480.0: 26, 507.0: 26, 523.0: 24, 515.0: 24, 505.0: 22, 521.0: 22, 525.0: 22, 495.0: 22, 527.0: 20, 532.0: 20, 526.0: 20, 524.0: 20, 556.0: 18, 512.0: 18, 529.0: 18, 537.0: 18, 520.0: 18, 506.0: 18, 516.0: 18, 517.0: 16, 511.0: 16, 513.0: 16, 531.0: 16, 518.0: 16, 535.0: 16, 538.0: 16, 557.0: 14, 530.0: 14, 540.0: 14, 519.0: 14, 566.0: 14, 543.0: 14, 533.0: 14, 544.0: 14, 541.0: 12, 548.0: 12, 555.0: 12, 522.0: 12, 550.0: 10, 553.0: 10, 580.0: 10, 547.0: 10, 549.0: 8, 558.0: 8, 542.0: 8, 536.0: 8, 562.0: 6, 564.0: 6, 565.0: 6, 546.0: 6, 581.0: 6, 587.0: 6, 582.0: 6, 534.0: 6, 570.0: 4, 551.0: 4, 545.0: 4, 568.0: 4, 578.0: 4, 576.0: 4, 563.0: 4, 572.0: 4, 539.0: 4, 611.0: 4, 604.0: 4, 571.0: 4, 567.0: 4, 591.0: 4, 552.0: 4, 575.0: 4, 610.0: 4, 584.0: 4, 594.0: 4, 560.0: 4, 559.0: 4, 574.0: 4, 586.0: 4, 602.0: 4, 554.0: 4, 589.0: 4, 573.0: 4, 561.0: 4, 579.0: 2, 593.0: 2, 597.0: 2, 668.0: 2, 592.0: 2, 699.0: 2, 632.0: 2, 620.0: 2, 607.0: 2, 641.0: 2, 616.0: 2, 608.0: 2, 649.0: 2, 648.0: 2, 612.0: 2, 618.0: 2, 577.0: 2, 633.0: 2, 606.0: 2, 615.0: 2, 596.0: 2, 588.0: 2, 614.0: 2, 583.0: 2, 629.0: 2, 636.0: 2})
446380264
Convert a graph into a bidirected graph: 43.182 seconds
Metis partitioning: 114.918 seconds
Split the graph: 12.364 seconds
Construct subgraphs: 0.039 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  170.69328355789185
14681
15444
14697
15557
14679
15330
15267
15574
15422
14679
14721
15261
15259
total k batches seeds list generation spend  335.5756404399872
after graph partition
graph partition algorithm spend time 339.1489064693451
14681
15444
14697
15557
14679
15330
15267
15574
15422
14679
14721
15261
15259
partition_len_list
[327109, 224525, 322094, 267014, 312852, 161779, 355801, 312751, 340837, 422873, 238895, 387698, 353686]
REG selection method  spend 340.11557126045227
time for parepare:  0.36222195625305176
local_output_nid generation:  0.0075380802154541016
local_in_edges_tensor generation:  0.01603984832763672
mini_batch_src_global generation:  0.06385183334350586
r_  generation:  0.5846242904663086
local_output_nid generation:  0.0076825618743896484
local_in_edges_tensor generation:  0.01507115364074707
mini_batch_src_global generation:  0.07766842842102051
r_  generation:  0.5972368717193604
local_output_nid generation:  0.007159233093261719
local_in_edges_tensor generation:  0.017348766326904297
mini_batch_src_global generation:  0.07981276512145996
r_  generation:  0.6631040573120117
local_output_nid generation:  0.007769107818603516
local_in_edges_tensor generation:  0.03266549110412598
mini_batch_src_global generation:  0.10622024536132812
r_  generation:  0.8630504608154297
local_output_nid generation:  0.007367849349975586
local_in_edges_tensor generation:  0.02930450439453125
mini_batch_src_global generation:  0.09696507453918457
r_  generation:  0.7646515369415283
local_output_nid generation:  0.007752180099487305
local_in_edges_tensor generation:  0.017502784729003906
mini_batch_src_global generation:  0.08816695213317871
r_  generation:  0.6467397212982178
local_output_nid generation:  0.007638692855834961
local_in_edges_tensor generation:  0.018478870391845703
mini_batch_src_global generation:  0.08098578453063965
r_  generation:  0.705718994140625
local_output_nid generation:  0.007727622985839844
local_in_edges_tensor generation:  0.03860116004943848
mini_batch_src_global generation:  0.11578845977783203
r_  generation:  0.9290475845336914
local_output_nid generation:  0.007679939270019531
local_in_edges_tensor generation:  0.04518890380859375
mini_batch_src_global generation:  0.11476922035217285
r_  generation:  0.9286952018737793
local_output_nid generation:  0.007352113723754883
local_in_edges_tensor generation:  0.01941823959350586
mini_batch_src_global generation:  0.12372660636901855
r_  generation:  0.8887419700622559
local_output_nid generation:  0.00728154182434082
local_in_edges_tensor generation:  0.03273415565490723
mini_batch_src_global generation:  0.09167695045471191
r_  generation:  0.7396421432495117
local_output_nid generation:  0.007591724395751953
local_in_edges_tensor generation:  0.035778045654296875
mini_batch_src_global generation:  0.11327075958251953
r_  generation:  0.9372103214263916
local_output_nid generation:  0.007670402526855469
local_in_edges_tensor generation:  0.0372014045715332
mini_batch_src_global generation:  0.11213397979736328
r_  generation:  0.9668107032775879
----------------------check_connections_block total spend ----------------------------- 14.058713674545288
generate_one_block  1.7372748851776123
generate_one_block  1.14927339553833
generate_one_block  1.2980446815490723
generate_one_block  1.5681755542755127
generate_one_block  1.4320745468139648
generate_one_block  1.1154468059539795
generate_one_block  1.243983268737793
generate_one_block  1.7041852474212646
generate_one_block  1.6554136276245117
generate_one_block  1.6214604377746582
generate_one_block  1.2726664543151855
generate_one_block  1.631251335144043
generate_one_block  1.6427171230316162
----------===============-------------===============-------------the number of batches *****---- 13

original number of batches:  13
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19344663619995117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

connection checking time:  14.058713674545288
block generation total time  19.071967363357544
average batch blocks generation time:  1.467074412565965
block dataloader generation time/epoch 383.5908821423848
pseudo mini batch 0 input nodes size: 327109
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15590810775756836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15590810775756836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.27776575088500977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2778754234313965  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12588787078857422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1409015655517578  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1409015655517578  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14681, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.753865242004395  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.756764888763428  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15597152709960938  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 1 input nodes size: 224525
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12588930130004883  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12588930130004883  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2095317840576172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20964717864990234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08767986297607422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10331249237060547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10331249237060547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15444, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.665011405944824  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.667716026306152  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11846017837524414  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 2 input nodes size: 322094
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0878133773803711  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0878133773803711  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20780277252197266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20791244506835938  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12415456771850586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1401810646057129  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1401810646057129  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14697, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.561607837677002  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.56431245803833  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15613174438476562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 3 input nodes size: 267014
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1240239143371582  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1240239143371582  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2234945297241211  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22361087799072266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10351181030273438  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12491416931152344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12491416931152344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15557, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.600800037384033  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.603524684906006  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14682388305664062  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 4 input nodes size: 312852
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10396099090576172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10396099090576172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22050762176513672  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22061729431152344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12103033065795898  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13946866989135742  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13946866989135742  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.373258590698242  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.37628173828125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15750932693481445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 5 input nodes size: 161779
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12057781219482422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12057781219482422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1808452606201172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18095970153808594  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06430339813232422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08082199096679688  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08082199096679688  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15330, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.857748031616211  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.86048936843872  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09751176834106445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 6 input nodes size: 355801
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06441736221313477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06441736221313477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19696378707885742  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19707775115966797  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13669586181640625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15201282501220703  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15201282501220703  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15267, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.02354907989502  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.026233673095703  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16771745681762695  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 7 input nodes size: 312751
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13702630996704102  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13702630996704102  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25353527069091797  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25365161895751953  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12099123001098633  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14442873001098633  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14442873001098633  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15574, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.05994749069214  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.06267499923706  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16763687133789062  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 8 input nodes size: 340837
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12070369720458984  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12070369720458984  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24767541885375977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24779033660888672  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1311650276184082  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15240049362182617  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15240049362182617  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15422, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.520325660705566  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.52337121963501  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17366695404052734  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 9 input nodes size: 422873
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13113832473754883  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13113832473754883  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.28867101669311523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.28878068923950195  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16169404983520508  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1806473731994629  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1806473731994629  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.814538955688477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.817239761352539  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1995253562927246  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 10 input nodes size: 238895
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16156387329101562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16156387329101562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25055932998657227  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2506694793701172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09302711486816406  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11010074615478516  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11010074615478516  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14721, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.303479194641113  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.306057453155518  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12755775451660156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 11 input nodes size: 387698
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09335517883300781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09335517883300781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.23778438568115234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2378983497619629  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14879274368286133  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1694779396057129  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1694779396057129  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15261, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.092005729675293  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.09490442276001  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1901106834411621  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 12 input nodes size: 353686
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1486830711364746  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1486830711364746  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2804417610168457  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.28055572509765625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13601255416870117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15678071975708008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15678071975708008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15259, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.143889904022217  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.146672248840332  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1774892807006836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1774892807006836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1774892807006836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.17595953207749587 |0.04007764963003305 |17.932894633366512 |0.00019570497366098256 |36.60939486210163 |0.029728412628173828 |
----------------------------------------------------------pseudo_mini_loss sum 3.4553163051605225
Total (block generation + training)time/epoch 1094.8686800003052
Training time/epoch 713.5837399959564
Training time without block to device /epoch 713.062730550766
Training time without total dataloading part /epoch 709.0820360183716
load block tensor time/epoch 2.2874739170074463
block to device time/epoch 0.5210094451904297
input features size transfer per epoch 1.7434358596801758e-06
blocks size to device per epoch 1.1622905731201172e-06
 Run 0| Epoch 2 |
Number of nodes for computation during this epoch:  4027914
Number of first layer input nodes during this epoch:  4027914
Number of first layer output nodes during this epoch:  196571
----------------------------------------before generate dataloader block 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1774888038635254  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 1.5218729972839355
global_2_local spend time (sec) 0.6828155517578125
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.34377074241638184
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1658222, 800: 3460, 77: 1190, 81: 1185, 79: 1185, 88: 1183, 84: 1177, 78: 1169, 75: 1169, 83: 1165, 85: 1164, 82: 1160, 67: 1158, 87: 1156, 91: 1154, 86: 1151, 76: 1145, 89: 1142, 92: 1119, 80: 1117, 90: 1108, 69: 1107, 93: 1088, 71: 1080, 73: 1080, 74: 1069, 94: 1069, 70: 1068, 68: 1053, 72: 1052, 99: 1042, 97: 1034, 96: 1020, 95: 1017, 102: 1006, 54: 996, 65: 994, 61: 981, 66: 977, 98: 963, 62: 959, 52: 959, 48: 958, 100: 957, 58: 957, 63: 955, 101: 954, 64: 953, 59: 950, 107: 949, 104: 947, 106: 945, 105: 942, 103: 939, 43: 933, 60: 930, 51: 928, 47: 927, 57: 923, 56: 913, 53: 907, 55: 907, 108: 898, 112: 887, 45: 884, 49: 879, 50: 877, 109: 867, 41: 861, 115: 857, 111: 853, 40: 852, 110: 850, 113: 848, 120: 844, 117: 838, 114: 835, 122: 825, 119: 816, 39: 816, 42: 813, 121: 810, 46: 807, 44: 806, 118: 798, 33: 793, 37: 791, 128: 782, 38: 775, 116: 775, 28: 768, 125: 756, 35: 754, 136: 752, 126: 747, 124: 744, 36: 741, 123: 741, 32: 727, 127: 722, 138: 722, 130: 716, 129: 711, 133: 706, 135: 704, 134: 703, 132: 702, 14: 695, 31: 691, 140: 689, 30: 689, 34: 677, 15: 673, 145: 673, 25: 671, 26: 659, 7: 655, 139: 654, 131: 654, 137: 654, 141: 652, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 150: 633, 143: 629, 11: 624, 144: 620, 142: 617, 13: 615, 16: 614, 148: 612, 147: 612, 146: 605, 18: 604, 149: 602, 22: 592, 155: 587, 21: 586, 19: 584, 12: 583, 154: 580, 152: 579, 151: 577, 157: 577, 9: 576, 153: 575, 20: 572, 17: 556, 6: 550, 159: 544, 156: 541, 158: 535, 164: 527, 160: 520, 8: 512, 165: 508, 169: 507, 161: 505, 172: 503, 163: 497, 166: 495, 170: 492, 168: 486, 162: 484, 171: 482, 167: 476, 177: 463, 4: 456, 179: 453, 180: 447, 175: 446, 5: 445, 182: 438, 173: 435, 181: 435, 185: 429, 176: 428, 184: 427, 174: 423, 178: 421, 199: 400, 187: 391, 188: 389, 186: 387, 190: 386, 193: 386, 192: 381, 189: 377, 191: 375, 3: 374, 183: 370, 196: 369, 208: 369, 195: 369, 194: 365, 198: 363, 204: 350, 203: 340, 209: 340, 197: 339, 200: 338, 207: 337, 202: 336, 206: 335, 201: 333, 213: 327, 214: 320, 211: 316, 224: 309, 231: 308, 216: 306, 215: 305, 219: 304, 205: 303, 218: 302, 210: 301, 221: 299, 228: 293, 212: 291, 217: 291, 225: 289, 222: 284, 220: 282, 223: 275, 233: 273, 226: 273, 230: 271, 227: 268, 239: 268, 244: 259, 238: 259, 234: 258, 249: 258, 237: 257, 229: 254, 240: 253, 246: 252, 235: 252, 232: 246, 236: 246, 247: 244, 241: 243, 245: 239, 242: 235, 257: 234, 243: 233, 250: 232, 255: 227, 248: 221, 2: 221, 252: 219, 264: 219, 254: 214, 259: 210, 267: 209, 268: 206, 251: 202, 258: 201, 253: 201, 266: 199, 260: 196, 269: 195, 273: 190, 265: 190, 263: 189, 270: 189, 278: 188, 277: 187, 262: 183, 276: 182, 282: 182, 261: 182, 256: 179, 274: 179, 272: 178, 285: 178, 271: 177, 299: 175, 280: 175, 284: 174, 1: 173, 290: 169, 291: 168, 295: 165, 303: 165, 287: 164, 279: 160, 315: 159, 286: 159, 288: 159, 298: 157, 294: 156, 300: 155, 292: 154, 283: 152, 297: 152, 302: 151, 301: 151, 289: 149, 305: 148, 293: 147, 306: 147, 275: 147, 281: 147, 312: 146, 307: 146, 311: 145, 316: 144, 313: 140, 310: 139, 296: 134, 309: 133, 304: 133, 318: 132, 320: 131, 314: 131, 308: 130, 332: 127, 319: 127, 342: 123, 326: 123, 328: 123, 321: 120, 323: 120, 333: 119, 322: 119, 317: 118, 344: 115, 340: 114, 327: 114, 351: 114, 331: 113, 324: 113, 336: 110, 325: 109, 355: 108, 349: 107, 329: 105, 365: 105, 341: 105, 345: 104, 353: 104, 338: 103, 330: 103, 339: 103, 359: 102, 357: 102, 334: 101, 381: 100, 378: 100, 362: 100, 337: 99, 383: 99, 371: 99, 380: 99, 348: 99, 350: 98, 360: 98, 356: 98, 354: 97, 370: 97, 343: 96, 363: 96, 372: 95, 385: 94, 335: 93, 376: 92, 374: 92, 347: 92, 352: 92, 368: 91, 375: 91, 373: 91, 361: 91, 366: 90, 346: 90, 393: 89, 369: 88, 364: 87, 384: 86, 377: 82, 390: 81, 386: 81, 398: 80, 416: 80, 387: 80, 395: 80, 389: 79, 392: 79, 397: 79, 407: 79, 358: 78, 419: 77, 382: 77, 421: 75, 418: 74, 367: 73, 400: 73, 402: 73, 429: 72, 417: 71, 401: 71, 379: 71, 450: 71, 408: 71, 406: 69, 431: 69, 394: 69, 388: 68, 405: 68, 427: 68, 453: 68, 391: 68, 409: 67, 404: 67, 410: 67, 411: 66, 399: 66, 467: 65, 440: 64, 433: 63, 446: 62, 447: 62, 412: 62, 413: 62, 396: 61, 434: 61, 426: 60, 425: 60, 451: 60, 475: 60, 424: 59, 430: 58, 432: 58, 454: 57, 420: 57, 415: 57, 464: 57, 428: 56, 460: 56, 441: 55, 423: 55, 484: 55, 461: 54, 514: 54, 435: 54, 462: 54, 444: 53, 403: 52, 481: 52, 445: 52, 468: 52, 459: 51, 443: 51, 448: 51, 439: 51, 476: 50, 422: 50, 437: 49, 507: 49, 442: 48, 472: 48, 436: 48, 438: 48, 498: 48, 465: 48, 478: 47, 473: 47, 480: 47, 458: 47, 489: 46, 469: 46, 456: 46, 494: 46, 479: 45, 455: 45, 477: 45, 487: 44, 491: 44, 519: 44, 510: 43, 500: 43, 414: 43, 471: 42, 483: 42, 470: 42, 518: 42, 457: 42, 534: 42, 564: 41, 463: 41, 516: 41, 526: 41, 553: 41, 511: 40, 521: 40, 495: 40, 499: 40, 536: 40, 486: 40, 540: 40, 517: 40, 502: 39, 541: 39, 449: 39, 520: 39, 466: 38, 482: 38, 505: 38, 538: 37, 503: 37, 535: 37, 524: 37, 513: 37, 497: 36, 452: 36, 550: 36, 506: 36, 555: 36, 603: 36, 474: 36, 598: 36, 532: 36, 530: 35, 527: 35, 490: 35, 563: 35, 504: 35, 554: 35, 595: 34, 488: 34, 537: 34, 556: 34, 512: 34, 493: 34, 565: 34, 492: 34, 531: 34, 551: 34, 515: 34, 533: 33, 528: 33, 559: 33, 496: 33, 548: 33, 523: 32, 557: 32, 612: 32, 501: 32, 542: 32, 545: 32, 588: 31, 485: 31, 546: 31, 525: 31, 529: 30, 624: 30, 606: 30, 577: 30, 600: 29, 543: 29, 508: 29, 579: 29, 604: 29, 566: 29, 586: 29, 585: 29, 575: 29, 509: 29, 617: 29, 569: 28, 636: 28, 522: 28, 552: 28, 539: 28, 570: 27, 602: 27, 601: 27, 580: 27, 558: 27, 642: 27, 589: 26, 596: 26, 561: 26, 547: 26, 571: 25, 584: 25, 560: 25, 592: 25, 726: 25, 576: 25, 582: 25, 549: 25, 613: 25, 678: 24, 581: 24, 597: 24, 544: 24, 620: 24, 626: 24, 666: 24, 625: 24, 616: 24, 568: 24, 638: 23, 629: 23, 628: 23, 665: 23, 631: 23, 634: 23, 594: 23, 574: 23, 573: 23, 619: 23, 614: 23, 562: 23, 658: 22, 578: 22, 702: 22, 654: 22, 737: 22, 641: 22, 609: 22, 679: 21, 650: 21, 667: 21, 623: 21, 607: 21, 615: 21, 643: 21, 669: 21, 591: 21, 608: 20, 583: 20, 711: 20, 646: 20, 645: 20, 567: 20, 772: 20, 686: 20, 587: 20, 627: 20, 647: 20, 676: 20, 653: 20, 655: 19, 731: 19, 648: 19, 649: 19, 719: 19, 688: 19, 751: 19, 611: 19, 572: 19, 618: 19, 724: 19, 610: 19, 671: 19, 651: 19, 590: 19, 644: 18, 663: 18, 661: 18, 635: 18, 740: 18, 695: 18, 681: 18, 630: 18, 639: 18, 664: 18, 769: 18, 687: 18, 599: 18, 673: 18, 720: 17, 700: 17, 621: 17, 710: 17, 763: 17, 680: 17, 715: 17, 709: 17, 698: 17, 708: 17, 727: 16, 714: 16, 593: 16, 674: 16, 745: 16, 682: 16, 652: 16, 697: 16, 716: 16, 670: 16, 660: 16, 712: 16, 784: 16, 730: 16, 738: 16, 755: 15, 668: 15, 684: 15, 672: 15, 605: 15, 739: 15, 633: 15, 785: 15, 683: 15, 692: 15, 734: 15, 699: 15, 757: 15, 792: 14, 662: 14, 732: 14, 637: 14, 729: 14, 659: 14, 689: 14, 722: 14, 728: 14, 705: 14, 675: 14, 632: 14, 721: 13, 756: 13, 797: 13, 760: 13, 754: 13, 677: 13, 766: 13, 775: 13, 725: 13, 768: 13, 780: 13, 622: 13, 717: 13, 735: 13, 640: 13, 788: 13, 685: 13, 656: 12, 713: 12, 690: 12, 657: 12, 791: 12, 691: 12, 693: 12, 749: 12, 733: 12, 765: 11, 782: 11, 703: 11, 758: 11, 776: 11, 752: 11, 706: 11, 798: 11, 759: 11, 742: 11, 762: 11, 750: 11, 741: 11, 701: 11, 736: 10, 694: 10, 777: 10, 723: 10, 779: 10, 743: 10, 790: 10, 799: 10, 773: 10, 767: 10, 778: 9, 781: 9, 771: 9, 783: 9, 774: 9, 718: 9, 704: 9, 744: 9, 770: 9, 696: 9, 794: 8, 786: 8, 764: 8, 707: 8, 796: 7, 787: 6, 795: 6, 789: 6, 747: 6, 753: 6, 793: 6, 746: 6, 761: 5, 748: 3})

A = g.adjacency_matrix() spent  0.4737720489501953
auxiliary_graph
Graph(num_nodes=1854793, num_edges=446590861,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.9165887832641602
remove nodes length  1658222

auxiliary_graph.remove_nodes spent  21.93302869796753
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=446590861,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  22.012598514556885

the counter of shared neighbor distribution
Counter({1.0: 248635196, 2.0: 67822728, 3.0: 33426004, 4.0: 20173296, 5.0: 13559434, 6.0: 9763504, 7.0: 7328202, 8.0: 5714950, 9.0: 4559372, 10.0: 3724156, 11.0: 3087004, 12.0: 2603458, 13.0: 2228526, 14.0: 1914160, 15.0: 1664390, 16.0: 1459842, 17.0: 1288644, 18.0: 1146624, 19.0: 1025172, 20.0: 919830, 21.0: 827084, 22.0: 747012, 23.0: 681882, 24.0: 622030, 25.0: 572242, 26.0: 524830, 27.0: 485204, 28.0: 449626, 29.0: 415176, 30.0: 388416, 31.0: 361618, 32.0: 338606, 33.0: 318056, 34.0: 298302, 35.0: 279060, 36.0: 263936, 37.0: 249614, 38.0: 237094, 39.0: 226342, 40.0: 212666, 41.0: 201852, 42.0: 192920, 43.0: 183674, 44.0: 175352, 45.0: 166994, 46.0: 159176, 47.0: 151076, 48.0: 145686, 49.0: 142340, 50.0: 134058, 51.0: 130440, 52.0: 124232, 53.0: 118252, 54.0: 112490, 55.0: 107674, 56.0: 103344, 57.0: 100128, 58.0: 96664, 59.0: 92222, 60.0: 88990, 61.0: 85458, 62.0: 82580, 63.0: 79892, 64.0: 75852, 65.0: 73630, 67.0: 72716, 66.0: 71538, 68.0: 66602, 69.0: 64688, 70.0: 62680, 71.0: 59988, 72.0: 58456, 73.0: 56476, 74.0: 54578, 75.0: 53526, 76.0: 51602, 77.0: 50516, 78.0: 47146, 79.0: 45704, 80.0: 44224, 81.0: 44130, 82.0: 42162, 83.0: 40904, 84.0: 39966, 85.0: 39918, 86.0: 37734, 87.0: 36180, 88.0: 35332, 89.0: 34186, 90.0: 33410, 91.0: 32256, 92.0: 31692, 93.0: 30452, 94.0: 29676, 95.0: 29010, 96.0: 27946, 97.0: 27872, 98.0: 26778, 99.0: 26110, 100.0: 25544, 101.0: 24742, 102.0: 24174, 103.0: 23832, 104.0: 22808, 106.0: 22072, 105.0: 21970, 107.0: 21352, 108.0: 20418, 109.0: 19926, 110.0: 19732, 111.0: 19188, 113.0: 18580, 112.0: 18552, 114.0: 17966, 115.0: 17136, 116.0: 17038, 117.0: 16524, 118.0: 16456, 120.0: 16100, 119.0: 15850, 121.0: 15010, 122.0: 14620, 123.0: 14270, 126.0: 13818, 124.0: 13776, 125.0: 13626, 127.0: 13240, 129.0: 12606, 128.0: 12580, 132.0: 11994, 131.0: 11900, 130.0: 11842, 134.0: 11740, 133.0: 11540, 135.0: 11420, 136.0: 10616, 137.0: 10588, 138.0: 10150, 141.0: 10058, 139.0: 9936, 140.0: 9792, 142.0: 9558, 143.0: 9472, 145.0: 9194, 144.0: 9012, 146.0: 8754, 148.0: 8494, 147.0: 8418, 149.0: 8414, 150.0: 8148, 152.0: 8016, 151.0: 7814, 154.0: 7466, 153.0: 7416, 157.0: 7260, 156.0: 7248, 155.0: 7214, 158.0: 7034, 159.0: 6950, 160.0: 6602, 161.0: 6528, 162.0: 6468, 163.0: 6274, 164.0: 6148, 165.0: 6016, 166.0: 5932, 168.0: 5884, 167.0: 5674, 169.0: 5606, 170.0: 5548, 171.0: 5474, 172.0: 5224, 174.0: 5186, 173.0: 5150, 175.0: 4980, 177.0: 4932, 176.0: 4818, 178.0: 4770, 179.0: 4648, 180.0: 4514, 182.0: 4502, 184.0: 4476, 181.0: 4462, 183.0: 4328, 186.0: 4274, 185.0: 4182, 187.0: 4008, 188.0: 4006, 191.0: 3856, 190.0: 3808, 189.0: 3784, 192.0: 3634, 193.0: 3594, 194.0: 3546, 195.0: 3534, 197.0: 3434, 196.0: 3416, 199.0: 3350, 198.0: 3222, 200.0: 3216, 201.0: 3074, 202.0: 3058, 203.0: 3016, 204.0: 2986, 205.0: 2978, 206.0: 2964, 208.0: 2958, 210.0: 2858, 207.0: 2808, 209.0: 2774, 211.0: 2692, 212.0: 2632, 214.0: 2626, 215.0: 2620, 213.0: 2536, 216.0: 2492, 218.0: 2464, 217.0: 2448, 219.0: 2386, 222.0: 2254, 224.0: 2250, 220.0: 2242, 225.0: 2186, 223.0: 2174, 221.0: 2174, 228.0: 2118, 226.0: 2078, 227.0: 2076, 229.0: 1956, 234.0: 1916, 233.0: 1898, 230.0: 1894, 232.0: 1880, 231.0: 1858, 235.0: 1834, 236.0: 1770, 239.0: 1764, 238.0: 1748, 237.0: 1744, 240.0: 1684, 241.0: 1674, 243.0: 1664, 244.0: 1604, 242.0: 1584, 245.0: 1548, 249.0: 1532, 247.0: 1530, 251.0: 1500, 248.0: 1476, 250.0: 1472, 246.0: 1468, 252.0: 1408, 253.0: 1406, 256.0: 1360, 259.0: 1346, 258.0: 1296, 254.0: 1292, 257.0: 1282, 261.0: 1240, 262.0: 1234, 260.0: 1232, 255.0: 1230, 266.0: 1214, 264.0: 1186, 265.0: 1180, 263.0: 1150, 267.0: 1146, 269.0: 1092, 268.0: 1080, 272.0: 1072, 271.0: 1068, 277.0: 1024, 270.0: 1018, 274.0: 1004, 275.0: 970, 276.0: 950, 273.0: 944, 279.0: 928, 281.0: 906, 283.0: 896, 278.0: 896, 282.0: 894, 280.0: 876, 284.0: 834, 286.0: 818, 285.0: 818, 287.0: 804, 289.0: 796, 288.0: 778, 295.0: 778, 296.0: 772, 291.0: 764, 297.0: 762, 293.0: 754, 294.0: 752, 292.0: 734, 290.0: 726, 299.0: 726, 304.0: 676, 311.0: 670, 303.0: 658, 305.0: 658, 307.0: 652, 298.0: 652, 300.0: 638, 301.0: 632, 302.0: 630, 308.0: 614, 306.0: 590, 315.0: 574, 317.0: 572, 313.0: 568, 310.0: 562, 312.0: 546, 314.0: 546, 309.0: 540, 319.0: 532, 323.0: 530, 316.0: 520, 326.0: 516, 321.0: 512, 320.0: 506, 318.0: 496, 322.0: 484, 330.0: 482, 329.0: 478, 327.0: 474, 332.0: 462, 331.0: 460, 324.0: 458, 325.0: 444, 334.0: 432, 335.0: 428, 344.0: 416, 342.0: 404, 333.0: 398, 348.0: 394, 343.0: 394, 337.0: 388, 328.0: 386, 346.0: 384, 340.0: 380, 351.0: 378, 350.0: 370, 341.0: 366, 336.0: 366, 345.0: 364, 347.0: 360, 352.0: 340, 358.0: 338, 353.0: 338, 338.0: 330, 355.0: 328, 339.0: 328, 367.0: 310, 354.0: 308, 365.0: 308, 372.0: 306, 349.0: 306, 360.0: 304, 356.0: 298, 363.0: 296, 359.0: 294, 361.0: 290, 364.0: 290, 366.0: 284, 371.0: 282, 362.0: 282, 370.0: 270, 357.0: 266, 368.0: 264, 379.0: 258, 378.0: 246, 373.0: 238, 369.0: 238, 374.0: 236, 375.0: 234, 380.0: 234, 384.0: 228, 381.0: 226, 376.0: 224, 377.0: 212, 393.0: 212, 383.0: 212, 391.0: 212, 388.0: 200, 386.0: 200, 392.0: 200, 389.0: 196, 394.0: 196, 382.0: 196, 387.0: 194, 390.0: 184, 399.0: 178, 385.0: 178, 400.0: 170, 404.0: 168, 408.0: 166, 396.0: 166, 397.0: 162, 403.0: 160, 407.0: 158, 402.0: 158, 395.0: 158, 411.0: 156, 416.0: 154, 417.0: 152, 420.0: 152, 401.0: 150, 398.0: 148, 414.0: 144, 413.0: 144, 405.0: 140, 409.0: 130, 418.0: 126, 412.0: 124, 433.0: 122, 406.0: 122, 439.0: 118, 415.0: 118, 426.0: 118, 432.0: 116, 425.0: 114, 410.0: 112, 424.0: 108, 428.0: 108, 419.0: 106, 422.0: 106, 444.0: 104, 443.0: 102, 430.0: 102, 423.0: 102, 434.0: 96, 449.0: 96, 427.0: 94, 435.0: 92, 436.0: 92, 437.0: 92, 454.0: 92, 441.0: 92, 421.0: 92, 442.0: 90, 440.0: 90, 446.0: 90, 457.0: 90, 448.0: 90, 438.0: 90, 447.0: 88, 445.0: 86, 429.0: 86, 459.0: 84, 431.0: 84, 462.0: 80, 451.0: 80, 453.0: 78, 461.0: 72, 470.0: 72, 467.0: 72, 463.0: 72, 477.0: 72, 455.0: 68, 473.0: 68, 469.0: 68, 450.0: 66, 458.0: 66, 460.0: 66, 466.0: 64, 476.0: 64, 456.0: 64, 472.0: 62, 499.0: 62, 468.0: 54, 452.0: 52, 483.0: 52, 482.0: 52, 486.0: 52, 464.0: 50, 489.0: 50, 484.0: 48, 474.0: 46, 491.0: 46, 481.0: 46, 478.0: 46, 465.0: 46, 485.0: 46, 480.0: 44, 495.0: 44, 475.0: 42, 471.0: 42, 500.0: 42, 490.0: 42, 502.0: 40, 497.0: 40, 479.0: 40, 498.0: 40, 510.0: 38, 488.0: 36, 492.0: 36, 493.0: 32, 507.0: 32, 511.0: 32, 509.0: 30, 496.0: 30, 519.0: 28, 501.0: 28, 494.0: 26, 505.0: 26, 506.0: 24, 525.0: 24, 514.0: 24, 529.0: 24, 503.0: 24, 487.0: 24, 527.0: 22, 522.0: 22, 538.0: 22, 504.0: 22, 512.0: 22, 518.0: 22, 535.0: 20, 515.0: 20, 513.0: 20, 528.0: 20, 517.0: 20, 523.0: 20, 537.0: 20, 521.0: 18, 545.0: 16, 533.0: 16, 543.0: 16, 531.0: 14, 524.0: 14, 562.0: 14, 520.0: 14, 508.0: 14, 561.0: 12, 516.0: 12, 530.0: 12, 557.0: 12, 572.0: 10, 548.0: 10, 532.0: 10, 549.0: 10, 534.0: 10, 550.0: 10, 580.0: 10, 556.0: 10, 553.0: 10, 552.0: 10, 564.0: 8, 544.0: 8, 541.0: 8, 536.0: 8, 526.0: 8, 542.0: 8, 558.0: 8, 566.0: 8, 563.0: 8, 560.0: 8, 555.0: 8, 578.0: 6, 581.0: 6, 587.0: 6, 610.0: 6, 588.0: 6, 606.0: 6, 539.0: 6, 554.0: 6, 547.0: 6, 567.0: 6, 593.0: 4, 616.0: 4, 583.0: 4, 602.0: 4, 604.0: 4, 577.0: 4, 571.0: 4, 540.0: 4, 573.0: 4, 575.0: 4, 570.0: 4, 591.0: 4, 584.0: 4, 627.0: 2, 586.0: 2, 699.0: 2, 614.0: 2, 582.0: 2, 595.0: 2, 617.0: 2, 546.0: 2, 638.0: 2, 635.0: 2, 569.0: 2, 594.0: 2, 596.0: 2, 612.0: 2, 576.0: 2, 649.0: 2, 636.0: 2, 669.0: 2, 608.0: 2, 592.0: 2, 565.0: 2, 651.0: 2, 597.0: 2, 629.0: 2, 615.0: 2})
446394290
Convert a graph into a bidirected graph: 43.496 seconds
Metis partitioning: 118.138 seconds
Split the graph: 10.965 seconds
Construct subgraphs: 0.050 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  172.84474515914917
15535
14683
15465
14679
14679
15346
15554
15417
15538
14679
14679
14810
15507
total k batches seeds list generation spend  338.45875000953674
after graph partition
graph partition algorithm spend time 342.23635721206665
15535
14683
15465
14679
14679
15346
15554
15417
15538
14679
14679
14810
15507
partition_len_list
[250525, 218761, 240284, 357779, 327164, 162884, 306261, 382378, 299054, 472135, 313977, 243864, 285129]
REG selection method  spend 343.30646324157715
time for parepare:  0.3911869525909424
local_output_nid generation:  0.007710933685302734
local_in_edges_tensor generation:  0.024395465850830078
mini_batch_src_global generation:  0.0716545581817627
r_  generation:  0.6344397068023682
local_output_nid generation:  0.006818532943725586
local_in_edges_tensor generation:  0.04329109191894531
mini_batch_src_global generation:  0.0951533317565918
r_  generation:  0.5800273418426514
local_output_nid generation:  0.007206439971923828
local_in_edges_tensor generation:  0.03791689872741699
mini_batch_src_global generation:  0.07567834854125977
r_  generation:  0.6279118061065674
local_output_nid generation:  0.006874799728393555
local_in_edges_tensor generation:  0.04046797752380371
mini_batch_src_global generation:  0.10769486427307129
r_  generation:  0.925950288772583
local_output_nid generation:  0.0068433284759521484
local_in_edges_tensor generation:  0.030088186264038086
mini_batch_src_global generation:  0.10182785987854004
r_  generation:  0.7312254905700684
local_output_nid generation:  0.007286787033081055
local_in_edges_tensor generation:  0.027475833892822266
mini_batch_src_global generation:  0.08844280242919922
r_  generation:  0.6452374458312988
local_output_nid generation:  0.0072786808013916016
local_in_edges_tensor generation:  0.026341676712036133
mini_batch_src_global generation:  0.07983183860778809
r_  generation:  0.6653563976287842
local_output_nid generation:  0.007314920425415039
local_in_edges_tensor generation:  0.028203964233398438
mini_batch_src_global generation:  0.11967921257019043
r_  generation:  0.9689621925354004
local_output_nid generation:  0.007264852523803711
local_in_edges_tensor generation:  0.03534269332885742
mini_batch_src_global generation:  0.11576294898986816
r_  generation:  0.9180119037628174
local_output_nid generation:  0.00685429573059082
local_in_edges_tensor generation:  0.0625312328338623
mini_batch_src_global generation:  0.10941219329833984
r_  generation:  0.9526054859161377
local_output_nid generation:  0.006812095642089844
local_in_edges_tensor generation:  0.048926591873168945
mini_batch_src_global generation:  0.10224604606628418
r_  generation:  0.8087096214294434
local_output_nid generation:  0.007161140441894531
local_in_edges_tensor generation:  0.04661750793457031
mini_batch_src_global generation:  0.10284733772277832
r_  generation:  0.7899770736694336
local_output_nid generation:  0.0073893070220947266
local_in_edges_tensor generation:  0.04981637001037598
mini_batch_src_global generation:  0.11206817626953125
r_  generation:  0.8304808139801025
----------------------check_connections_block total spend ----------------------------- 14.151206970214844
generate_one_block  1.756777286529541
generate_one_block  1.1860415935516357
generate_one_block  1.2376494407653809
generate_one_block  1.8689417839050293
generate_one_block  1.431469202041626
generate_one_block  1.156709909439087
generate_one_block  1.2695753574371338
generate_one_block  1.7836699485778809
generate_one_block  1.7025837898254395
generate_one_block  1.8718163967132568
generate_one_block  1.5490550994873047
generate_one_block  1.4521450996398926
generate_one_block  1.5217885971069336
----------===============-------------===============-------------the number of batches *****---- 13

original number of batches:  13
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1774888038635254  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

connection checking time:  14.151206970214844
block generation total time  19.78822350502014
average batch blocks generation time:  1.5221710388477032
block dataloader generation time/epoch 387.15623527765274
pseudo mini batch 0 input nodes size: 250525
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.135894775390625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.135894775390625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22922277450561523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2293386459350586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09746599197387695  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1141657829284668  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1141657829284668  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15535, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.029153823852539  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.032343864440918  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13097333908081055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 1 input nodes size: 218761
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09751558303833008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09751558303833008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17901086807250977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17912054061889648  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08567667007446289  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1004328727722168  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1004328727722168  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14683, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.527273654937744  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.529994487762451  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11509466171264648  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 2 input nodes size: 240284
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08552742004394531  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08552742004394531  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17504024505615234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1751556396484375  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0935506820678711  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10916662216186523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10916662216186523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15465, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.920506954193115  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.923215389251709  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12462854385375977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 3 input nodes size: 357779
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09368753433227539  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09368753433227539  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22697067260742188  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2270803451538086  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1374521255493164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1608896255493164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1608896255493164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.280642986297607  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.28322744369507  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18424415588378906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 4 input nodes size: 327164
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1373143196105957  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1373143196105957  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25919246673583984  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25930213928222656  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12590932846069336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14334726333618164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14334726333618164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.6216139793396  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.624184608459473  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16084003448486328  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 5 input nodes size: 162884
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12590932846069336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12590932846069336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18658876419067383  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18670320510864258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06471538543701172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08127689361572266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08127689361572266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15346, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.895139217376709  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.898169994354248  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09801244735717773  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 6 input nodes size: 306261
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06483221054077148  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06483221054077148  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1789236068725586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17903995513916016  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11824607849121094  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13382816314697266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13382816314697266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15554, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.97499132156372  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.977715492248535  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1491999626159668  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 7 input nodes size: 382378
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11828279495239258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11828279495239258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2607297897338867  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26084470748901367  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.146636962890625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16806983947753906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16806983947753906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15417, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.69044780731201  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.693147659301758  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18993425369262695  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 8 input nodes size: 299054
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14701080322265625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14701080322265625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25841712951660156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2585330009460449  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11597108840942383  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13933038711547852  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13933038711547852  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15538, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.718045234680176  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.72114324569702  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16244935989379883  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 9 input nodes size: 472135
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11559438705444336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11559438705444336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.29147863388061523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.29158830642700195  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18006610870361328  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20102882385253906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20102882385253906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.353206634521484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.35592794418335  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22189569473266602  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 10 input nodes size: 313977
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1799154281616211  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1799154281616211  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.29688119888305664  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.29699087142944336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12099695205688477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13935041427612305  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13935041427612305  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.2890625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.291633129119873  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1577587127685547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 11 input nodes size: 243864
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12099695205688477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12099695205688477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21279382705688477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2129044532775879  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09582901000976562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11453819274902344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11453819274902344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14810, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.558517932891846  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.56111192703247  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13332605361938477  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 12 input nodes size: 285129
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09585237503051758  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09585237503051758  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2020716667175293  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20218753814697266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11028003692626953  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12986326217651367  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12986326217651367  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15507, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.893630981445312  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.896686553955078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14917278289794922  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14917278289794922  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14917278289794922  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.17979996020977312 |0.0363160280080942 |18.068578298275288 |0.0001994463113638071 |36.787590100215034 |0.016407489776611328 |
----------------------------------------------------------pseudo_mini_loss sum 2.6220643520355225
Total (block generation + training)time/epoch 1099.9966037273407
Training time/epoch 717.527666091919
Training time without block to device /epoch 717.0555577278137
Training time without total dataloading part /epoch 713.1491894721985
load block tensor time/epoch 2.337399482727051
block to device time/epoch 0.4721083641052246
input features size transfer per epoch 1.7434358596801758e-06
blocks size to device per epoch 1.1622905731201172e-06
 Run 0| Epoch 3 |
Number of nodes for computation during this epoch:  3860195
Number of first layer input nodes during this epoch:  3860195
Number of first layer output nodes during this epoch:  196571
----------------------------------------before generate dataloader block 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14917230606079102  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 1.5248820781707764
global_2_local spend time (sec) 0.6653642654418945
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.3439624309539795
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1658284, 800: 3460, 77: 1190, 79: 1185, 81: 1185, 88: 1183, 84: 1177, 75: 1169, 78: 1169, 83: 1165, 85: 1164, 82: 1160, 67: 1158, 87: 1156, 91: 1154, 86: 1151, 76: 1145, 89: 1142, 92: 1119, 80: 1117, 90: 1108, 69: 1107, 93: 1088, 73: 1080, 71: 1080, 74: 1069, 94: 1069, 70: 1068, 68: 1053, 72: 1052, 99: 1042, 97: 1034, 96: 1020, 95: 1017, 102: 1006, 54: 996, 65: 994, 61: 981, 66: 977, 98: 963, 52: 959, 62: 959, 48: 958, 100: 957, 58: 957, 63: 955, 101: 954, 64: 953, 59: 950, 107: 949, 104: 947, 106: 945, 105: 942, 103: 939, 43: 933, 60: 930, 51: 928, 47: 927, 57: 923, 56: 913, 53: 907, 55: 907, 108: 898, 112: 887, 45: 884, 49: 879, 50: 877, 109: 867, 41: 861, 115: 857, 111: 853, 40: 852, 110: 850, 113: 848, 120: 844, 117: 838, 114: 835, 122: 825, 119: 816, 39: 816, 42: 813, 121: 810, 46: 807, 44: 806, 118: 798, 33: 793, 37: 791, 128: 782, 38: 775, 116: 775, 28: 768, 125: 756, 35: 754, 136: 752, 126: 747, 124: 744, 36: 741, 123: 741, 32: 727, 138: 722, 127: 722, 130: 716, 129: 711, 133: 706, 135: 704, 134: 703, 132: 702, 14: 695, 31: 691, 30: 689, 140: 689, 34: 677, 145: 673, 15: 673, 25: 671, 26: 659, 7: 655, 137: 654, 131: 654, 139: 654, 141: 652, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 150: 633, 143: 629, 11: 624, 144: 620, 142: 617, 13: 615, 16: 614, 148: 612, 147: 612, 146: 605, 18: 604, 149: 602, 22: 592, 155: 587, 21: 586, 19: 584, 12: 583, 154: 580, 152: 579, 151: 577, 157: 577, 9: 576, 153: 575, 20: 572, 17: 556, 6: 550, 159: 544, 156: 541, 158: 535, 164: 527, 160: 520, 8: 512, 165: 508, 169: 507, 161: 505, 172: 503, 163: 497, 166: 495, 170: 492, 168: 486, 162: 484, 171: 482, 167: 476, 177: 463, 4: 456, 179: 453, 180: 447, 175: 446, 5: 445, 182: 438, 181: 435, 173: 435, 185: 429, 176: 428, 184: 427, 174: 423, 178: 421, 199: 400, 187: 391, 188: 389, 186: 387, 190: 386, 193: 386, 192: 381, 189: 377, 191: 375, 3: 374, 183: 370, 196: 369, 195: 369, 208: 369, 194: 365, 198: 363, 204: 350, 209: 340, 203: 340, 197: 339, 200: 338, 207: 337, 202: 336, 206: 335, 201: 333, 213: 327, 214: 320, 211: 316, 224: 309, 231: 308, 216: 306, 215: 305, 219: 304, 205: 303, 218: 302, 210: 301, 221: 299, 228: 293, 212: 291, 217: 291, 225: 289, 222: 284, 220: 282, 223: 275, 226: 273, 233: 273, 230: 271, 239: 268, 227: 268, 244: 259, 238: 259, 234: 258, 249: 258, 237: 257, 229: 254, 240: 253, 235: 252, 246: 252, 232: 246, 236: 246, 247: 244, 241: 243, 245: 239, 242: 235, 257: 234, 243: 233, 250: 232, 255: 227, 2: 221, 248: 221, 252: 219, 264: 219, 254: 214, 259: 210, 267: 209, 268: 206, 251: 202, 253: 201, 258: 201, 266: 199, 260: 196, 269: 195, 265: 190, 273: 190, 270: 189, 263: 189, 278: 188, 277: 187, 262: 183, 276: 182, 282: 182, 261: 182, 256: 179, 274: 179, 285: 178, 272: 178, 271: 177, 299: 175, 280: 175, 284: 174, 1: 173, 290: 169, 291: 168, 295: 165, 303: 165, 287: 164, 279: 160, 288: 159, 286: 159, 315: 159, 298: 157, 294: 156, 300: 155, 292: 154, 297: 152, 283: 152, 301: 151, 302: 151, 289: 149, 305: 148, 306: 147, 281: 147, 275: 147, 293: 147, 307: 146, 312: 146, 311: 145, 316: 144, 313: 140, 310: 139, 296: 134, 304: 133, 309: 133, 318: 132, 320: 131, 314: 131, 308: 130, 319: 127, 332: 127, 342: 123, 328: 123, 326: 123, 321: 120, 323: 120, 333: 119, 322: 119, 317: 118, 344: 115, 327: 114, 351: 114, 340: 114, 324: 113, 331: 113, 336: 110, 325: 109, 355: 108, 349: 107, 329: 105, 341: 105, 365: 105, 353: 104, 345: 104, 339: 103, 338: 103, 330: 103, 359: 102, 357: 102, 334: 101, 362: 100, 378: 100, 381: 100, 383: 99, 348: 99, 371: 99, 337: 99, 380: 99, 356: 98, 360: 98, 350: 98, 354: 97, 370: 97, 363: 96, 343: 96, 372: 95, 385: 94, 335: 93, 347: 92, 376: 92, 374: 92, 352: 92, 361: 91, 375: 91, 373: 91, 368: 91, 346: 90, 366: 90, 393: 89, 369: 88, 364: 87, 384: 86, 377: 82, 386: 81, 390: 81, 395: 80, 387: 80, 398: 80, 416: 80, 392: 79, 397: 79, 389: 79, 407: 79, 358: 78, 382: 77, 419: 77, 421: 75, 418: 74, 402: 73, 400: 73, 367: 73, 429: 72, 450: 71, 417: 71, 401: 71, 408: 71, 379: 71, 394: 69, 406: 69, 431: 69, 405: 68, 453: 68, 388: 68, 427: 68, 391: 68, 410: 67, 409: 67, 404: 67, 399: 66, 411: 66, 467: 65, 440: 64, 433: 63, 446: 62, 412: 62, 413: 62, 447: 62, 396: 61, 434: 61, 426: 60, 475: 60, 425: 60, 451: 60, 424: 59, 432: 58, 430: 58, 454: 57, 415: 57, 420: 57, 464: 57, 428: 56, 460: 56, 484: 55, 423: 55, 441: 55, 435: 54, 462: 54, 461: 54, 514: 54, 444: 53, 445: 52, 468: 52, 403: 52, 481: 52, 443: 51, 448: 51, 439: 51, 459: 51, 422: 50, 476: 50, 437: 49, 507: 49, 436: 48, 465: 48, 498: 48, 472: 48, 442: 48, 438: 48, 473: 47, 458: 47, 478: 47, 480: 47, 469: 46, 489: 46, 494: 46, 456: 46, 455: 45, 477: 45, 479: 45, 487: 44, 519: 44, 491: 44, 414: 43, 510: 43, 500: 43, 483: 42, 534: 42, 457: 42, 471: 42, 518: 42, 470: 42, 553: 41, 526: 41, 516: 41, 463: 41, 564: 41, 486: 40, 499: 40, 536: 40, 511: 40, 540: 40, 517: 40, 521: 40, 495: 40, 520: 39, 541: 39, 502: 39, 449: 39, 466: 38, 482: 38, 505: 38, 538: 37, 524: 37, 513: 37, 535: 37, 503: 37, 452: 36, 603: 36, 532: 36, 506: 36, 598: 36, 550: 36, 555: 36, 474: 36, 497: 36, 530: 35, 554: 35, 563: 35, 527: 35, 504: 35, 490: 35, 565: 34, 512: 34, 537: 34, 551: 34, 492: 34, 556: 34, 531: 34, 515: 34, 595: 34, 493: 34, 488: 34, 533: 33, 528: 33, 548: 33, 559: 33, 496: 33, 557: 32, 545: 32, 612: 32, 523: 32, 501: 32, 542: 32, 546: 31, 525: 31, 485: 31, 588: 31, 624: 30, 606: 30, 529: 30, 577: 30, 600: 29, 508: 29, 509: 29, 604: 29, 575: 29, 585: 29, 617: 29, 579: 29, 543: 29, 566: 29, 586: 29, 539: 28, 636: 28, 552: 28, 522: 28, 569: 28, 602: 27, 570: 27, 580: 27, 601: 27, 642: 27, 558: 27, 589: 26, 561: 26, 596: 26, 547: 26, 726: 25, 576: 25, 571: 25, 613: 25, 549: 25, 592: 25, 560: 25, 582: 25, 584: 25, 616: 24, 620: 24, 568: 24, 581: 24, 626: 24, 678: 24, 666: 24, 597: 24, 625: 24, 544: 24, 594: 23, 638: 23, 574: 23, 665: 23, 634: 23, 628: 23, 631: 23, 614: 23, 629: 23, 562: 23, 573: 23, 619: 23, 737: 22, 654: 22, 641: 22, 578: 22, 702: 22, 609: 22, 658: 22, 615: 21, 650: 21, 669: 21, 607: 21, 667: 21, 679: 21, 623: 21, 643: 21, 591: 21, 587: 20, 627: 20, 646: 20, 567: 20, 645: 20, 608: 20, 676: 20, 583: 20, 772: 20, 653: 20, 711: 20, 686: 20, 647: 20, 671: 19, 649: 19, 731: 19, 611: 19, 651: 19, 724: 19, 655: 19, 648: 19, 751: 19, 572: 19, 618: 19, 610: 19, 688: 19, 590: 19, 719: 19, 635: 18, 599: 18, 681: 18, 664: 18, 663: 18, 639: 18, 673: 18, 687: 18, 695: 18, 740: 18, 769: 18, 630: 18, 661: 18, 644: 18, 709: 17, 621: 17, 715: 17, 708: 17, 680: 17, 763: 17, 720: 17, 698: 17, 700: 17, 710: 17, 697: 16, 714: 16, 682: 16, 730: 16, 670: 16, 738: 16, 716: 16, 674: 16, 652: 16, 712: 16, 660: 16, 727: 16, 784: 16, 593: 16, 745: 16, 734: 15, 692: 15, 684: 15, 605: 15, 672: 15, 668: 15, 699: 15, 757: 15, 633: 15, 683: 15, 785: 15, 739: 15, 755: 15, 689: 14, 675: 14, 662: 14, 792: 14, 637: 14, 705: 14, 659: 14, 729: 14, 632: 14, 728: 14, 732: 14, 722: 14, 685: 13, 725: 13, 756: 13, 735: 13, 721: 13, 640: 13, 717: 13, 768: 13, 760: 13, 677: 13, 766: 13, 775: 13, 754: 13, 797: 13, 788: 13, 780: 13, 622: 13, 690: 12, 691: 12, 656: 12, 657: 12, 791: 12, 733: 12, 693: 12, 713: 12, 749: 12, 701: 11, 742: 11, 776: 11, 758: 11, 782: 11, 703: 11, 798: 11, 706: 11, 752: 11, 762: 11, 741: 11, 759: 11, 750: 11, 765: 11, 736: 10, 694: 10, 723: 10, 767: 10, 790: 10, 777: 10, 773: 10, 779: 10, 799: 10, 743: 10, 744: 9, 778: 9, 718: 9, 781: 9, 696: 9, 704: 9, 774: 9, 783: 9, 770: 9, 771: 9, 707: 8, 794: 8, 764: 8, 786: 8, 796: 7, 753: 6, 787: 6, 793: 6, 746: 6, 789: 6, 795: 6, 747: 6, 761: 5, 748: 3})

A = g.adjacency_matrix() spent  0.48593688011169434
auxiliary_graph
Graph(num_nodes=1854855, num_edges=446551265,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.8912942409515381
remove nodes length  1658284

auxiliary_graph.remove_nodes spent  23.80733299255371
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=446551265,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  23.012852430343628

the counter of shared neighbor distribution
Counter({1.0: 248612262, 2.0: 67815508, 3.0: 33426854, 4.0: 20173806, 5.0: 13556930, 6.0: 9761844, 7.0: 7327604, 8.0: 5714734, 9.0: 4559014, 10.0: 3721650, 11.0: 3086768, 12.0: 2603508, 13.0: 2227450, 14.0: 1913100, 15.0: 1665302, 16.0: 1458414, 17.0: 1290362, 18.0: 1146506, 19.0: 1024248, 20.0: 919560, 21.0: 827098, 22.0: 747002, 23.0: 682432, 24.0: 621986, 25.0: 572956, 26.0: 523736, 27.0: 484766, 28.0: 450012, 29.0: 416348, 30.0: 388108, 31.0: 360528, 32.0: 338268, 33.0: 318660, 34.0: 298236, 35.0: 279532, 36.0: 263980, 37.0: 249394, 38.0: 237094, 39.0: 225952, 40.0: 212470, 41.0: 201434, 42.0: 193090, 43.0: 183928, 44.0: 175226, 45.0: 166618, 46.0: 158686, 47.0: 151154, 48.0: 145520, 49.0: 142998, 50.0: 134426, 51.0: 130144, 52.0: 124228, 53.0: 117882, 54.0: 113002, 55.0: 108340, 56.0: 103382, 57.0: 100030, 58.0: 96408, 59.0: 91928, 60.0: 88960, 61.0: 85272, 62.0: 82380, 63.0: 79976, 64.0: 75926, 65.0: 73936, 67.0: 72338, 66.0: 71576, 68.0: 66794, 69.0: 64740, 70.0: 62406, 71.0: 60146, 72.0: 58784, 73.0: 56320, 74.0: 54568, 75.0: 53452, 76.0: 51722, 77.0: 50260, 78.0: 46996, 79.0: 45882, 81.0: 44132, 80.0: 44080, 82.0: 42236, 83.0: 40900, 85.0: 39850, 84.0: 39734, 86.0: 37600, 87.0: 36514, 88.0: 35494, 89.0: 34094, 90.0: 33104, 91.0: 32242, 92.0: 31832, 93.0: 30596, 94.0: 29756, 95.0: 28884, 96.0: 28140, 97.0: 27906, 98.0: 26606, 99.0: 26524, 100.0: 25368, 101.0: 24616, 102.0: 24212, 103.0: 23750, 104.0: 22652, 106.0: 22092, 105.0: 22024, 107.0: 21216, 108.0: 20452, 109.0: 19978, 110.0: 19700, 111.0: 19254, 112.0: 18600, 113.0: 18352, 114.0: 17850, 115.0: 17312, 116.0: 16922, 117.0: 16526, 118.0: 16486, 120.0: 16292, 119.0: 15904, 121.0: 15102, 122.0: 14740, 123.0: 14182, 126.0: 13720, 124.0: 13714, 125.0: 13638, 127.0: 13268, 128.0: 12700, 129.0: 12436, 132.0: 12062, 131.0: 11936, 130.0: 11852, 134.0: 11488, 133.0: 11470, 135.0: 11436, 136.0: 10740, 137.0: 10648, 138.0: 10310, 141.0: 10172, 139.0: 9934, 140.0: 9678, 142.0: 9600, 143.0: 9376, 144.0: 9182, 145.0: 9044, 146.0: 8814, 148.0: 8614, 147.0: 8450, 149.0: 8408, 152.0: 8068, 150.0: 8004, 151.0: 7836, 153.0: 7364, 154.0: 7342, 156.0: 7294, 155.0: 7254, 157.0: 7184, 158.0: 6980, 159.0: 6834, 162.0: 6652, 161.0: 6550, 160.0: 6544, 163.0: 6422, 164.0: 6122, 166.0: 5972, 165.0: 5964, 168.0: 5878, 167.0: 5742, 169.0: 5688, 170.0: 5514, 171.0: 5388, 172.0: 5306, 174.0: 5146, 175.0: 5058, 173.0: 5056, 177.0: 4880, 176.0: 4796, 178.0: 4786, 179.0: 4630, 181.0: 4520, 182.0: 4488, 180.0: 4466, 183.0: 4410, 184.0: 4396, 186.0: 4268, 185.0: 4174, 187.0: 4074, 188.0: 4002, 189.0: 3874, 191.0: 3866, 190.0: 3800, 192.0: 3710, 193.0: 3572, 194.0: 3530, 195.0: 3516, 196.0: 3468, 197.0: 3388, 198.0: 3324, 199.0: 3278, 201.0: 3142, 200.0: 3126, 202.0: 3076, 203.0: 3068, 206.0: 2974, 204.0: 2898, 208.0: 2888, 205.0: 2862, 210.0: 2830, 207.0: 2812, 211.0: 2788, 209.0: 2758, 212.0: 2628, 214.0: 2608, 213.0: 2608, 217.0: 2526, 216.0: 2472, 215.0: 2466, 218.0: 2398, 220.0: 2346, 219.0: 2300, 224.0: 2272, 222.0: 2250, 221.0: 2232, 225.0: 2196, 223.0: 2164, 228.0: 2132, 227.0: 2024, 231.0: 1994, 226.0: 1976, 233.0: 1964, 229.0: 1944, 230.0: 1934, 232.0: 1856, 237.0: 1834, 234.0: 1800, 235.0: 1800, 239.0: 1784, 238.0: 1760, 236.0: 1742, 242.0: 1734, 243.0: 1692, 240.0: 1678, 241.0: 1670, 244.0: 1592, 251.0: 1576, 248.0: 1550, 249.0: 1546, 245.0: 1530, 246.0: 1482, 247.0: 1468, 253.0: 1444, 252.0: 1424, 250.0: 1418, 256.0: 1350, 255.0: 1312, 258.0: 1304, 254.0: 1272, 257.0: 1262, 259.0: 1254, 261.0: 1218, 260.0: 1218, 262.0: 1214, 266.0: 1178, 264.0: 1176, 269.0: 1172, 265.0: 1140, 268.0: 1116, 272.0: 1094, 271.0: 1070, 270.0: 1058, 267.0: 1054, 263.0: 1054, 274.0: 1000, 277.0: 988, 282.0: 950, 276.0: 942, 275.0: 942, 273.0: 938, 278.0: 928, 280.0: 920, 281.0: 914, 279.0: 908, 283.0: 902, 285.0: 840, 286.0: 810, 289.0: 798, 291.0: 790, 284.0: 790, 295.0: 784, 287.0: 782, 290.0: 762, 288.0: 760, 294.0: 756, 293.0: 752, 296.0: 752, 297.0: 748, 299.0: 748, 292.0: 706, 304.0: 692, 298.0: 690, 307.0: 676, 301.0: 662, 302.0: 642, 303.0: 642, 305.0: 630, 300.0: 630, 308.0: 618, 311.0: 608, 306.0: 604, 315.0: 602, 310.0: 594, 313.0: 578, 314.0: 552, 319.0: 546, 309.0: 542, 316.0: 528, 321.0: 526, 326.0: 524, 312.0: 518, 323.0: 514, 320.0: 512, 322.0: 494, 318.0: 488, 317.0: 488, 331.0: 482, 329.0: 476, 330.0: 476, 324.0: 462, 334.0: 456, 325.0: 450, 335.0: 436, 327.0: 432, 332.0: 432, 337.0: 410, 336.0: 408, 328.0: 406, 333.0: 400, 344.0: 388, 351.0: 384, 348.0: 380, 353.0: 376, 347.0: 376, 340.0: 376, 341.0: 372, 342.0: 372, 346.0: 366, 345.0: 366, 338.0: 358, 339.0: 344, 350.0: 334, 358.0: 332, 352.0: 330, 343.0: 328, 367.0: 322, 355.0: 320, 354.0: 318, 356.0: 316, 349.0: 308, 360.0: 304, 361.0: 298, 362.0: 296, 365.0: 290, 359.0: 284, 363.0: 284, 366.0: 276, 369.0: 272, 372.0: 270, 357.0: 270, 368.0: 264, 371.0: 256, 374.0: 254, 384.0: 250, 380.0: 242, 370.0: 242, 386.0: 242, 375.0: 240, 376.0: 238, 364.0: 236, 379.0: 234, 383.0: 232, 389.0: 230, 373.0: 228, 381.0: 226, 378.0: 222, 377.0: 220, 382.0: 212, 388.0: 210, 387.0: 210, 391.0: 196, 400.0: 192, 394.0: 184, 395.0: 182, 392.0: 180, 390.0: 180, 385.0: 176, 393.0: 174, 404.0: 172, 401.0: 166, 396.0: 166, 403.0: 166, 397.0: 164, 417.0: 164, 411.0: 162, 408.0: 158, 407.0: 152, 399.0: 152, 414.0: 150, 420.0: 148, 405.0: 144, 398.0: 144, 413.0: 140, 402.0: 138, 416.0: 134, 406.0: 134, 409.0: 128, 433.0: 128, 419.0: 126, 412.0: 124, 418.0: 124, 410.0: 122, 425.0: 118, 449.0: 116, 426.0: 114, 423.0: 112, 436.0: 112, 421.0: 110, 432.0: 110, 427.0: 108, 415.0: 104, 443.0: 104, 442.0: 102, 439.0: 102, 429.0: 100, 422.0: 98, 430.0: 96, 424.0: 94, 445.0: 94, 451.0: 94, 441.0: 92, 440.0: 92, 428.0: 92, 444.0: 90, 437.0: 90, 434.0: 88, 431.0: 88, 448.0: 88, 454.0: 86, 438.0: 84, 473.0: 84, 447.0: 82, 450.0: 78, 435.0: 76, 460.0: 76, 462.0: 76, 446.0: 74, 457.0: 74, 467.0: 72, 463.0: 72, 453.0: 72, 455.0: 72, 459.0: 68, 464.0: 68, 466.0: 66, 456.0: 66, 461.0: 64, 472.0: 64, 458.0: 60, 465.0: 60, 452.0: 58, 499.0: 58, 470.0: 58, 469.0: 58, 482.0: 58, 475.0: 56, 476.0: 56, 486.0: 56, 474.0: 54, 468.0: 52, 477.0: 52, 478.0: 50, 491.0: 48, 484.0: 46, 497.0: 46, 471.0: 46, 479.0: 44, 483.0: 44, 495.0: 40, 490.0: 40, 489.0: 40, 481.0: 40, 493.0: 38, 498.0: 38, 501.0: 38, 492.0: 38, 502.0: 36, 503.0: 36, 509.0: 34, 488.0: 34, 485.0: 34, 487.0: 34, 494.0: 32, 480.0: 30, 504.0: 30, 500.0: 28, 496.0: 28, 514.0: 28, 529.0: 26, 508.0: 26, 523.0: 26, 518.0: 26, 524.0: 24, 505.0: 24, 510.0: 24, 519.0: 22, 507.0: 22, 526.0: 22, 538.0: 22, 511.0: 20, 520.0: 18, 517.0: 18, 512.0: 18, 527.0: 18, 533.0: 18, 525.0: 18, 522.0: 16, 535.0: 16, 516.0: 16, 530.0: 16, 541.0: 16, 521.0: 16, 513.0: 16, 506.0: 16, 531.0: 16, 544.0: 14, 528.0: 14, 532.0: 14, 536.0: 14, 543.0: 14, 537.0: 12, 561.0: 12, 556.0: 12, 545.0: 12, 553.0: 12, 581.0: 10, 577.0: 10, 564.0: 10, 550.0: 10, 539.0: 10, 534.0: 10, 540.0: 10, 549.0: 10, 555.0: 8, 515.0: 8, 572.0: 8, 557.0: 8, 563.0: 8, 566.0: 8, 548.0: 8, 580.0: 8, 560.0: 8, 546.0: 6, 591.0: 6, 562.0: 6, 542.0: 6, 610.0: 6, 588.0: 6, 558.0: 6, 559.0: 6, 547.0: 6, 616.0: 4, 587.0: 4, 570.0: 4, 552.0: 4, 614.0: 4, 554.0: 4, 602.0: 4, 615.0: 4, 596.0: 4, 571.0: 4, 579.0: 4, 573.0: 4, 586.0: 4, 597.0: 4, 584.0: 4, 576.0: 4, 567.0: 2, 578.0: 2, 606.0: 2, 598.0: 2, 629.0: 2, 583.0: 2, 551.0: 2, 649.0: 2, 601.0: 2, 634.0: 2, 585.0: 2, 604.0: 2, 595.0: 2, 574.0: 2, 633.0: 2, 635.0: 2, 698.0: 2, 589.0: 2, 648.0: 2, 637.0: 2, 668.0: 2, 592.0: 2, 575.0: 2, 618.0: 2, 565.0: 2})
446354694
Convert a graph into a bidirected graph: 42.256 seconds
Metis partitioning: 118.325 seconds
Split the graph: 10.329 seconds
Construct subgraphs: 0.077 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  171.1863181591034
15513
15352
15563
14679
14680
15244
15419
15467
15142
15298
14679
14856
14679
total k batches seeds list generation spend  341.4876379966736
after graph partition
graph partition algorithm spend time 345.3149974346161
15513
15352
15563
14679
14680
15244
15419
15467
15142
15298
14679
14856
14679
partition_len_list
[234116, 222587, 253153, 320385, 336209, 163381, 363792, 331140, 307277, 256110, 450233, 372670, 314603]
REG selection method  spend 346.3455798625946
time for parepare:  0.3453710079193115
local_output_nid generation:  0.007714033126831055
local_in_edges_tensor generation:  0.03179621696472168
mini_batch_src_global generation:  0.07235956192016602
r_  generation:  0.6315958499908447
local_output_nid generation:  0.007246732711791992
local_in_edges_tensor generation:  0.03233003616333008
mini_batch_src_global generation:  0.08757257461547852
r_  generation:  0.6188795566558838
local_output_nid generation:  0.0073337554931640625
local_in_edges_tensor generation:  0.023316621780395508
mini_batch_src_global generation:  0.07622337341308594
r_  generation:  0.627051591873169
local_output_nid generation:  0.006867885589599609
local_in_edges_tensor generation:  0.02982640266418457
mini_batch_src_global generation:  0.1088876724243164
r_  generation:  0.916414737701416
local_output_nid generation:  0.0069065093994140625
local_in_edges_tensor generation:  0.025873422622680664
mini_batch_src_global generation:  0.09343171119689941
r_  generation:  0.7236385345458984
local_output_nid generation:  0.0073184967041015625
local_in_edges_tensor generation:  0.020438671112060547
mini_batch_src_global generation:  0.08373284339904785
r_  generation:  0.6567592620849609
local_output_nid generation:  0.00738525390625
local_in_edges_tensor generation:  0.02277231216430664
mini_batch_src_global generation:  0.08240985870361328
r_  generation:  0.7344276905059814
local_output_nid generation:  0.007325887680053711
local_in_edges_tensor generation:  0.07612109184265137
mini_batch_src_global generation:  0.11387038230895996
r_  generation:  0.89589524269104
local_output_nid generation:  0.007235050201416016
local_in_edges_tensor generation:  0.06759023666381836
mini_batch_src_global generation:  0.10467195510864258
r_  generation:  0.869173526763916
local_output_nid generation:  0.0073626041412353516
local_in_edges_tensor generation:  0.03875565528869629
mini_batch_src_global generation:  0.10465192794799805
r_  generation:  0.761547327041626
local_output_nid generation:  0.006947517395019531
local_in_edges_tensor generation:  0.03554272651672363
mini_batch_src_global generation:  0.09919953346252441
r_  generation:  0.8922722339630127
local_output_nid generation:  0.007178544998168945
local_in_edges_tensor generation:  0.04392552375793457
mini_batch_src_global generation:  0.11972737312316895
r_  generation:  0.9654910564422607
local_output_nid generation:  0.006887912750244141
local_in_edges_tensor generation:  0.027338027954101562
mini_batch_src_global generation:  0.10181140899658203
r_  generation:  0.855149507522583
----------------------check_connections_block total spend ----------------------------- 14.171234369277954
generate_one_block  1.8486969470977783
generate_one_block  1.2473185062408447
generate_one_block  1.220949649810791
generate_one_block  1.8274128437042236
generate_one_block  1.4319281578063965
generate_one_block  1.1416659355163574
generate_one_block  1.3824436664581299
generate_one_block  1.6477680206298828
generate_one_block  1.6096611022949219
generate_one_block  1.3746843338012695
generate_one_block  1.8307404518127441
generate_one_block  1.6903131008148193
generate_one_block  1.5195279121398926
----------===============-------------===============-------------the number of batches *****---- 13

original number of batches:  13
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14917230606079102  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

connection checking time:  14.171234369277954
block generation total time  19.77311062812805
average batch blocks generation time:  1.521008509856004
block dataloader generation time/epoch 390.0020038127899
pseudo mini batch 0 input nodes size: 234116
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11040067672729492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11040067672729492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1976161003112793  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19773197174072266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09139680862426758  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10800313949584961  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10800313949584961  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15513, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.942354202270508  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.945071697235107  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12467002868652344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 1 input nodes size: 222587
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0913991928100586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0913991928100586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17431974411010742  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17443418502807617  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08710289001464844  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10260677337646484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10260677337646484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15352, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.084738731384277  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.087455749511719  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11813974380493164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 2 input nodes size: 253153
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08707475662231445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08707475662231445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1813817024230957  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18149805068969727  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09846305847167969  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1136941909790039  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1136941909790039  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15563, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.897574424743652  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.900642395019531  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12902021408081055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 3 input nodes size: 320385
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09849977493286133  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09849977493286133  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21785259246826172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21796226501464844  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12353897094726562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14697647094726562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14697647094726562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.879032135009766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.881757736206055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17031383514404297  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 4 input nodes size: 336209
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12338399887084961  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12338399887084961  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24863195419311523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24874162673950195  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12927913665771484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14629459381103516  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14629459381103516  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14680, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.303914546966553  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.306485652923584  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16379880905151367  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 5 input nodes size: 163381
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1297130584716797  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1297130584716797  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19057750701904297  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19069147109985352  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06533384323120117  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0819401741027832  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0819401741027832  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15244, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.924292087554932  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.92729663848877  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09826898574829102  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 6 input nodes size: 363792
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06499910354614258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06499910354614258  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20052242279052734  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2006373405456543  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13965892791748047  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1557769775390625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1557769775390625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15419, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.637235641479492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 12.639935970306396  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17232799530029297  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 7 input nodes size: 331140
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14003419876098633  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14003419876098633  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2633938789367676  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26350927352905273  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12787103652954102  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14865827560424805  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14865827560424805  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15467, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.18261480331421  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.1856689453125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16916704177856445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 8 input nodes size: 307277
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1275348663330078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1275348663330078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2420048713684082  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24211788177490234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11864280700683594  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13988447189331055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13988447189331055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15142, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.816898345947266  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.819607257843018  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1602458953857422  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 9 input nodes size: 256110
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11858558654785156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11858558654785156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21399402618408203  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21410846710205078  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09952545166015625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11745262145996094  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11745262145996094  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15298, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.967578887939453  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.970258235931396  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13546466827392578  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 10 input nodes size: 450233
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09955310821533203  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09955310821533203  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26727819442749023  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26738786697387695  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17186498641967773  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19140005111694336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19140005111694336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.012358665466309  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.015038013458252  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2105417251586914  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 11 input nodes size: 372670
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17175626754760742  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17175626754760742  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.31058692932128906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.3106980323791504  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14286327362060547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16339969635009766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16339969635009766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14856, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.981459617614746  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.984061241149902  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1840229034423828  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 12 input nodes size: 314603
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14289426803588867  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14289426803588867  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26009321212768555  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.26020288467407227  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1212611198425293  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14069414138793945  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14069414138793945  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.110731601715088  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.113302230834961  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16015100479125977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16015100479125977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16015100479125977  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.1856508071605976 |0.041395334097055286 |17.993432466800396 |0.00019596173213078425 |36.60563111305237 |0.02835702896118164 |
----------------------------------------------------------pseudo_mini_loss sum 2.1641147136688232
Total (block generation + training)time/epoch 1103.1640394687652
Training time/epoch 714.448260307312
Training time without block to device /epoch 713.9101209640503
Training time without total dataloading part /epoch 709.8187310695648
load block tensor time/epoch 2.4134604930877686
block to device time/epoch 0.5381393432617188
input features size transfer per epoch 1.7434358596801758e-06
blocks size to device per epoch 1.1622905731201172e-06
 Run 0| Epoch 4 |
Number of nodes for computation during this epoch:  3925656
Number of first layer input nodes during this epoch:  3925656
Number of first layer output nodes during this epoch:  196571
----------------------------------------before generate dataloader block 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16015052795410156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 1.5502936840057373
global_2_local spend time (sec) 1.3881239891052246
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.33713245391845703
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1658041, 800: 3460, 77: 1190, 81: 1185, 79: 1185, 88: 1183, 84: 1177, 78: 1169, 75: 1169, 83: 1165, 85: 1164, 82: 1160, 67: 1158, 87: 1156, 91: 1154, 86: 1151, 76: 1145, 89: 1142, 92: 1119, 80: 1117, 90: 1108, 69: 1107, 93: 1088, 73: 1080, 71: 1080, 74: 1069, 94: 1069, 70: 1068, 68: 1053, 72: 1052, 99: 1042, 97: 1034, 96: 1020, 95: 1017, 102: 1006, 54: 996, 65: 994, 61: 981, 66: 977, 98: 963, 52: 959, 62: 959, 48: 958, 100: 957, 58: 957, 63: 955, 101: 954, 64: 953, 59: 950, 107: 949, 104: 947, 106: 945, 105: 942, 103: 939, 43: 933, 60: 930, 51: 928, 47: 927, 57: 923, 56: 913, 53: 907, 55: 907, 108: 898, 112: 887, 45: 884, 49: 879, 50: 877, 109: 867, 41: 861, 115: 857, 111: 853, 40: 852, 110: 850, 113: 848, 120: 844, 117: 838, 114: 835, 122: 825, 39: 816, 119: 816, 42: 813, 121: 810, 46: 807, 44: 806, 118: 798, 33: 793, 37: 791, 128: 782, 116: 775, 38: 775, 28: 768, 125: 756, 35: 754, 136: 752, 126: 747, 124: 744, 36: 741, 123: 741, 32: 727, 138: 722, 127: 722, 130: 716, 129: 711, 133: 706, 135: 704, 134: 703, 132: 702, 14: 695, 31: 691, 140: 689, 30: 689, 34: 677, 145: 673, 15: 673, 25: 671, 26: 659, 7: 655, 131: 654, 137: 654, 139: 654, 141: 652, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 150: 633, 143: 629, 11: 624, 144: 620, 142: 617, 13: 615, 16: 614, 148: 612, 147: 612, 146: 605, 18: 604, 149: 602, 22: 592, 155: 587, 21: 586, 19: 584, 12: 583, 154: 580, 152: 579, 151: 577, 157: 577, 9: 576, 153: 575, 20: 572, 17: 556, 6: 550, 159: 544, 156: 541, 158: 535, 164: 527, 160: 520, 8: 512, 165: 508, 169: 507, 161: 505, 172: 503, 163: 497, 166: 495, 170: 492, 168: 486, 162: 484, 171: 482, 167: 476, 177: 463, 4: 456, 179: 453, 180: 447, 175: 446, 5: 445, 182: 438, 173: 435, 181: 435, 185: 429, 176: 428, 184: 427, 174: 423, 178: 421, 199: 400, 187: 391, 188: 389, 186: 387, 193: 386, 190: 386, 192: 381, 189: 377, 191: 375, 3: 374, 183: 370, 208: 369, 195: 369, 196: 369, 194: 365, 198: 363, 204: 350, 209: 340, 203: 340, 197: 339, 200: 338, 207: 337, 202: 336, 206: 335, 201: 333, 213: 327, 214: 320, 211: 316, 224: 309, 231: 308, 216: 306, 215: 305, 219: 304, 205: 303, 218: 302, 210: 301, 221: 299, 228: 293, 212: 291, 217: 291, 225: 289, 222: 284, 220: 282, 223: 275, 226: 273, 233: 273, 230: 271, 239: 268, 227: 268, 244: 259, 238: 259, 249: 258, 234: 258, 237: 257, 229: 254, 240: 253, 235: 252, 246: 252, 232: 246, 236: 246, 247: 244, 241: 243, 245: 239, 242: 235, 257: 234, 243: 233, 250: 232, 255: 227, 2: 221, 248: 221, 252: 219, 264: 219, 254: 214, 259: 210, 267: 209, 268: 206, 251: 202, 258: 201, 253: 201, 266: 199, 260: 196, 269: 195, 273: 190, 265: 190, 263: 189, 270: 189, 278: 188, 277: 187, 262: 183, 282: 182, 261: 182, 276: 182, 274: 179, 256: 179, 272: 178, 285: 178, 271: 177, 280: 175, 299: 175, 284: 174, 1: 173, 290: 169, 291: 168, 295: 165, 303: 165, 287: 164, 279: 160, 315: 159, 286: 159, 288: 159, 298: 157, 294: 156, 300: 155, 292: 154, 297: 152, 283: 152, 301: 151, 302: 151, 289: 149, 305: 148, 293: 147, 306: 147, 281: 147, 275: 147, 312: 146, 307: 146, 311: 145, 316: 144, 313: 140, 310: 139, 296: 134, 304: 133, 309: 133, 318: 132, 314: 131, 320: 131, 308: 130, 319: 127, 332: 127, 326: 123, 342: 123, 328: 123, 321: 120, 323: 120, 322: 119, 333: 119, 317: 118, 344: 115, 340: 114, 351: 114, 327: 114, 324: 113, 331: 113, 336: 110, 325: 109, 355: 108, 349: 107, 329: 105, 341: 105, 365: 105, 345: 104, 353: 104, 330: 103, 339: 103, 338: 103, 359: 102, 357: 102, 334: 101, 381: 100, 378: 100, 362: 100, 383: 99, 380: 99, 337: 99, 348: 99, 371: 99, 360: 98, 356: 98, 350: 98, 370: 97, 354: 97, 363: 96, 343: 96, 372: 95, 385: 94, 335: 93, 374: 92, 376: 92, 352: 92, 347: 92, 373: 91, 361: 91, 375: 91, 368: 91, 366: 90, 346: 90, 393: 89, 369: 88, 364: 87, 384: 86, 377: 82, 386: 81, 390: 81, 398: 80, 416: 80, 395: 80, 387: 80, 397: 79, 392: 79, 389: 79, 407: 79, 358: 78, 382: 77, 419: 77, 421: 75, 418: 74, 400: 73, 367: 73, 402: 73, 429: 72, 450: 71, 417: 71, 379: 71, 401: 71, 408: 71, 406: 69, 431: 69, 394: 69, 388: 68, 453: 68, 391: 68, 405: 68, 427: 68, 409: 67, 410: 67, 404: 67, 399: 66, 411: 66, 467: 65, 440: 64, 433: 63, 446: 62, 447: 62, 413: 62, 412: 62, 396: 61, 434: 61, 425: 60, 451: 60, 426: 60, 475: 60, 424: 59, 432: 58, 430: 58, 420: 57, 454: 57, 415: 57, 464: 57, 460: 56, 428: 56, 441: 55, 484: 55, 423: 55, 514: 54, 461: 54, 462: 54, 435: 54, 444: 53, 403: 52, 445: 52, 481: 52, 468: 52, 443: 51, 459: 51, 448: 51, 439: 51, 476: 50, 422: 50, 437: 49, 507: 49, 465: 48, 498: 48, 472: 48, 438: 48, 436: 48, 442: 48, 480: 47, 478: 47, 473: 47, 458: 47, 489: 46, 494: 46, 456: 46, 469: 46, 477: 45, 455: 45, 479: 45, 487: 44, 491: 44, 519: 44, 510: 43, 500: 43, 414: 43, 534: 42, 471: 42, 470: 42, 518: 42, 457: 42, 483: 42, 463: 41, 564: 41, 553: 41, 516: 41, 526: 41, 486: 40, 517: 40, 499: 40, 511: 40, 495: 40, 536: 40, 540: 40, 521: 40, 502: 39, 541: 39, 520: 39, 449: 39, 505: 38, 466: 38, 482: 38, 524: 37, 513: 37, 535: 37, 538: 37, 503: 37, 497: 36, 532: 36, 555: 36, 598: 36, 550: 36, 452: 36, 506: 36, 474: 36, 603: 36, 527: 35, 554: 35, 490: 35, 530: 35, 504: 35, 563: 35, 565: 34, 512: 34, 531: 34, 515: 34, 556: 34, 488: 34, 492: 34, 537: 34, 551: 34, 493: 34, 595: 34, 533: 33, 548: 33, 528: 33, 559: 33, 496: 33, 557: 32, 523: 32, 542: 32, 545: 32, 501: 32, 612: 32, 485: 31, 525: 31, 588: 31, 546: 31, 577: 30, 606: 30, 624: 30, 529: 30, 543: 29, 604: 29, 600: 29, 509: 29, 617: 29, 579: 29, 508: 29, 575: 29, 585: 29, 586: 29, 566: 29, 569: 28, 522: 28, 539: 28, 552: 28, 636: 28, 601: 27, 602: 27, 642: 27, 580: 27, 570: 27, 558: 27, 561: 26, 589: 26, 596: 26, 547: 26, 613: 25, 584: 25, 560: 25, 726: 25, 571: 25, 576: 25, 592: 25, 582: 25, 549: 25, 620: 24, 597: 24, 666: 24, 625: 24, 568: 24, 581: 24, 626: 24, 678: 24, 616: 24, 544: 24, 638: 23, 574: 23, 614: 23, 631: 23, 594: 23, 562: 23, 573: 23, 628: 23, 629: 23, 634: 23, 665: 23, 619: 23, 654: 22, 658: 22, 641: 22, 578: 22, 737: 22, 702: 22, 609: 22, 679: 21, 591: 21, 643: 21, 607: 21, 667: 21, 623: 21, 669: 21, 615: 21, 650: 21, 587: 20, 647: 20, 653: 20, 772: 20, 711: 20, 567: 20, 608: 20, 645: 20, 686: 20, 583: 20, 676: 20, 627: 20, 646: 20, 610: 19, 751: 19, 651: 19, 724: 19, 648: 19, 688: 19, 649: 19, 655: 19, 719: 19, 611: 19, 618: 19, 572: 19, 731: 19, 590: 19, 671: 19, 673: 18, 599: 18, 695: 18, 630: 18, 740: 18, 663: 18, 769: 18, 635: 18, 681: 18, 639: 18, 661: 18, 644: 18, 687: 18, 664: 18, 715: 17, 698: 17, 621: 17, 709: 17, 710: 17, 720: 17, 700: 17, 763: 17, 680: 17, 708: 17, 730: 16, 697: 16, 593: 16, 674: 16, 712: 16, 652: 16, 727: 16, 714: 16, 682: 16, 670: 16, 660: 16, 716: 16, 738: 16, 784: 16, 745: 16, 785: 15, 668: 15, 672: 15, 683: 15, 734: 15, 739: 15, 699: 15, 684: 15, 692: 15, 633: 15, 605: 15, 757: 15, 755: 15, 662: 14, 792: 14, 659: 14, 732: 14, 729: 14, 675: 14, 632: 14, 637: 14, 689: 14, 728: 14, 722: 14, 705: 14, 780: 13, 735: 13, 717: 13, 622: 13, 760: 13, 721: 13, 640: 13, 797: 13, 788: 13, 677: 13, 725: 13, 766: 13, 775: 13, 685: 13, 756: 13, 754: 13, 768: 13, 733: 12, 690: 12, 691: 12, 713: 12, 749: 12, 791: 12, 656: 12, 693: 12, 657: 12, 750: 11, 782: 11, 742: 11, 706: 11, 762: 11, 752: 11, 765: 11, 741: 11, 703: 11, 798: 11, 701: 11, 758: 11, 759: 11, 776: 11, 790: 10, 723: 10, 694: 10, 743: 10, 799: 10, 777: 10, 773: 10, 767: 10, 779: 10, 736: 10, 783: 9, 770: 9, 744: 9, 704: 9, 774: 9, 718: 9, 696: 9, 778: 9, 781: 9, 771: 9, 786: 8, 764: 8, 707: 8, 794: 8, 796: 7, 747: 6, 789: 6, 746: 6, 795: 6, 793: 6, 753: 6, 787: 6, 761: 5, 748: 3})

A = g.adjacency_matrix() spent  0.6646993160247803
auxiliary_graph
Graph(num_nodes=1854612, num_edges=446581497,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.9082095623016357
remove nodes length  1658041

auxiliary_graph.remove_nodes spent  21.344157457351685
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=446581497,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  22.54627799987793

the counter of shared neighbor distribution
Counter({1.0: 248649502, 2.0: 67821260, 3.0: 33423848, 4.0: 20168588, 5.0: 13553352, 6.0: 9761920, 7.0: 7325730, 8.0: 5713762, 9.0: 4558934, 10.0: 3722482, 11.0: 3088422, 12.0: 2602312, 13.0: 2228148, 14.0: 1912742, 15.0: 1665966, 16.0: 1459572, 17.0: 1289304, 18.0: 1146604, 19.0: 1025228, 20.0: 919376, 21.0: 826644, 22.0: 747852, 23.0: 681944, 24.0: 621064, 25.0: 573196, 26.0: 524036, 27.0: 485670, 28.0: 450076, 29.0: 415000, 30.0: 388044, 31.0: 361216, 32.0: 338808, 33.0: 318294, 34.0: 297926, 35.0: 278820, 36.0: 264228, 37.0: 249098, 38.0: 237366, 39.0: 225770, 40.0: 213032, 41.0: 201408, 42.0: 192956, 43.0: 184154, 44.0: 175126, 45.0: 166390, 46.0: 158762, 47.0: 151172, 48.0: 145490, 49.0: 142780, 50.0: 133772, 51.0: 130290, 52.0: 124424, 53.0: 117754, 54.0: 113148, 55.0: 107904, 56.0: 103854, 57.0: 99812, 58.0: 96396, 59.0: 91936, 60.0: 89226, 61.0: 85374, 62.0: 82048, 63.0: 80078, 64.0: 75752, 65.0: 73684, 67.0: 72776, 66.0: 71640, 68.0: 66814, 69.0: 64666, 70.0: 62628, 71.0: 60222, 72.0: 58834, 73.0: 56352, 74.0: 54378, 75.0: 53454, 76.0: 51530, 77.0: 50288, 78.0: 47296, 79.0: 45610, 80.0: 44404, 81.0: 44104, 82.0: 42144, 83.0: 40846, 84.0: 40012, 85.0: 39784, 86.0: 37640, 87.0: 36510, 88.0: 35226, 89.0: 33930, 90.0: 33194, 91.0: 32240, 92.0: 31708, 93.0: 30504, 94.0: 29858, 95.0: 28948, 96.0: 28158, 97.0: 27702, 98.0: 26866, 99.0: 26302, 100.0: 25330, 101.0: 24660, 102.0: 24370, 103.0: 23766, 104.0: 22724, 105.0: 22104, 106.0: 22030, 107.0: 21174, 108.0: 20254, 109.0: 19832, 110.0: 19762, 111.0: 19204, 113.0: 18612, 112.0: 18580, 114.0: 17868, 115.0: 17150, 116.0: 16844, 117.0: 16666, 118.0: 16450, 120.0: 16304, 119.0: 15820, 121.0: 15132, 122.0: 14582, 123.0: 14376, 126.0: 13748, 124.0: 13690, 125.0: 13640, 127.0: 13226, 128.0: 12782, 129.0: 12518, 131.0: 11898, 132.0: 11862, 130.0: 11730, 134.0: 11640, 133.0: 11502, 135.0: 11420, 136.0: 10638, 137.0: 10630, 138.0: 10312, 141.0: 9970, 139.0: 9906, 140.0: 9750, 142.0: 9686, 143.0: 9372, 144.0: 9118, 145.0: 9096, 146.0: 8900, 147.0: 8464, 149.0: 8456, 148.0: 8422, 150.0: 8112, 152.0: 7934, 151.0: 7882, 153.0: 7532, 154.0: 7492, 156.0: 7362, 155.0: 7220, 157.0: 7164, 159.0: 6876, 158.0: 6850, 162.0: 6696, 160.0: 6616, 161.0: 6518, 163.0: 6396, 165.0: 6068, 164.0: 6006, 168.0: 5856, 166.0: 5840, 169.0: 5712, 167.0: 5688, 170.0: 5454, 171.0: 5432, 172.0: 5372, 174.0: 5108, 173.0: 5094, 175.0: 5018, 177.0: 4890, 178.0: 4830, 176.0: 4762, 179.0: 4716, 182.0: 4506, 181.0: 4474, 180.0: 4472, 184.0: 4442, 183.0: 4430, 186.0: 4182, 187.0: 4140, 185.0: 4136, 188.0: 3994, 191.0: 3922, 190.0: 3850, 189.0: 3800, 192.0: 3660, 195.0: 3604, 194.0: 3570, 193.0: 3466, 197.0: 3448, 196.0: 3396, 199.0: 3268, 198.0: 3260, 201.0: 3122, 200.0: 3108, 202.0: 3068, 206.0: 3032, 203.0: 2964, 208.0: 2910, 204.0: 2900, 205.0: 2880, 209.0: 2840, 207.0: 2820, 211.0: 2786, 210.0: 2774, 214.0: 2628, 212.0: 2604, 213.0: 2574, 217.0: 2488, 215.0: 2474, 216.0: 2472, 218.0: 2432, 219.0: 2328, 222.0: 2304, 220.0: 2288, 228.0: 2276, 224.0: 2248, 223.0: 2198, 221.0: 2190, 226.0: 2120, 225.0: 2098, 227.0: 2020, 229.0: 2020, 230.0: 1936, 231.0: 1922, 235.0: 1896, 233.0: 1884, 237.0: 1874, 232.0: 1836, 234.0: 1836, 239.0: 1806, 236.0: 1764, 240.0: 1700, 238.0: 1676, 242.0: 1674, 241.0: 1672, 243.0: 1662, 244.0: 1604, 245.0: 1572, 247.0: 1554, 249.0: 1536, 248.0: 1510, 251.0: 1486, 253.0: 1456, 250.0: 1444, 246.0: 1418, 256.0: 1408, 252.0: 1396, 257.0: 1280, 258.0: 1276, 255.0: 1264, 259.0: 1254, 260.0: 1252, 254.0: 1248, 262.0: 1246, 261.0: 1196, 266.0: 1164, 264.0: 1150, 263.0: 1146, 269.0: 1140, 268.0: 1126, 265.0: 1114, 267.0: 1070, 270.0: 1050, 275.0: 1038, 272.0: 1018, 271.0: 1016, 274.0: 992, 278.0: 972, 277.0: 962, 273.0: 944, 276.0: 940, 282.0: 922, 279.0: 918, 281.0: 908, 285.0: 890, 280.0: 884, 283.0: 860, 287.0: 832, 286.0: 826, 284.0: 802, 296.0: 786, 289.0: 784, 288.0: 762, 293.0: 760, 295.0: 758, 297.0: 756, 294.0: 748, 291.0: 746, 290.0: 730, 304.0: 714, 292.0: 700, 305.0: 686, 301.0: 676, 299.0: 676, 303.0: 652, 298.0: 652, 302.0: 640, 300.0: 634, 307.0: 630, 308.0: 626, 306.0: 598, 309.0: 596, 310.0: 588, 311.0: 586, 315.0: 574, 319.0: 566, 312.0: 552, 313.0: 550, 314.0: 544, 316.0: 544, 320.0: 540, 317.0: 526, 321.0: 524, 323.0: 516, 318.0: 508, 326.0: 508, 329.0: 500, 327.0: 492, 325.0: 486, 334.0: 460, 331.0: 458, 324.0: 452, 330.0: 450, 322.0: 448, 328.0: 446, 335.0: 436, 332.0: 436, 336.0: 410, 348.0: 408, 337.0: 394, 333.0: 392, 351.0: 386, 344.0: 384, 346.0: 378, 342.0: 376, 352.0: 374, 340.0: 370, 347.0: 356, 341.0: 354, 358.0: 350, 349.0: 350, 338.0: 348, 355.0: 336, 343.0: 330, 339.0: 328, 345.0: 324, 367.0: 318, 356.0: 316, 350.0: 316, 354.0: 314, 353.0: 310, 359.0: 304, 361.0: 300, 362.0: 298, 363.0: 296, 364.0: 292, 366.0: 292, 372.0: 280, 357.0: 280, 380.0: 270, 360.0: 266, 365.0: 262, 379.0: 260, 368.0: 260, 371.0: 258, 369.0: 254, 386.0: 252, 375.0: 244, 378.0: 236, 374.0: 236, 373.0: 234, 370.0: 224, 391.0: 220, 381.0: 220, 384.0: 216, 383.0: 216, 376.0: 216, 392.0: 210, 387.0: 210, 389.0: 204, 382.0: 200, 390.0: 198, 385.0: 192, 394.0: 190, 404.0: 188, 377.0: 186, 388.0: 184, 393.0: 180, 400.0: 180, 411.0: 176, 403.0: 168, 401.0: 168, 420.0: 168, 399.0: 164, 407.0: 158, 413.0: 152, 397.0: 152, 402.0: 148, 396.0: 148, 395.0: 146, 417.0: 146, 418.0: 144, 405.0: 140, 398.0: 140, 408.0: 140, 409.0: 136, 433.0: 134, 406.0: 134, 416.0: 130, 410.0: 124, 415.0: 122, 414.0: 120, 412.0: 120, 422.0: 116, 425.0: 112, 432.0: 112, 430.0: 112, 439.0: 110, 428.0: 110, 421.0: 108, 419.0: 108, 445.0: 108, 440.0: 108, 424.0: 106, 426.0: 106, 423.0: 102, 429.0: 102, 454.0: 100, 447.0: 100, 441.0: 100, 431.0: 98, 427.0: 94, 444.0: 92, 436.0: 92, 462.0: 90, 459.0: 90, 451.0: 88, 442.0: 86, 443.0: 86, 438.0: 84, 463.0: 84, 435.0: 82, 437.0: 82, 457.0: 80, 473.0: 80, 434.0: 80, 467.0: 80, 460.0: 76, 453.0: 74, 449.0: 72, 448.0: 72, 456.0: 70, 446.0: 68, 477.0: 68, 461.0: 66, 465.0: 64, 458.0: 64, 452.0: 64, 464.0: 64, 472.0: 62, 469.0: 62, 468.0: 60, 450.0: 60, 482.0: 56, 476.0: 56, 470.0: 54, 479.0: 54, 499.0: 54, 475.0: 52, 497.0: 50, 466.0: 50, 484.0: 50, 478.0: 50, 485.0: 50, 455.0: 48, 474.0: 48, 471.0: 48, 481.0: 46, 489.0: 44, 502.0: 44, 488.0: 42, 486.0: 42, 496.0: 42, 483.0: 40, 493.0: 40, 491.0: 40, 487.0: 38, 490.0: 38, 498.0: 36, 500.0: 34, 494.0: 34, 505.0: 32, 507.0: 32, 495.0: 30, 509.0: 30, 510.0: 28, 492.0: 28, 521.0: 28, 504.0: 26, 480.0: 26, 506.0: 26, 524.0: 26, 515.0: 26, 501.0: 24, 527.0: 24, 513.0: 22, 503.0: 22, 511.0: 22, 520.0: 22, 516.0: 22, 517.0: 20, 541.0: 20, 525.0: 20, 508.0: 20, 538.0: 20, 529.0: 20, 512.0: 18, 518.0: 18, 523.0: 18, 537.0: 18, 531.0: 18, 519.0: 18, 550.0: 16, 528.0: 14, 532.0: 14, 514.0: 14, 549.0: 14, 530.0: 14, 540.0: 14, 561.0: 12, 522.0: 12, 581.0: 12, 562.0: 12, 580.0: 12, 591.0: 12, 534.0: 12, 543.0: 12, 535.0: 12, 548.0: 10, 556.0: 10, 558.0: 10, 536.0: 10, 557.0: 10, 533.0: 10, 539.0: 10, 553.0: 8, 544.0: 8, 555.0: 8, 547.0: 8, 564.0: 8, 565.0: 8, 577.0: 6, 542.0: 6, 586.0: 6, 526.0: 6, 574.0: 6, 566.0: 6, 552.0: 6, 575.0: 6, 610.0: 6, 583.0: 4, 563.0: 4, 600.0: 4, 572.0: 4, 596.0: 4, 567.0: 4, 560.0: 4, 614.0: 4, 615.0: 4, 649.0: 4, 616.0: 4, 545.0: 4, 604.0: 2, 584.0: 2, 570.0: 2, 592.0: 2, 636.0: 2, 597.0: 2, 582.0: 2, 607.0: 2, 551.0: 2, 546.0: 2, 571.0: 2, 628.0: 2, 559.0: 2, 585.0: 2, 568.0: 2, 576.0: 2, 587.0: 2, 602.0: 2, 630.0: 2, 578.0: 2, 641.0: 2, 588.0: 2, 569.0: 2, 573.0: 2, 579.0: 2, 598.0: 2, 608.0: 2, 625.0: 2, 554.0: 2, 668.0: 2, 601.0: 2, 698.0: 2})
446384926
Convert a graph into a bidirected graph: 42.337 seconds
Metis partitioning: 117.482 seconds
Split the graph: 10.269 seconds
Construct subgraphs: 0.058 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  170.34264373779297
14679
15574
14679
14909
15463
15548
15118
15556
15407
14679
14679
14981
15299
total k batches seeds list generation spend  334.4750986099243
after graph partition
graph partition algorithm spend time 338.3562309741974
14679
15574
14679
14909
15463
15548
15118
15556
15407
14679
14679
14981
15299
partition_len_list
[348100, 166969, 325579, 238624, 289888, 214337, 367700, 302753, 371009, 276712, 416490, 389644, 350259]
REG selection method  spend 340.11702013015747
time for parepare:  0.38229823112487793
local_output_nid generation:  0.006938457489013672
local_in_edges_tensor generation:  0.03571605682373047
mini_batch_src_global generation:  0.10537362098693848
r_  generation:  0.884451150894165
local_output_nid generation:  0.008010149002075195
local_in_edges_tensor generation:  0.032730817794799805
mini_batch_src_global generation:  0.09255385398864746
r_  generation:  0.6409897804260254
local_output_nid generation:  0.00683903694152832
local_in_edges_tensor generation:  0.028293371200561523
mini_batch_src_global generation:  0.09058833122253418
r_  generation:  0.7141542434692383
local_output_nid generation:  0.007743358612060547
local_in_edges_tensor generation:  0.01884627342224121
mini_batch_src_global generation:  0.07843756675720215
r_  generation:  0.6139945983886719
local_output_nid generation:  0.0074617862701416016
local_in_edges_tensor generation:  0.021676063537597656
mini_batch_src_global generation:  0.08460760116577148
r_  generation:  0.7372901439666748
local_output_nid generation:  0.0074994564056396484
local_in_edges_tensor generation:  0.020933151245117188
mini_batch_src_global generation:  0.08382010459899902
r_  generation:  0.6583225727081299
local_output_nid generation:  0.008404016494750977
local_in_edges_tensor generation:  0.03138327598571777
mini_batch_src_global generation:  0.08051061630249023
r_  generation:  0.7066450119018555
local_output_nid generation:  0.007372617721557617
local_in_edges_tensor generation:  0.0596776008605957
mini_batch_src_global generation:  0.11263418197631836
r_  generation:  0.9061357975006104
local_output_nid generation:  0.007264375686645508
local_in_edges_tensor generation:  0.04864621162414551
mini_batch_src_global generation:  0.11087775230407715
r_  generation:  0.989539384841919
local_output_nid generation:  0.006915092468261719
local_in_edges_tensor generation:  0.03489065170288086
mini_batch_src_global generation:  0.10345125198364258
r_  generation:  0.7770123481750488
local_output_nid generation:  0.006917476654052734
local_in_edges_tensor generation:  0.032018423080444336
mini_batch_src_global generation:  0.09681153297424316
r_  generation:  0.8645145893096924
local_output_nid generation:  0.007268190383911133
local_in_edges_tensor generation:  0.0341486930847168
mini_batch_src_global generation:  0.11010432243347168
r_  generation:  0.9895634651184082
local_output_nid generation:  0.007464408874511719
local_in_edges_tensor generation:  0.04775500297546387
mini_batch_src_global generation:  0.12285876274108887
r_  generation:  0.9916231632232666
----------------------check_connections_block total spend ----------------------------- 14.550800085067749
generate_one_block  2.4629411697387695
generate_one_block  1.2323646545410156
generate_one_block  1.470320463180542
generate_one_block  1.1784765720367432
generate_one_block  1.3786396980285645
generate_one_block  1.1857831478118896
generate_one_block  1.3384654521942139
generate_one_block  1.6614415645599365
generate_one_block  1.7896225452423096
generate_one_block  1.4153051376342773
generate_one_block  1.645829439163208
generate_one_block  1.673553466796875
generate_one_block  1.6767380237579346
----------===============-------------===============-------------the number of batches *****---- 13

original number of batches:  13
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16015052795410156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

connection checking time:  14.550800085067749
block generation total time  20.10948133468628
average batch blocks generation time:  1.5468831795912523
block dataloader generation time/epoch 390.94556963443756
pseudo mini batch 0 input nodes size: 348100
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12122917175292969  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12122917175292969  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25090694427490234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25101661682128906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13370800018310547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15714550018310547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15714550018310547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.873952865600586  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 17.87702703475952  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18063879013061523  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 1 input nodes size: 166969
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13370895385742188  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13370895385742188  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19590997695922852  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19602632522583008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0662388801574707  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08299589157104492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08299589157104492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15574, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.040144443511963  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.042871952056885  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09996795654296875  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 2 input nodes size: 325579
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06639575958251953  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.06639575958251953  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1876835823059082  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18779325485229492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12547588348388672  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14324140548706055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14324140548706055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.655855178833008  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.65858268737793  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16061067581176758  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 3 input nodes size: 238624
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1253190040588379  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1253190040588379  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.21421337127685547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2143244743347168  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.0929269790649414  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1074066162109375  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1074066162109375  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14909, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.28610897064209  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.28872013092041  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.12198257446289062  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 4 input nodes size: 289888
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09296751022338867  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09296751022338867  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2009592056274414  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.20107460021972656  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11206912994384766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1289215087890625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1289215087890625  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15463, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.17784833908081  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.180902004241943  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14592838287353516  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 5 input nodes size: 214337
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11216592788696289  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11216592788696289  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19201278686523438  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.19212865829467773  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08402156829833984  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09934425354003906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.09934425354003906  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15548, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.933579444885254  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.936302661895752  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11474037170410156  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 6 input nodes size: 367700
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08403682708740234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.08403682708740234  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.22101593017578125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2211289405822754  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14116621017456055  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1564030647277832  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1564030647277832  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15118, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.959872245788574  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 11.962595462799072  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17162132263183594  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 7 input nodes size: 302753
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14109086990356445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14109086990356445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2538752555847168  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25399160385131836  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11689949035644531  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1378774642944336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1378774642944336  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15556, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.282373428344727  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.28509759902954  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15898990631103516  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 8 input nodes size: 371009
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11697578430175781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.11697578430175781  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2551875114440918  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.25530242919921875  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14240169525146484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16583919525146484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16583919525146484  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15407, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.851773738861084  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.85481595993042  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18930864334106445  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 9 input nodes size: 276712
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14237594604492188  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14237594604492188  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24545955657958984  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.24556922912597656  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10724258422851562  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1249542236328125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1249542236328125  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.807933807373047  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 13.810632228851318  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14278793334960938  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 10 input nodes size: 416490
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10730981826782227  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.10730981826782227  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2624645233154297  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2625741958618164  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15938091278076172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17747020721435547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17747020721435547  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14679, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.138875961303711  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 14.141446590423584  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1954193115234375  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 11 input nodes size: 389644
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15918588638305664  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.15918588638305664  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.3043398857116699  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.30445194244384766  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14918756484985352  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16939401626586914  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.16939401626586914  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([14981, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.728711605072021  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 15.731363773345947  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.18970966339111328  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

pseudo mini batch 12 input nodes size: 350259
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14924049377441406  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.14924049377441406  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.2797222137451172  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.27983665466308594  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.13457059860229492  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1551680564880371  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.1551680564880371  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

torch.Size([15299, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.01656198501587  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 16.019336700439453  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17587852478027344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17587852478027344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.3690185546875 GB
    Memory Allocated: 0.17587852478027344  GigaBytes
Max Memory Allocated: 20.05219268798828  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.1582647653726431 |0.03330324246333195 |18.137546282548172 |0.00020047334524301381 |36.46486032926119 |0.018581390380859375 |
----------------------------------------------------------pseudo_mini_loss sum 1.8116858005523682
Total (block generation + training)time/epoch 1104.2022417783737
Training time/epoch 713.7294750213623
Training time without block to device /epoch 713.296532869339
Training time without total dataloading part /epoch 709.8524734973907
load block tensor time/epoch 2.0574419498443604
block to device time/epoch 0.43294215202331543
input features size transfer per epoch 1.7434358596801758e-06
blocks size to device per epoch 1.1622905731201172e-06
 Run 0| Epoch 5 |
Number of nodes for computation during this epoch:  4058064
Number of first layer input nodes during this epoch:  4058064
Number of first layer output nodes during this epoch:  196571
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(100, 100, batch_first=True)
      (fc_self): Linear(in_features=100, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  90200
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([400, 100])
layers.0.lstm.weight_hh_l0, torch.Size([400, 100])
layers.0.lstm.bias_ih_l0, torch.Size([400])
layers.0.lstm.bias_hh_l0, torch.Size([400])
layers.0.fc_self.weight, torch.Size([47, 100])
layers.0.fc_neigh.weight, torch.Size([47, 100])
----------------------------------------
un-trainable parameters
