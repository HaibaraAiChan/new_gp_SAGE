main start at this time 1656028301.2487805
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 0.14130210876464844
global_2_local spend time (sec) 0.35916686058044434
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.020301342010498047
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 922590, 20: 186421, 14: 695, 15: 673, 7: 655, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 19: 584, 12: 583, 9: 576, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.06392931938171387
auxiliary_graph
Graph(num_nodes=1119161, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.5425360202789307
remove nodes length  922590

auxiliary_graph.remove_nodes spent  2.193176746368408
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  1.483154058456421

the counter of shared neighbor distribution
Counter({1.0: 31135406, 2.0: 3552592, 3.0: 936932, 4.0: 353502, 5.0: 159904, 6.0: 75186, 7.0: 40668, 8.0: 21746, 9.0: 14870, 10.0: 9568, 11.0: 6274, 12.0: 4756, 15.0: 4752, 14.0: 4072, 13.0: 3450, 18.0: 2810, 16.0: 2680, 17.0: 1584, 19.0: 1406, 20.0: 1276})
36333434
Convert a graph into a bidirected graph: 2.005 seconds
Metis partitioning: 8.517 seconds
Split the graph: 4.752 seconds
Construct subgraphs: 0.052 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  15.343353033065796
98160
98411
total k batches seeds list generation spend  26.812222003936768
after graph partition
graph partition algorithm spend time 27.526707410812378
98160
98411
partition_len_list
[614301, 566354]
REG selection method  spend 28.130026817321777
time for parepare:  0.23830628395080566
local_output_nid generation:  0.013802289962768555
local_in_edges_tensor generation:  0.03963947296142578
mini_batch_src_global generation:  0.061158180236816406
r_  generation:  0.9123804569244385
local_output_nid generation:  0.01842188835144043
local_in_edges_tensor generation:  0.04719686508178711
mini_batch_src_global generation:  0.07615971565246582
r_  generation:  0.9681267738342285
----------------------check_connections_block total spend ----------------------------- 2.745210886001587
generate_one_block  2.558832883834839
generate_one_block  1.0985033512115479
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

connection checking time:  2.745210886001587
block generation total time  3.6573362350463867
average batch blocks generation time:  1.8286681175231934
block dataloader generation time/epoch 35.22057580947876
pseudo mini batch 0 input nodes size: 614301
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.2479248046875 GB
    Memory Allocated: 0.22918272018432617  GigaBytes
Max Memory Allocated: 0.22918272018432617  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.2479248046875 GB
    Memory Allocated: 0.22991418838500977  GigaBytes
Max Memory Allocated: 0.22991418838500977  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.2479248046875 GB
    Memory Allocated: 0.22991418838500977  GigaBytes
Max Memory Allocated: 0.22991418838500977  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.24420595169067383  GigaBytes
Max Memory Allocated: 0.24420595169067383  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.24420595169067383  GigaBytes
Max Memory Allocated: 0.24420595169067383  GigaBytes

torch.Size([98160, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 11.183269500732422  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 11.200457572937012  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.27638912200927734  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

pseudo mini batch 1 input nodes size: 566354
----------------------------------------before load block subtensor 
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.24743986129760742  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.24743986129760742  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.4584236145019531  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.45915699005126953  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.22958040237426758  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.24390459060668945  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 13.8162841796875 GB
    Memory Allocated: 0.24390459060668945  GigaBytes
Max Memory Allocated: 12.557976245880127  GigaBytes

torch.Size([98411, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.5428466796875 GB
    Memory Allocated: 11.18207836151123  GigaBytes
Max Memory Allocated: 12.57838487625122  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.5428466796875 GB
    Memory Allocated: 11.199309825897217  GigaBytes
Max Memory Allocated: 12.57838487625122  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.5428466796875 GB
    Memory Allocated: 0.2586393356323242  GigaBytes
Max Memory Allocated: 12.57838487625122  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.5428466796875 GB
    Memory Allocated: 0.25931453704833984  GigaBytes
Max Memory Allocated: 12.57838487625122  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.5428466796875 GB
    Memory Allocated: 0.25931453704833984  GigaBytes
Max Memory Allocated: 12.57838487625122  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.12449705600738525 |0.16540169715881348 |0.320125937461853 |0.00022470951080322266 |0.13313722610473633 |0.007155179977416992 |
----------------------------------------------------------pseudo_mini_loss sum 4.7910614013671875
Total (block generation + training)time/epoch 36.72364616394043
Training time/epoch 1.5027658939361572
Training time without block to device /epoch 1.1719624996185303
Training time without total dataloading part /epoch 0.9141309261322021
load block tensor time/epoch 0.2489941120147705
block to device time/epoch 0.33080339431762695
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1180655
Number of first layer input nodes during this epoch:  1180655
Number of first layer output nodes during this epoch:  196571
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(100, 100, batch_first=True)
      (fc_self): Linear(in_features=100, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  90200
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([400, 100])
layers.0.lstm.weight_hh_l0, torch.Size([400, 100])
layers.0.lstm.bias_ih_l0, torch.Size([400])
layers.0.lstm.bias_hh_l0, torch.Size([400])
layers.0.fc_self.weight, torch.Size([47, 100])
layers.0.fc_neigh.weight, torch.Size([47, 100])
----------------------------------------
un-trainable parameters
