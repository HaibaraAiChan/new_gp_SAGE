main start at this time 1656028621.940609
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 0.276456356048584
global_2_local spend time (sec) 0.36451220512390137
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.02724933624267578
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 922590, 20: 186421, 14: 695, 15: 673, 7: 655, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 19: 584, 12: 583, 9: 576, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.07233309745788574
auxiliary_graph
Graph(num_nodes=1119161, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.5511736869812012
remove nodes length  922590

auxiliary_graph.remove_nodes spent  2.235976457595825
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  1.4917027950286865

the counter of shared neighbor distribution
Counter({1.0: 31135406, 2.0: 3552592, 3.0: 936932, 4.0: 353502, 5.0: 159904, 6.0: 75186, 7.0: 40668, 8.0: 21746, 9.0: 14870, 10.0: 9568, 11.0: 6274, 12.0: 4756, 15.0: 4752, 14.0: 4072, 13.0: 3450, 18.0: 2810, 16.0: 2680, 17.0: 1584, 19.0: 1406, 20.0: 1276})
36333434
Convert a graph into a bidirected graph: 2.022 seconds
Metis partitioning: 8.580 seconds
Split the graph: 1.674 seconds
Construct subgraphs: 0.058 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  12.350285053253174
38199
39599
40147
38184
40442
total k batches seeds list generation spend  24.38825559616089
after graph partition
graph partition algorithm spend time 24.974653244018555
38199
39599
40147
38184
40442
partition_len_list
[236455, 244972, 289868, 301281, 284829]
REG selection method  spend 25.583889961242676
time for parepare:  0.23972177505493164
local_output_nid generation:  0.0071563720703125
local_in_edges_tensor generation:  0.008866071701049805
mini_batch_src_global generation:  0.025345563888549805
r_  generation:  0.27759790420532227
local_output_nid generation:  0.00829172134399414
local_in_edges_tensor generation:  0.02217864990234375
mini_batch_src_global generation:  0.03398299217224121
r_  generation:  0.3438985347747803
local_output_nid generation:  0.01188206672668457
local_in_edges_tensor generation:  0.02603435516357422
mini_batch_src_global generation:  0.032036542892456055
r_  generation:  0.36337709426879883
local_output_nid generation:  0.008196592330932617
local_in_edges_tensor generation:  0.011779069900512695
mini_batch_src_global generation:  0.030464649200439453
r_  generation:  0.33671021461486816
local_output_nid generation:  0.008455514907836914
local_in_edges_tensor generation:  0.011444330215454102
mini_batch_src_global generation:  0.03492021560668945
r_  generation:  0.41446566581726074
----------------------check_connections_block total spend ----------------------------- 2.616316556930542
generate_one_block  1.8529047966003418
generate_one_block  0.3962376117706299
generate_one_block  0.4290158748626709
generate_one_block  0.40279436111450195
generate_one_block  0.4344627857208252
----------===============-------------===============-------------the number of batches *****---- 5

original number of batches:  5
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

connection checking time:  2.616316556930542
block generation total time  3.5154154300689697
average batch blocks generation time:  0.703083086013794
block dataloader generation time/epoch 32.23888111114502
pseudo mini batch 0 input nodes size: 236455
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.0884242057800293  GigaBytes
Max Memory Allocated: 0.0884242057800293  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.08870887756347656  GigaBytes
Max Memory Allocated: 0.08870887756347656  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.08870887756347656  GigaBytes
Max Memory Allocated: 0.08870887756347656  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1912841796875 GB
    Memory Allocated: 0.09421634674072266  GigaBytes
Max Memory Allocated: 0.09421634674072266  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1912841796875 GB
    Memory Allocated: 0.09421634674072266  GigaBytes
Max Memory Allocated: 0.09421634674072266  GigaBytes

torch.Size([38199, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 4.319255352020264  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 4.325944900512695  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.10689353942871094  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

pseudo mini batch 1 input nodes size: 244972
----------------------------------------before load block subtensor 
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.09573602676391602  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.09573602676391602  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.1869955062866211  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.18729066848754883  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.09891939163208008  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.10468626022338867  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.1541748046875 GB
    Memory Allocated: 0.10468626022338867  GigaBytes
Max Memory Allocated: 4.847469329833984  GigaBytes

torch.Size([39599, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 4.538783550262451  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 4.545717716217041  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.11084604263305664  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

pseudo mini batch 2 input nodes size: 289868
----------------------------------------before load block subtensor 
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.09916448593139648  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.09916448593139648  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.20714902877807617  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.20744848251342773  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.11589384078979492  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.12263202667236328  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 9.7244873046875 GB
    Memory Allocated: 0.12263202667236328  GigaBytes
Max Memory Allocated: 5.100363731384277  GigaBytes

torch.Size([40147, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 4.613153457641602  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 4.62018346786499  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.12915754318237305  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

pseudo mini batch 3 input nodes size: 301281
----------------------------------------before load block subtensor 
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.11638069152832031  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.11638069152832031  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.22861671447753906  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.22890138626098633  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.12061738967895508  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.1260666847229004  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.7088623046875 GB
    Memory Allocated: 0.1260666847229004  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

torch.Size([38184, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 4.312377452850342  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 4.31991720199585  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.13115262985229492  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

pseudo mini batch 4 input nodes size: 284829
----------------------------------------before load block subtensor 
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.12006282806396484  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.12006282806396484  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.22617006301879883  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.2264714241027832  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.11395072937011719  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.11995410919189453  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.7615966796875 GB
    Memory Allocated: 0.11995410919189453  GigaBytes
Max Memory Allocated: 5.188119888305664  GigaBytes

torch.Size([40442, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.4764404296875 GB
    Memory Allocated: 4.722951412200928  GigaBytes
Max Memory Allocated: 5.315549373626709  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 15.4764404296875 GB
    Memory Allocated: 4.730032920837402  GigaBytes
Max Memory Allocated: 5.315549373626709  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 15.4764404296875 GB
    Memory Allocated: 0.12698125839233398  GigaBytes
Max Memory Allocated: 5.315549373626709  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 15.4764404296875 GB
    Memory Allocated: 0.1276564598083496  GigaBytes
Max Memory Allocated: 5.315549373626709  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 15.4764404296875 GB
    Memory Allocated: 0.1276564598083496  GigaBytes
Max Memory Allocated: 5.315549373626709  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.07496099472045899 |0.07035279273986816 |0.15015630722045897 |0.00017685890197753905 |0.057760763168334964 |0.00398707389831543 |
----------------------------------------------------------pseudo_mini_loss sum 4.7910614013671875
Total (block generation + training)time/epoch 34.02860951423645
Training time/epoch 1.7894344329833984
Training time without block to device /epoch 1.4376704692840576
Training time without total dataloading part /epoch 1.0444567203521729
load block tensor time/epoch 0.3748049736022949
block to device time/epoch 0.3517639636993408
input features size transfer per epoch 6.705522537231445e-07
blocks size to device per epoch 4.470348358154297e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1357405
Number of first layer input nodes during this epoch:  1357405
Number of first layer output nodes during this epoch:  196571
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(100, 100, batch_first=True)
      (fc_self): Linear(in_features=100, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  90200
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([400, 100])
layers.0.lstm.weight_hh_l0, torch.Size([400, 100])
layers.0.lstm.bias_ih_l0, torch.Size([400])
layers.0.lstm.bias_hh_l0, torch.Size([400])
layers.0.fc_self.weight, torch.Size([47, 100])
layers.0.fc_neigh.weight, torch.Size([47, 100])
----------------------------------------
un-trainable parameters
