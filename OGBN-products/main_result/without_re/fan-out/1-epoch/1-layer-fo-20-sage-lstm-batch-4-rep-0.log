main start at this time 1656028562.9109938
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 0.134474515914917
global_2_local spend time (sec) 0.35357165336608887
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.02006840705871582
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 922590, 20: 186421, 14: 695, 15: 673, 7: 655, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 19: 584, 12: 583, 9: 576, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.06347250938415527
auxiliary_graph
Graph(num_nodes=1119161, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.5400960445404053
remove nodes length  922590

auxiliary_graph.remove_nodes spent  2.191084146499634
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=36530005,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  1.4887895584106445

the counter of shared neighbor distribution
Counter({1.0: 31135406, 2.0: 3552592, 3.0: 936932, 4.0: 353502, 5.0: 159904, 6.0: 75186, 7.0: 40668, 8.0: 21746, 9.0: 14870, 10.0: 9568, 11.0: 6274, 12.0: 4756, 15.0: 4752, 14.0: 4072, 13.0: 3450, 18.0: 2810, 16.0: 2680, 17.0: 1584, 19.0: 1406, 20.0: 1276})
36333434
Convert a graph into a bidirected graph: 2.013 seconds
Metis partitioning: 8.770 seconds
Split the graph: 2.175 seconds
Construct subgraphs: 0.057 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  13.0425705909729
48078
50296
47916
50281
total k batches seeds list generation spend  24.37343430519104
after graph partition
graph partition algorithm spend time 24.957091569900513
48078
50296
47916
50281
partition_len_list
[349423, 342433, 298043, 307862]
REG selection method  spend 25.55945611000061
time for parepare:  0.2208266258239746
local_output_nid generation:  0.008233070373535156
local_in_edges_tensor generation:  0.0317082405090332
mini_batch_src_global generation:  0.03166937828063965
r_  generation:  0.368938684463501
local_output_nid generation:  0.010358572006225586
local_in_edges_tensor generation:  0.05095028877258301
mini_batch_src_global generation:  0.04738569259643555
r_  generation:  0.450162410736084
local_output_nid generation:  0.011966228485107422
local_in_edges_tensor generation:  0.014950275421142578
mini_batch_src_global generation:  0.03274726867675781
r_  generation:  0.4399850368499756
local_output_nid generation:  0.009605884552001953
local_in_edges_tensor generation:  0.01670527458190918
mini_batch_src_global generation:  0.03630352020263672
r_  generation:  0.48004984855651855
----------------------check_connections_block total spend ----------------------------- 2.616225242614746
generate_one_block  1.9362707138061523
generate_one_block  0.5755712985992432
generate_one_block  0.49021291732788086
generate_one_block  0.5152173042297363
----------===============-------------===============-------------the number of batches *****---- 4

original number of batches:  4
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

connection checking time:  2.616225242614746
block generation total time  3.5172722339630127
average batch blocks generation time:  0.8793180584907532
block dataloader generation time/epoch 32.08904719352722
pseudo mini batch 0 input nodes size: 349423
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.1483154296875 GB
    Memory Allocated: 0.1311969757080078  GigaBytes
Max Memory Allocated: 0.1311969757080078  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.1483154296875 GB
    Memory Allocated: 0.13155555725097656  GigaBytes
Max Memory Allocated: 0.13155555725097656  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.1483154296875 GB
    Memory Allocated: 0.13155555725097656  GigaBytes
Max Memory Allocated: 0.13155555725097656  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2322998046875 GB
    Memory Allocated: 0.1384134292602539  GigaBytes
Max Memory Allocated: 0.1384134292602539  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2322998046875 GB
    Memory Allocated: 0.1384134292602539  GigaBytes
Max Memory Allocated: 0.1384134292602539  GigaBytes

torch.Size([48078, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 5.380266189575195  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 5.389214992523193  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.1542072296142578  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

pseudo mini batch 1 input nodes size: 342433
----------------------------------------before load block subtensor 
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.14031219482421875  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.14031219482421875  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.26787853240966797  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.2682533264160156  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.13703536987304688  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.14449787139892578  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 7.4061279296875 GB
    Memory Allocated: 0.14449787139892578  GigaBytes
Max Memory Allocated: 6.030190944671631  GigaBytes

torch.Size([50296, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 5.837022304534912  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 5.845829486846924  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.15275955200195312  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

pseudo mini batch 2 input nodes size: 298043
----------------------------------------before load block subtensor 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.13764715194702148  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.13764715194702148  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.24867725372314453  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.24903440475463867  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.1210932731628418  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.12807130813598633  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.12807130813598633  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

torch.Size([47916, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 5.472459316253662  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 5.480849742889404  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.13458824157714844  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

pseudo mini batch 3 input nodes size: 307862
----------------------------------------before load block subtensor 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.1204533576965332  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.1204533576965332  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.23514127731323242  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.23551607131958008  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.12412881851196289  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.13144731521606445  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.13144731521606445  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

torch.Size([50281, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 5.71330451965332  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 5.722108840942383  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.13936710357666016  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.14004230499267578  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 12.1600341796875 GB
    Memory Allocated: 0.14004230499267578  GigaBytes
Max Memory Allocated: 6.57295560836792  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.07252728939056396 |0.08640635013580322 |0.18072843551635742 |0.0001742243766784668 |0.07176923751831055 |0.003361225128173828 |
----------------------------------------------------------pseudo_mini_loss sum 4.7910614013671875
Total (block generation + training)time/epoch 33.75687861442566
Training time/epoch 1.6675641536712646
Training time without block to device /epoch 1.3219387531280518
Training time without total dataloading part /epoch 1.0140488147735596
load block tensor time/epoch 0.29010915756225586
block to device time/epoch 0.3456254005432129
input features size transfer per epoch 5.364418029785156e-07
blocks size to device per epoch 3.5762786865234375e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1297761
Number of first layer input nodes during this epoch:  1297761
Number of first layer output nodes during this epoch:  196571
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(100, 100, batch_first=True)
      (fc_self): Linear(in_features=100, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  90200
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([400, 100])
layers.0.lstm.weight_hh_l0, torch.Size([400, 100])
layers.0.lstm.bias_ih_l0, torch.Size([400])
layers.0.lstm.bias_hh_l0, torch.Size([400])
layers.0.fc_self.weight, torch.Size([47, 100])
layers.0.fc_neigh.weight, torch.Size([47, 100])
----------------------------------------
un-trainable parameters
