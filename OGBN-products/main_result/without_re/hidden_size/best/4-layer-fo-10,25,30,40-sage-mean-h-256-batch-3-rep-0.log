main start at this time 1656050839.965077
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.3493645191192627
global_2_local spend time (sec) 0.42766571044921875
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.07654213905334473
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1181171, 40: 172537, 39: 816, 33: 793, 37: 791, 38: 775, 28: 768, 35: 754, 36: 741, 32: 727, 14: 695, 31: 691, 30: 689, 34: 677, 15: 673, 25: 671, 26: 659, 7: 655, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 22: 592, 21: 586, 19: 584, 12: 583, 9: 576, 20: 572, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.12202024459838867
auxiliary_graph
Graph(num_nodes=1377742, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.6909139156341553
remove nodes length  1181171

auxiliary_graph.remove_nodes spent  5.809425354003906
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  4.271210432052612

the counter of shared neighbor distribution
Counter({1.0: 76625834, 2.0: 14048222, 3.0: 5011620, 4.0: 2308328, 5.0: 1244288, 6.0: 737614, 7.0: 469104, 8.0: 320932, 9.0: 223716, 10.0: 162494, 11.0: 118854, 12.0: 89870, 13.0: 69466, 14.0: 53028, 15.0: 41764, 16.0: 31248, 17.0: 22002, 18.0: 19492, 19.0: 13018, 20.0: 10882, 21.0: 7144, 22.0: 5740, 23.0: 4796, 24.0: 3814, 25.0: 3584, 33.0: 3046, 28.0: 2926, 26.0: 2688, 30.0: 2312, 27.0: 2286, 31.0: 2154, 39.0: 2098, 32.0: 2040, 35.0: 1750, 29.0: 1680, 37.0: 1650, 36.0: 1526, 38.0: 1460, 34.0: 1422, 40.0: 1080})
101676972
Convert a graph into a bidirected graph: 6.850 seconds
Metis partitioning: 22.433 seconds
Split the graph: 7.305 seconds
Construct subgraphs: 0.074 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  36.7044460773468
67385
63612
65574
total k batches seeds list generation spend  67.90181303024292
after graph partition
graph partition algorithm spend time 69.09424352645874
67385
63612
65574
partition_len_list
[496512, 530044, 547438]
REG selection method  spend 69.79166078567505
time for parepare:  0.2819557189941406
local_output_nid generation:  0.019316434860229492
local_in_edges_tensor generation:  0.03233742713928223
mini_batch_src_global generation:  0.08145856857299805
r_  generation:  1.047579050064087
local_output_nid generation:  0.01438283920288086
local_in_edges_tensor generation:  0.0673074722290039
mini_batch_src_global generation:  0.0901639461517334
r_  generation:  1.025575876235962
local_output_nid generation:  0.010942935943603516
local_in_edges_tensor generation:  0.03480863571166992
mini_batch_src_global generation:  0.0927119255065918
r_  generation:  1.201622486114502
----------------------check_connections_block total spend ----------------------------- 4.604146957397461
generate_one_block  2.7189953327178955
generate_one_block  1.2738051414489746
generate_one_block  1.3726282119750977
The real block id is  2
get_global_graph_edges_ids_block function  spend 1.843465805053711
gen group dst list time:  0.04607248306274414
time for parepare:  0.4401569366455078
local_output_nid generation:  0.09502148628234863
local_in_edges_tensor generation:  0.39689064025878906
mini_batch_src_global generation:  0.3772313594818115
r_  generation:  5.188827037811279
local_output_nid generation:  0.14758062362670898
local_in_edges_tensor generation:  0.44237518310546875
mini_batch_src_global generation:  0.5977969169616699
r_  generation:  5.9663097858428955
local_output_nid generation:  0.13134002685546875
local_in_edges_tensor generation:  0.4221773147583008
mini_batch_src_global generation:  0.6144182682037354
r_  generation:  6.458328485488892
----------------------check_connections_block total spend ----------------------------- 24.430059909820557
generate_one_block  6.9619879722595215
generate_one_block  7.954580307006836
generate_one_block  8.200685977935791
The real block id is  1
get_global_graph_edges_ids_block function  spend 2.128514528274536
gen group dst list time:  0.1447770595550537
time for parepare:  0.47518229484558105
local_output_nid generation:  0.27034783363342285
local_in_edges_tensor generation:  0.8069460391998291
mini_batch_src_global generation:  0.678804874420166
r_  generation:  9.799756288528442
local_output_nid generation:  0.4169332981109619
local_in_edges_tensor generation:  1.021716594696045
mini_batch_src_global generation:  1.0860624313354492
r_  generation:  12.750954151153564
local_output_nid generation:  0.3465900421142578
local_in_edges_tensor generation:  0.6919941902160645
mini_batch_src_global generation:  1.0546741485595703
r_  generation:  11.749027967453003
----------------------check_connections_block total spend ----------------------------- 47.25404191017151
generate_one_block  12.572771310806274
generate_one_block  15.948936462402344
generate_one_block  14.796143531799316
The real block id is  0
get_global_graph_edges_ids_block function  spend 1.1853270530700684
gen group dst list time:  0.23523211479187012
time for parepare:  0.47391533851623535
local_output_nid generation:  0.5315964221954346
local_in_edges_tensor generation:  0.9038364887237549
mini_batch_src_global generation:  0.5491724014282227
r_  generation:  8.975126266479492
local_output_nid generation:  0.6531994342803955
local_in_edges_tensor generation:  0.9331603050231934
mini_batch_src_global generation:  0.7193286418914795
r_  generation:  9.77034068107605
local_output_nid generation:  0.5918624401092529
local_in_edges_tensor generation:  0.8711776733398438
mini_batch_src_global generation:  0.700873851776123
r_  generation:  9.083544969558716
----------------------check_connections_block total spend ----------------------------- 40.29480504989624
generate_one_block  11.476764440536499
generate_one_block  11.870045185089111
generate_one_block  11.249680280685425
----------===============-------------===============-------------the number of batches *****---- 3

original number of batches:  3
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

connection checking time:  116.58305382728577
block generation total time  106.39702415466309
average batch blocks generation time:  8.866418679555258
block dataloader generation time/epoch 306.9050898551941
pseudo mini batch 0 input nodes size: 2145847
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.8182373046875 GB
    Memory Allocated: 0.8006472587585449  GigaBytes
Max Memory Allocated: 0.8006472587585449  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.8182373046875 GB
    Memory Allocated: 0.8011493682861328  GigaBytes
Max Memory Allocated: 0.8011493682861328  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.8182373046875 GB
    Memory Allocated: 0.8011493682861328  GigaBytes
Max Memory Allocated: 0.8011493682861328  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 2.2850341796875 GB
    Memory Allocated: 1.2005481719970703  GigaBytes
Max Memory Allocated: 1.2005481719970703  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2850341796875 GB
    Memory Allocated: 1.2005481719970703  GigaBytes
Max Memory Allocated: 1.2005481719970703  GigaBytes

first layer input nodes number: 2145847
first layer output nodes number: 1908355
edges number: 17262629
torch.Size([2145847, 100])
torch.Size([1908355, 256])
input nodes number: 1908355
output nodes number: 1126331
edges number: 21624785
torch.Size([1908355, 256])
torch.Size([1126331, 256])
input nodes number: 1126331
output nodes number: 496512
edges number: 11981534
torch.Size([1126331, 256])
torch.Size([496512, 256])
torch.Size([67385, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.7791748046875 GB
    Memory Allocated: 11.608072280883789  GigaBytes
Max Memory Allocated: 11.974462509155273  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.7791748046875 GB
    Memory Allocated: 11.619871616363525  GigaBytes
Max Memory Allocated: 11.974462509155273  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 1.9727821350097656  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

pseudo mini batch 1 input nodes size: 2190175
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 0.8142056465148926  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 0.8142056465148926  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 1.6301097869873047  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 1.6305837631225586  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 0.8306913375854492  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 1.3024754524230957  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.4432373046875 GB
    Memory Allocated: 1.3024754524230957  GigaBytes
Max Memory Allocated: 12.499858379364014  GigaBytes

first layer input nodes number: 2190175
first layer output nodes number: 2036878
edges number: 18535279
torch.Size([2190175, 100])
torch.Size([2036878, 256])
input nodes number: 2036878
output nodes number: 1372427
edges number: 28554610
torch.Size([2036878, 256])
torch.Size([1372427, 256])
input nodes number: 1372427
output nodes number: 530044
edges number: 13742267
torch.Size([1372427, 256])
torch.Size([530044, 256])
torch.Size([63612, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 19.0369873046875 GB
    Memory Allocated: 12.96790885925293  GigaBytes
Max Memory Allocated: 13.384175777435303  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 19.0369873046875 GB
    Memory Allocated: 12.979047298431396  GigaBytes
Max Memory Allocated: 13.384175777435303  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 2.207819938659668  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

pseudo mini batch 2 input nodes size: 2121770
----------------------------------------before load block subtensor 
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 0.8300309181213379  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 0.8300309181213379  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 1.6204519271850586  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 1.6209406852722168  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 0.8045625686645508  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 1.2552261352539062  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 19.1131591796875 GB
    Memory Allocated: 1.2552261352539062  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

first layer input nodes number: 2121770
first layer output nodes number: 1882074
edges number: 17296956
torch.Size([2121770, 100])
torch.Size([1882074, 256])
input nodes number: 1882074
output nodes number: 1206924
edges number: 25776314
torch.Size([1882074, 256])
torch.Size([1206924, 256])
input nodes number: 1206924
output nodes number: 547438
edges number: 14858898
torch.Size([1206924, 256])
torch.Size([547438, 256])
torch.Size([65574, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.2674560546875 GB
    Memory Allocated: 12.045312881469727  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.2674560546875 GB
    Memory Allocated: 12.05721378326416  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.4197998046875 GB
    Memory Allocated: 2.1222829818725586  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 21.4217529296875 GB
    Memory Allocated: 2.1247968673706055  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 21.4217529296875 GB
    Memory Allocated: 2.1247968673706055  GigaBytes
Max Memory Allocated: 13.995893955230713  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.3438834349314372 |0.6734584172566732 |0.5604658126831055 |0.0002342065175374349 |0.24722679456075033 |0.004610300064086914 |
----------------------------------------------------------pseudo_mini_loss sum 11.032981872558594
Total (block generation + training)time/epoch 312.76434445381165
Training time/epoch 5.858919143676758
Training time without block to device /epoch 3.8385438919067383
Training time without total dataloading part /epoch 2.4283907413482666
load block tensor time/epoch 1.0316503047943115
block to device time/epoch 2.0203752517700195
input features size transfer per epoch 4.023313522338867e-07
blocks size to device per epoch 2.682209014892578e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  17564775
Number of first layer input nodes during this epoch:  6457792
Number of first layer output nodes during this epoch:  5827307
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  337408
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 100])
layers.0.fc_neigh.weight, torch.Size([256, 100])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([47, 256])
layers.3.fc_neigh.weight, torch.Size([47, 256])
----------------------------------------
un-trainable parameters
