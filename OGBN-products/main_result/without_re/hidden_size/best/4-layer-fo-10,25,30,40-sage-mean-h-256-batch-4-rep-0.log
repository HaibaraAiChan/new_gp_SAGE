main start at this time 1656051178.018636
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.47673821449279785
global_2_local spend time (sec) 0.4569406509399414
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.10326290130615234
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1181171, 40: 172537, 39: 816, 33: 793, 37: 791, 38: 775, 28: 768, 35: 754, 36: 741, 32: 727, 14: 695, 31: 691, 30: 689, 34: 677, 15: 673, 25: 671, 26: 659, 7: 655, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 22: 592, 21: 586, 19: 584, 12: 583, 9: 576, 20: 572, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.1244354248046875
auxiliary_graph
Graph(num_nodes=1377742, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.7008006572723389
remove nodes length  1181171

auxiliary_graph.remove_nodes spent  5.815853834152222
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  4.219792366027832

the counter of shared neighbor distribution
Counter({1.0: 76625834, 2.0: 14048222, 3.0: 5011620, 4.0: 2308328, 5.0: 1244288, 6.0: 737614, 7.0: 469104, 8.0: 320932, 9.0: 223716, 10.0: 162494, 11.0: 118854, 12.0: 89870, 13.0: 69466, 14.0: 53028, 15.0: 41764, 16.0: 31248, 17.0: 22002, 18.0: 19492, 19.0: 13018, 20.0: 10882, 21.0: 7144, 22.0: 5740, 23.0: 4796, 24.0: 3814, 25.0: 3584, 33.0: 3046, 28.0: 2926, 26.0: 2688, 30.0: 2312, 27.0: 2286, 31.0: 2154, 39.0: 2098, 32.0: 2040, 35.0: 1750, 29.0: 1680, 37.0: 1650, 36.0: 1526, 38.0: 1460, 34.0: 1422, 40.0: 1080})
101676972
Convert a graph into a bidirected graph: 6.569 seconds
Metis partitioning: 23.360 seconds
Split the graph: 6.930 seconds
Construct subgraphs: 0.046 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  36.94831132888794
48059
50437
47709
50366
total k batches seeds list generation spend  68.54859399795532
after graph partition
graph partition algorithm spend time 69.65716767311096
48059
50437
47709
50366
partition_len_list
[369230, 399423, 461928, 443327]
REG selection method  spend 70.37805151939392
time for parepare:  0.27866196632385254
local_output_nid generation:  0.007988929748535156
local_in_edges_tensor generation:  0.02100348472595215
mini_batch_src_global generation:  0.05758953094482422
r_  generation:  0.7134747505187988
local_output_nid generation:  0.009452342987060547
local_in_edges_tensor generation:  0.03856348991394043
mini_batch_src_global generation:  0.072296142578125
r_  generation:  0.8176388740539551
local_output_nid generation:  0.009039163589477539
local_in_edges_tensor generation:  0.029776811599731445
mini_batch_src_global generation:  0.06367301940917969
r_  generation:  0.7355380058288574
local_output_nid generation:  0.010494232177734375
local_in_edges_tensor generation:  0.08211469650268555
mini_batch_src_global generation:  0.07111763954162598
r_  generation:  0.9219348430633545
----------------------check_connections_block total spend ----------------------------- 4.554610967636108
generate_one_block  2.2865705490112305
generate_one_block  0.9311206340789795
generate_one_block  0.9135560989379883
generate_one_block  1.0296621322631836
The real block id is  2
get_global_graph_edges_ids_block function  spend 1.8795504570007324
gen group dst list time:  0.04529738426208496
time for parepare:  0.41707277297973633
local_output_nid generation:  0.07148385047912598
local_in_edges_tensor generation:  0.2835261821746826
mini_batch_src_global generation:  0.27399611473083496
r_  generation:  3.469130516052246
local_output_nid generation:  0.08729863166809082
local_in_edges_tensor generation:  0.230607271194458
mini_batch_src_global generation:  0.39379286766052246
r_  generation:  4.311627626419067
local_output_nid generation:  0.10416007041931152
local_in_edges_tensor generation:  0.3312973976135254
mini_batch_src_global generation:  0.4581904411315918
r_  generation:  5.170776844024658
local_output_nid generation:  0.10253357887268066
local_in_edges_tensor generation:  0.3178865909576416
mini_batch_src_global generation:  0.5007390975952148
r_  generation:  5.117530584335327
----------------------check_connections_block total spend ----------------------------- 24.831125259399414
generate_one_block  5.093940734863281
generate_one_block  5.65314507484436
generate_one_block  6.72581672668457
generate_one_block  6.789280414581299
The real block id is  1
get_global_graph_edges_ids_block function  spend 2.1935553550720215
gen group dst list time:  0.1457054615020752
time for parepare:  0.477968692779541
local_output_nid generation:  0.266554594039917
local_in_edges_tensor generation:  0.6497459411621094
mini_batch_src_global generation:  0.6076152324676514
r_  generation:  8.618937730789185
local_output_nid generation:  0.33502912521362305
local_in_edges_tensor generation:  0.7304842472076416
mini_batch_src_global generation:  0.8404076099395752
r_  generation:  9.393994092941284
local_output_nid generation:  0.4285240173339844
local_in_edges_tensor generation:  0.986736536026001
mini_batch_src_global generation:  1.0921459197998047
r_  generation:  12.597612142562866
local_output_nid generation:  0.2951211929321289
local_in_edges_tensor generation:  0.7168922424316406
mini_batch_src_global generation:  0.9755687713623047
r_  generation:  10.250341653823853
----------------------check_connections_block total spend ----------------------------- 56.5538067817688
generate_one_block  10.996644973754883
generate_one_block  12.19468379020691
generate_one_block  15.71255373954773
generate_one_block  12.888590574264526
The real block id is  0
get_global_graph_edges_ids_block function  spend 1.1709156036376953
gen group dst list time:  0.30161285400390625
time for parepare:  0.4743845462799072
local_output_nid generation:  0.5952377319335938
local_in_edges_tensor generation:  1.0414888858795166
mini_batch_src_global generation:  0.5320842266082764
r_  generation:  8.680386066436768
local_output_nid generation:  0.6287565231323242
local_in_edges_tensor generation:  0.9546833038330078
mini_batch_src_global generation:  0.7051286697387695
r_  generation:  8.8109290599823
local_output_nid generation:  0.6435017585754395
local_in_edges_tensor generation:  1.4664585590362549
mini_batch_src_global generation:  0.7234160900115967
r_  generation:  10.70858383178711
local_output_nid generation:  0.6046805381774902
local_in_edges_tensor generation:  0.8711187839508057
mini_batch_src_global generation:  0.7681310176849365
r_  generation:  8.86893630027771
----------------------check_connections_block total spend ----------------------------- 54.3927698135376
generate_one_block  10.918587446212769
generate_one_block  10.693605661392212
generate_one_block  12.427186250686646
generate_one_block  10.909466981887817
----------===============-------------===============-------------the number of batches *****---- 4

original number of batches:  4
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

connection checking time:  140.33231282234192
block generation total time  126.16441178321838
average batch blocks generation time:  7.885275736451149
block dataloader generation time/epoch 352.11604714393616
pseudo mini batch 0 input nodes size: 2110075
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.8045654296875 GB
    Memory Allocated: 0.7873215675354004  GigaBytes
Max Memory Allocated: 0.7873215675354004  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.8045654296875 GB
    Memory Allocated: 0.7876796722412109  GigaBytes
Max Memory Allocated: 0.7876796722412109  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.8045654296875 GB
    Memory Allocated: 0.7876796722412109  GigaBytes
Max Memory Allocated: 0.7876796722412109  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 2.2244873046875 GB
    Memory Allocated: 1.134139060974121  GigaBytes
Max Memory Allocated: 1.134139060974121  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2244873046875 GB
    Memory Allocated: 1.134139060974121  GigaBytes
Max Memory Allocated: 1.134139060974121  GigaBytes

first layer input nodes number: 2110075
first layer output nodes number: 1827434
edges number: 16676279
torch.Size([2110075, 100])
torch.Size([1827434, 256])
input nodes number: 1827434
output nodes number: 969670
edges number: 19007774
torch.Size([1827434, 256])
torch.Size([969670, 256])
input nodes number: 969670
output nodes number: 369230
edges number: 8772904
torch.Size([969670, 256])
torch.Size([369230, 256])
torch.Size([48059, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 13.3416748046875 GB
    Memory Allocated: 10.372382164001465  GigaBytes
Max Memory Allocated: 10.648053169250488  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 13.3416748046875 GB
    Memory Allocated: 10.380797863006592  GigaBytes
Max Memory Allocated: 10.648053169250488  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 1.7937874794006348  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

pseudo mini batch 1 input nodes size: 2104931
----------------------------------------before load block subtensor 
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 0.7973523139953613  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 0.7973523139953613  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 1.58150053024292  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 1.5818767547607422  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 0.7954540252685547  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 1.1725597381591797  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.1326904296875 GB
    Memory Allocated: 1.1725597381591797  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

first layer input nodes number: 2104931
first layer output nodes number: 1844762
edges number: 16972482
torch.Size([2104931, 100])
torch.Size([1844762, 256])
input nodes number: 1844762
output nodes number: 1013395
edges number: 21212423
torch.Size([1844762, 256])
torch.Size([1013395, 256])
input nodes number: 1013395
output nodes number: 399423
edges number: 10502321
torch.Size([1013395, 256])
torch.Size([399423, 256])
torch.Size([50437, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 16.5233154296875 GB
    Memory Allocated: 10.71340274810791  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 16.5233154296875 GB
    Memory Allocated: 10.722623825073242  GigaBytes
Max Memory Allocated: 11.10611629486084  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 1.8880319595336914  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

pseudo mini batch 2 input nodes size: 2169580
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 0.795870304107666  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 0.795870304107666  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 1.6041021347045898  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 1.6044578552246094  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 0.8199334144592285  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 1.269096851348877  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.2322998046875 GB
    Memory Allocated: 1.269096851348877  GigaBytes
Max Memory Allocated: 11.44837474822998  GigaBytes

first layer input nodes number: 2169580
first layer output nodes number: 1988321
edges number: 18199937
torch.Size([2169580, 100])
torch.Size([1988321, 256])
input nodes number: 1988321
output nodes number: 1335297
edges number: 28267395
torch.Size([1988321, 256])
torch.Size([1335297, 256])
input nodes number: 1335297
output nodes number: 461928
edges number: 12101251
torch.Size([1335297, 256])
torch.Size([461928, 256])
torch.Size([47709, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 18.1873779296875 GB
    Memory Allocated: 12.443283081054688  GigaBytes
Max Memory Allocated: 12.817214965820312  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 18.1873779296875 GB
    Memory Allocated: 12.451637268066406  GigaBytes
Max Memory Allocated: 12.817214965820312  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 2.1293258666992188  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

pseudo mini batch 3 input nodes size: 2070368
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 0.8194561004638672  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 0.8194561004638672  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 1.5907282829284668  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 1.5911035537719727  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 0.7825160026550293  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 1.1797633171081543  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 1.1797633171081543  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

first layer input nodes number: 2070368
first layer output nodes number: 1773878
edges number: 16463879
torch.Size([2070368, 100])
torch.Size([1773878, 256])
input nodes number: 1773878
output nodes number: 1045465
edges number: 22733612
torch.Size([1773878, 256])
torch.Size([1045465, 256])
input nodes number: 1045465
output nodes number: 443327
edges number: 12135596
torch.Size([1045465, 256])
torch.Size([443327, 256])
torch.Size([50366, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 10.796335220336914  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.4002685546875 GB
    Memory Allocated: 10.80515432357788  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.3983154296875 GB
    Memory Allocated: 1.9393739700317383  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 21.4022216796875 GB
    Memory Allocated: 1.9418878555297852  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 21.4022216796875 GB
    Memory Allocated: 1.9418878555297852  GigaBytes
Max Memory Allocated: 13.610122203826904  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.377765953540802 |0.6322843432426453 |0.5145859122276306 |0.00018310546875 |0.21233916282653809 |0.004862070083618164 |
----------------------------------------------------------pseudo_mini_loss sum 11.002107620239258
Total (block generation + training)time/epoch 359.3984749317169
Training time/epoch 7.282121896743774
Training time without block to device /epoch 4.752984523773193
Training time without total dataloading part /epoch 2.913294792175293
load block tensor time/epoch 1.511063814163208
block to device time/epoch 2.529137372970581
input features size transfer per epoch 5.364418029785156e-07
blocks size to device per epoch 3.5762786865234375e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  21927084
Number of first layer input nodes during this epoch:  8454954
Number of first layer output nodes during this epoch:  7434395
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  337408
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 100])
layers.0.fc_neigh.weight, torch.Size([256, 100])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([47, 256])
layers.3.fc_neigh.weight, torch.Size([47, 256])
----------------------------------------
un-trainable parameters
