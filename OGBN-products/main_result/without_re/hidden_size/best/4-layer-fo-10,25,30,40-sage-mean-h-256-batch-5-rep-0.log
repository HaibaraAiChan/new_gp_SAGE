main start at this time 1656051562.8603332
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.34052181243896484
global_2_local spend time (sec) 0.4320855140686035
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.08090019226074219
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1181171, 40: 172537, 39: 816, 33: 793, 37: 791, 38: 775, 28: 768, 35: 754, 36: 741, 32: 727, 14: 695, 31: 691, 30: 689, 34: 677, 15: 673, 25: 671, 26: 659, 7: 655, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 22: 592, 21: 586, 19: 584, 12: 583, 9: 576, 20: 572, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.12117934226989746
auxiliary_graph
Graph(num_nodes=1377742, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.6814465522766113
remove nodes length  1181171

auxiliary_graph.remove_nodes spent  5.7240142822265625
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  4.024414300918579

the counter of shared neighbor distribution
Counter({1.0: 76625834, 2.0: 14048222, 3.0: 5011620, 4.0: 2308328, 5.0: 1244288, 6.0: 737614, 7.0: 469104, 8.0: 320932, 9.0: 223716, 10.0: 162494, 11.0: 118854, 12.0: 89870, 13.0: 69466, 14.0: 53028, 15.0: 41764, 16.0: 31248, 17.0: 22002, 18.0: 19492, 19.0: 13018, 20.0: 10882, 21.0: 7144, 22.0: 5740, 23.0: 4796, 24.0: 3814, 25.0: 3584, 33.0: 3046, 28.0: 2926, 26.0: 2688, 30.0: 2312, 27.0: 2286, 31.0: 2154, 39.0: 2098, 32.0: 2040, 35.0: 1750, 29.0: 1680, 37.0: 1650, 36.0: 1526, 38.0: 1460, 34.0: 1422, 40.0: 1080})
101676972
Convert a graph into a bidirected graph: 6.537 seconds
Metis partitioning: 22.920 seconds
Split the graph: 5.210 seconds
Construct subgraphs: 0.081 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  34.789165019989014
40331
38195
39931
38527
39587
total k batches seeds list generation spend  65.80928444862366
after graph partition
graph partition algorithm spend time 66.95271420478821
40331
38195
39931
38527
39587
partition_len_list
[313437, 330037, 384476, 368380, 377664]
REG selection method  spend 67.64394164085388
time for parepare:  0.2699775695800781
local_output_nid generation:  0.007238149642944336
local_in_edges_tensor generation:  0.0170745849609375
mini_batch_src_global generation:  0.049681901931762695
r_  generation:  0.5427782535552979
local_output_nid generation:  0.008191585540771484
local_in_edges_tensor generation:  0.02873682975769043
mini_batch_src_global generation:  0.055665016174316406
r_  generation:  0.5422022342681885
local_output_nid generation:  0.008537530899047852
local_in_edges_tensor generation:  0.021754026412963867
mini_batch_src_global generation:  0.05252647399902344
r_  generation:  0.6678512096405029
local_output_nid generation:  0.008269309997558594
local_in_edges_tensor generation:  0.025734424591064453
mini_batch_src_global generation:  0.056795597076416016
r_  generation:  0.6892800331115723
local_output_nid generation:  0.00859522819519043
local_in_edges_tensor generation:  0.01900792121887207
mini_batch_src_global generation:  0.06290030479431152
r_  generation:  0.6823921203613281
----------------------check_connections_block total spend ----------------------------- 4.399912118911743
generate_one_block  2.1562535762786865
generate_one_block  0.6865353584289551
generate_one_block  0.7661478519439697
generate_one_block  0.7636377811431885
generate_one_block  0.726309061050415
The real block id is  2
get_global_graph_edges_ids_block function  spend 1.8576107025146484
gen group dst list time:  0.04866456985473633
time for parepare:  0.42669081687927246
local_output_nid generation:  0.06741023063659668
local_in_edges_tensor generation:  0.26465511322021484
mini_batch_src_global generation:  0.23154759407043457
r_  generation:  2.921794891357422
local_output_nid generation:  0.08085036277770996
local_in_edges_tensor generation:  0.23686599731445312
mini_batch_src_global generation:  0.31955814361572266
r_  generation:  3.3945224285125732
local_output_nid generation:  0.08583879470825195
local_in_edges_tensor generation:  0.42458558082580566
mini_batch_src_global generation:  0.37619709968566895
r_  generation:  4.203097581863403
local_output_nid generation:  0.09422826766967773
local_in_edges_tensor generation:  0.2863633632659912
mini_batch_src_global generation:  0.4196181297302246
r_  generation:  4.175915718078613
local_output_nid generation:  0.10756111145019531
local_in_edges_tensor generation:  0.2394402027130127
mini_batch_src_global generation:  0.41927552223205566
r_  generation:  4.2978715896606445
----------------------check_connections_block total spend ----------------------------- 26.513087034225464
generate_one_block  4.234841346740723
generate_one_block  4.544302701950073
generate_one_block  5.681024074554443
generate_one_block  5.280478477478027
generate_one_block  5.528360605239868
The real block id is  1
get_global_graph_edges_ids_block function  spend 2.328051805496216
gen group dst list time:  0.20881915092468262
time for parepare:  0.48035621643066406
local_output_nid generation:  0.24447965621948242
local_in_edges_tensor generation:  0.6903402805328369
mini_batch_src_global generation:  0.5262730121612549
r_  generation:  7.623175382614136
local_output_nid generation:  0.33435964584350586
local_in_edges_tensor generation:  0.7142868041992188
mini_batch_src_global generation:  0.7950849533081055
r_  generation:  8.84075117111206
local_output_nid generation:  0.34430360794067383
local_in_edges_tensor generation:  0.9093105792999268
mini_batch_src_global generation:  0.8591823577880859
r_  generation:  10.236313819885254
local_output_nid generation:  0.30017638206481934
local_in_edges_tensor generation:  0.6987872123718262
mini_batch_src_global generation:  0.8651988506317139
r_  generation:  9.89050555229187
local_output_nid generation:  0.3628511428833008
local_in_edges_tensor generation:  0.7046818733215332
mini_batch_src_global generation:  0.9415514469146729
r_  generation:  11.055545568466187
----------------------check_connections_block total spend ----------------------------- 65.67402935028076
generate_one_block  10.002706050872803
generate_one_block  11.633885860443115
generate_one_block  13.52432107925415
generate_one_block  12.509411811828613
generate_one_block  13.582207679748535
The real block id is  0
get_global_graph_edges_ids_block function  spend 1.259812831878662
gen group dst list time:  0.35831260681152344
time for parepare:  0.4916706085205078
local_output_nid generation:  0.5532751083374023
local_in_edges_tensor generation:  0.9531569480895996
mini_batch_src_global generation:  0.5061936378479004
r_  generation:  8.106619596481323
local_output_nid generation:  0.6383378505706787
local_in_edges_tensor generation:  0.9420986175537109
mini_batch_src_global generation:  0.6677770614624023
r_  generation:  8.488357067108154
local_output_nid generation:  0.6201059818267822
local_in_edges_tensor generation:  0.9030780792236328
mini_batch_src_global generation:  0.7153890132904053
r_  generation:  9.462960004806519
local_output_nid generation:  0.6097888946533203
local_in_edges_tensor generation:  0.8948192596435547
mini_batch_src_global generation:  0.6898529529571533
r_  generation:  8.69575834274292
local_output_nid generation:  0.6166276931762695
local_in_edges_tensor generation:  0.882331371307373
mini_batch_src_global generation:  0.6877264976501465
r_  generation:  9.075655937194824
----------------------check_connections_block total spend ----------------------------- 64.23480868339539
generate_one_block  10.465530157089233
generate_one_block  10.716663837432861
generate_one_block  10.850709199905396
generate_one_block  10.45622730255127
generate_one_block  11.19969916343689
----------===============-------------===============-------------the number of batches *****---- 5

original number of batches:  5
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

connection checking time:  160.82183718681335
block generation total time  145.30925297737122
average batch blocks generation time:  7.265462648868561
block dataloader generation time/epoch 389.64091634750366
pseudo mini batch 0 input nodes size: 2046296
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7811279296875 GB
    Memory Allocated: 0.7635617256164551  GigaBytes
Max Memory Allocated: 0.7635617256164551  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7811279296875 GB
    Memory Allocated: 0.7638626098632812  GigaBytes
Max Memory Allocated: 0.7638626098632812  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7811279296875 GB
    Memory Allocated: 0.7638626098632812  GigaBytes
Max Memory Allocated: 0.7638626098632812  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 2.1697998046875 GB
    Memory Allocated: 1.0768613815307617  GigaBytes
Max Memory Allocated: 1.0768613815307617  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.1697998046875 GB
    Memory Allocated: 1.0768613815307617  GigaBytes
Max Memory Allocated: 1.0768613815307617  GigaBytes

first layer input nodes number: 2046296
first layer output nodes number: 1718909
edges number: 15726280
torch.Size([2046296, 100])
torch.Size([1718909, 256])
input nodes number: 1718909
output nodes number: 872259
edges number: 17197361
torch.Size([1718909, 256])
torch.Size([872259, 256])
input nodes number: 872259
output nodes number: 313437
edges number: 7463612
torch.Size([872259, 256])
torch.Size([313437, 256])
torch.Size([40331, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 12.4803466796875 GB
    Memory Allocated: 9.51969861984253  GigaBytes
Max Memory Allocated: 9.754244327545166  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 12.4803466796875 GB
    Memory Allocated: 9.526761531829834  GigaBytes
Max Memory Allocated: 9.754244327545166  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 1.6722135543823242  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

pseudo mini batch 1 input nodes size: 2104601
----------------------------------------before load block subtensor 
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 0.7721824645996094  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 0.7721824645996094  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 1.5562076568603516  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 1.5564923286437988  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 0.793886661529541  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 1.1416888236999512  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 17.1951904296875 GB
    Memory Allocated: 1.1416888236999512  GigaBytes
Max Memory Allocated: 10.237192630767822  GigaBytes

first layer input nodes number: 2104601
first layer output nodes number: 1835518
edges number: 16742685
torch.Size([2104601, 100])
torch.Size([1835518, 256])
input nodes number: 1835518
output nodes number: 988138
edges number: 19997076
torch.Size([1835518, 256])
torch.Size([988138, 256])
input nodes number: 988138
output nodes number: 330037
edges number: 8422303
torch.Size([988138, 256])
torch.Size([330037, 256])
torch.Size([38195, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.5623779296875 GB
    Memory Allocated: 10.318427085876465  GigaBytes
Max Memory Allocated: 10.579501152038574  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.5623779296875 GB
    Memory Allocated: 10.325115203857422  GigaBytes
Max Memory Allocated: 10.579501152038574  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 1.795759677886963  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

pseudo mini batch 2 input nodes size: 2128756
----------------------------------------before load block subtensor 
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 0.7935123443603516  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 0.7935123443603516  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 1.586535930633545  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 1.5868334770202637  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 0.8025236129760742  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 1.1875925064086914  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.3826904296875 GB
    Memory Allocated: 1.1875925064086914  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

first layer input nodes number: 2128756
first layer output nodes number: 1857391
edges number: 17208515
torch.Size([2128756, 100])
torch.Size([1857391, 256])
input nodes number: 1857391
output nodes number: 1071181
edges number: 22739401
torch.Size([1857391, 256])
torch.Size([1071181, 256])
input nodes number: 1071181
output nodes number: 384476
edges number: 10119228
torch.Size([1071181, 256])
torch.Size([384476, 256])
torch.Size([39931, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.7772216796875 GB
    Memory Allocated: 10.88857650756836  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.7772216796875 GB
    Memory Allocated: 10.89600419998169  GigaBytes
Max Memory Allocated: 11.213390827178955  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.9180045127868652  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

pseudo mini batch 3 input nodes size: 2052234
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 0.8028278350830078  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 0.8028278350830078  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.5673446655273438  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.567631721496582  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 0.7743105888366699  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.1456828117370605  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.1456828117370605  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

first layer input nodes number: 2052234
first layer output nodes number: 1740256
edges number: 16203594
torch.Size([2052234, 100])
torch.Size([1740256, 256])
input nodes number: 1740256
output nodes number: 1002425
edges number: 22034928
torch.Size([1740256, 256])
torch.Size([1002425, 256])
input nodes number: 1002425
output nodes number: 368380
edges number: 10089614
torch.Size([1002425, 256])
torch.Size([368380, 256])
torch.Size([38527, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 10.26914358139038  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 10.275889873504639  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.8518848419189453  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

pseudo mini batch 4 input nodes size: 2097701
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 0.7740645408630371  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 0.7740645408630371  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.5555191040039062  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.555814266204834  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 0.7910103797912598  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.184584140777588  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.5682373046875 GB
    Memory Allocated: 1.184584140777588  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

first layer input nodes number: 2097701
first layer output nodes number: 1842548
edges number: 17007098
torch.Size([2097701, 100])
torch.Size([1842548, 256])
input nodes number: 1842548
output nodes number: 1111513
edges number: 24103042
torch.Size([1842548, 256])
torch.Size([1111513, 256])
input nodes number: 1111513
output nodes number: 377664
edges number: 10268216
torch.Size([1111513, 256])
torch.Size([377664, 256])
torch.Size([39587, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.6053466796875 GB
    Memory Allocated: 10.961068153381348  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 22.6053466796875 GB
    Memory Allocated: 10.967999935150146  GigaBytes
Max Memory Allocated: 11.786534786224365  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.6053466796875 GB
    Memory Allocated: 1.9342756271362305  GigaBytes
Max Memory Allocated: 11.957164764404297  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 22.6092529296875 GB
    Memory Allocated: 1.9367895126342773  GigaBytes
Max Memory Allocated: 11.957164764404297  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 22.6092529296875 GB
    Memory Allocated: 1.9367895126342773  GigaBytes
Max Memory Allocated: 11.957164764404297  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.37894716262817385 |0.5453029155731202 |0.3387007713317871 |0.00018486976623535156 |0.1710864543914795 |0.002651691436767578 |
----------------------------------------------------------pseudo_mini_loss sum 11.003887176513672
Total (block generation + training)time/epoch 397.142480134964
Training time/epoch 7.501305341720581
Training time without block to device /epoch 4.7747907638549805
Training time without total dataloading part /epoch 2.5525121688842773
load block tensor time/epoch 1.8947358131408691
block to device time/epoch 2.7265145778656006
input features size transfer per epoch 6.705522537231445e-07
blocks size to device per epoch 4.470348358154297e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  26243720
Number of first layer input nodes during this epoch:  10429588
Number of first layer output nodes during this epoch:  8994622
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  337408
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 100])
layers.0.fc_neigh.weight, torch.Size([256, 100])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([47, 256])
layers.3.fc_neigh.weight, torch.Size([47, 256])
----------------------------------------
un-trainable parameters
