main start at this time 1656051985.659651
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.3975512981414795
global_2_local spend time (sec) 0.43951845169067383
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.07925748825073242
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 1181171, 40: 172537, 39: 816, 33: 793, 37: 791, 38: 775, 28: 768, 35: 754, 36: 741, 32: 727, 14: 695, 31: 691, 30: 689, 34: 677, 15: 673, 25: 671, 26: 659, 7: 655, 23: 648, 27: 646, 24: 645, 29: 643, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 22: 592, 21: 586, 19: 584, 12: 583, 9: 576, 20: 572, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.12294459342956543
auxiliary_graph
Graph(num_nodes=1377742, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.6977944374084473
remove nodes length  1181171

auxiliary_graph.remove_nodes spent  5.3769285678863525
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=101873543,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  4.432307004928589

the counter of shared neighbor distribution
Counter({1.0: 76625834, 2.0: 14048222, 3.0: 5011620, 4.0: 2308328, 5.0: 1244288, 6.0: 737614, 7.0: 469104, 8.0: 320932, 9.0: 223716, 10.0: 162494, 11.0: 118854, 12.0: 89870, 13.0: 69466, 14.0: 53028, 15.0: 41764, 16.0: 31248, 17.0: 22002, 18.0: 19492, 19.0: 13018, 20.0: 10882, 21.0: 7144, 22.0: 5740, 23.0: 4796, 24.0: 3814, 25.0: 3584, 33.0: 3046, 28.0: 2926, 26.0: 2688, 30.0: 2312, 27.0: 2286, 31.0: 2154, 39.0: 2098, 32.0: 2040, 35.0: 1750, 29.0: 1680, 37.0: 1650, 36.0: 1526, 38.0: 1460, 34.0: 1422, 40.0: 1080})
101676972
Convert a graph into a bidirected graph: 6.305 seconds
Metis partitioning: 22.317 seconds
Split the graph: 4.460 seconds
Construct subgraphs: 0.038 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  33.1624174118042
31825
33438
33736
32833
31832
32907
total k batches seeds list generation spend  64.33723902702332
after graph partition
graph partition algorithm spend time 65.32299399375916
31825
33438
33736
32833
31832
32907
partition_len_list
[264647, 297767, 271798, 326134, 335551, 302902]
REG selection method  spend 66.02136182785034
time for parepare:  0.2710576057434082
local_output_nid generation:  0.006494998931884766
local_in_edges_tensor generation:  0.014401912689208984
mini_batch_src_global generation:  0.03661918640136719
r_  generation:  0.41338324546813965
local_output_nid generation:  0.007681131362915039
local_in_edges_tensor generation:  0.02702474594116211
mini_batch_src_global generation:  0.048944711685180664
r_  generation:  0.4893503189086914
local_output_nid generation:  0.007773160934448242
local_in_edges_tensor generation:  0.02274918556213379
mini_batch_src_global generation:  0.04513907432556152
r_  generation:  0.5053224563598633
local_output_nid generation:  0.007845878601074219
local_in_edges_tensor generation:  0.015361547470092773
mini_batch_src_global generation:  0.0456697940826416
r_  generation:  0.5327694416046143
local_output_nid generation:  0.007770061492919922
local_in_edges_tensor generation:  0.01711583137512207
mini_batch_src_global generation:  0.06130790710449219
r_  generation:  0.5006487369537354
local_output_nid generation:  0.008940458297729492
local_in_edges_tensor generation:  0.041939735412597656
mini_batch_src_global generation:  0.05794334411621094
r_  generation:  0.583702564239502
----------------------check_connections_block total spend ----------------------------- 4.367217779159546
generate_one_block  2.0074338912963867
generate_one_block  0.6407697200775146
generate_one_block  0.6304337978363037
generate_one_block  0.6296534538269043
generate_one_block  0.5717897415161133
generate_one_block  0.6681234836578369
The real block id is  2
get_global_graph_edges_ids_block function  spend 1.8807852268218994
gen group dst list time:  0.04809212684631348
time for parepare:  0.437028169631958
local_output_nid generation:  0.057871341705322266
local_in_edges_tensor generation:  0.2686781883239746
mini_batch_src_global generation:  0.2167041301727295
r_  generation:  2.648545026779175
local_output_nid generation:  0.10435748100280762
local_in_edges_tensor generation:  0.23142337799072266
mini_batch_src_global generation:  0.30378079414367676
r_  generation:  3.3045759201049805
local_output_nid generation:  0.07364654541015625
local_in_edges_tensor generation:  0.2563445568084717
mini_batch_src_global generation:  0.2807037830352783
r_  generation:  2.632185935974121
local_output_nid generation:  0.09553217887878418
local_in_edges_tensor generation:  0.23348212242126465
mini_batch_src_global generation:  0.33100271224975586
r_  generation:  3.574028968811035
local_output_nid generation:  0.09552764892578125
local_in_edges_tensor generation:  0.34946727752685547
mini_batch_src_global generation:  0.3849468231201172
r_  generation:  3.807199001312256
local_output_nid generation:  0.08401250839233398
local_in_edges_tensor generation:  0.2027454376220703
mini_batch_src_global generation:  0.3562173843383789
r_  generation:  3.4296772480010986
----------------------check_connections_block total spend ----------------------------- 27.25577139854431
generate_one_block  3.914064645767212
generate_one_block  4.2029969692230225
generate_one_block  3.2748844623565674
generate_one_block  4.551447153091431
generate_one_block  5.118490695953369
generate_one_block  4.448047399520874
The real block id is  1
get_global_graph_edges_ids_block function  spend 2.1262564659118652
gen group dst list time:  0.19678282737731934
time for parepare:  0.47000598907470703
local_output_nid generation:  0.23228168487548828
local_in_edges_tensor generation:  0.6097068786621094
mini_batch_src_global generation:  0.5372614860534668
r_  generation:  8.282414436340332
local_output_nid generation:  0.2987332344055176
local_in_edges_tensor generation:  0.7115097045898438
mini_batch_src_global generation:  0.7917506694793701
r_  generation:  8.997471570968628
local_output_nid generation:  0.21977996826171875
local_in_edges_tensor generation:  0.4834156036376953
mini_batch_src_global generation:  0.5977513790130615
r_  generation:  6.314291000366211
local_output_nid generation:  0.3257615566253662
local_in_edges_tensor generation:  0.6285605430603027
mini_batch_src_global generation:  0.7706747055053711
r_  generation:  9.736342668533325
local_output_nid generation:  0.3414609432220459
local_in_edges_tensor generation:  0.757925271987915
mini_batch_src_global generation:  0.9575831890106201
r_  generation:  11.192802906036377
local_output_nid generation:  0.28238630294799805
local_in_edges_tensor generation:  0.5658533573150635
mini_batch_src_global generation:  0.8319118022918701
r_  generation:  8.231565952301025
----------------------check_connections_block total spend ----------------------------- 72.35733199119568
generate_one_block  10.007811307907104
generate_one_block  11.341098070144653
generate_one_block  7.736847400665283
generate_one_block  12.138173818588257
generate_one_block  14.222606658935547
generate_one_block  10.057382583618164
The real block id is  0
get_global_graph_edges_ids_block function  spend 1.0849013328552246
gen group dst list time:  0.40786194801330566
time for parepare:  0.46651124954223633
local_output_nid generation:  0.5519170761108398
local_in_edges_tensor generation:  0.9380836486816406
mini_batch_src_global generation:  0.5127654075622559
r_  generation:  8.103581190109253
local_output_nid generation:  0.638634204864502
local_in_edges_tensor generation:  0.9306216239929199
mini_batch_src_global generation:  0.6450014114379883
r_  generation:  8.71148419380188
local_output_nid generation:  0.5564072132110596
local_in_edges_tensor generation:  0.7885246276855469
mini_batch_src_global generation:  0.594043493270874
r_  generation:  7.497662544250488
local_output_nid generation:  0.5874249935150146
local_in_edges_tensor generation:  0.8361897468566895
mini_batch_src_global generation:  0.657764196395874
r_  generation:  9.01649808883667
local_output_nid generation:  0.6261563301086426
local_in_edges_tensor generation:  0.9230380058288574
mini_batch_src_global generation:  0.7110040187835693
r_  generation:  9.155406475067139
local_output_nid generation:  0.5348544120788574
local_in_edges_tensor generation:  0.7408933639526367
mini_batch_src_global generation:  0.6830179691314697
r_  generation:  7.971469879150391
----------------------check_connections_block total spend ----------------------------- 73.64357233047485
generate_one_block  11.122003316879272
generate_one_block  10.53643536567688
generate_one_block  9.535560846328735
generate_one_block  10.794490575790405
generate_one_block  11.089637041091919
generate_one_block  9.73404049873352
----------===============-------------===============-------------the number of batches *****---- 6

original number of batches:  6
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

connection checking time:  177.6238934993744
block generation total time  158.97422289848328
average batch blocks generation time:  6.62392595410347
block dataloader generation time/epoch 418.87471175193787
pseudo mini batch 0 input nodes size: 2088643
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7967529296875 GB
    Memory Allocated: 0.7793374061584473  GigaBytes
Max Memory Allocated: 0.7793374061584473  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7967529296875 GB
    Memory Allocated: 0.7795748710632324  GigaBytes
Max Memory Allocated: 0.7795748710632324  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7967529296875 GB
    Memory Allocated: 0.7795748710632324  GigaBytes
Max Memory Allocated: 0.7795748710632324  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 2.1854248046875 GB
    Memory Allocated: 1.0894684791564941  GigaBytes
Max Memory Allocated: 1.0894684791564941  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.1854248046875 GB
    Memory Allocated: 1.0894684791564941  GigaBytes
Max Memory Allocated: 1.0894684791564941  GigaBytes

first layer input nodes number: 2088643
first layer output nodes number: 1749084
edges number: 16099126
torch.Size([2088643, 100])
torch.Size([1749084, 256])
input nodes number: 1749084
output nodes number: 836513
edges number: 17335735
torch.Size([1749084, 256])
torch.Size([836513, 256])
input nodes number: 836513
output nodes number: 264647
edges number: 6802009
torch.Size([836513, 256])
torch.Size([264647, 256])
torch.Size([31825, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 11.9471435546875 GB
    Memory Allocated: 9.331570148468018  GigaBytes
Max Memory Allocated: 9.5330171585083  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 11.9471435546875 GB
    Memory Allocated: 9.337404727935791  GigaBytes
Max Memory Allocated: 9.5330171585083  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 1.673398494720459  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

pseudo mini batch 1 input nodes size: 2075962
----------------------------------------before load block subtensor 
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 0.7865633964538574  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 0.7865633964538574  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 1.559919834136963  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 1.5601692199707031  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 0.7818512916564941  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 1.1254353523254395  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 18.2635498046875 GB
    Memory Allocated: 1.1254353523254395  GigaBytes
Max Memory Allocated: 10.133874416351318  GigaBytes

first layer input nodes number: 2075962
first layer output nodes number: 1792543
edges number: 16581898
torch.Size([2075962, 100])
torch.Size([1792543, 256])
input nodes number: 1792543
output nodes number: 934356
edges number: 20219011
torch.Size([1792543, 256])
torch.Size([934356, 256])
input nodes number: 934356
output nodes number: 297767
edges number: 8011364
torch.Size([934356, 256])
torch.Size([297767, 256])
torch.Size([33438, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 23.4901123046875 GB
    Memory Allocated: 9.917438507080078  GigaBytes
Max Memory Allocated: 10.152832984924316  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 23.4901123046875 GB
    Memory Allocated: 9.924107074737549  GigaBytes
Max Memory Allocated: 10.152832984924316  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.7747774124145508  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

pseudo mini batch 2 input nodes size: 1991781
----------------------------------------before load block subtensor 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 0.7819757461547852  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 0.7819757461547852  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.5239720344543457  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.524223804473877  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 0.7506179809570312  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.0198593139648438  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.0198593139648438  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

first layer input nodes number: 1991781
first layer output nodes number: 1585686
edges number: 14515612
torch.Size([1991781, 100])
torch.Size([1585686, 256])
input nodes number: 1585686
output nodes number: 727979
edges number: 13953148
torch.Size([1585686, 256])
torch.Size([727979, 256])
input nodes number: 727979
output nodes number: 271798
edges number: 6407011
torch.Size([727979, 256])
torch.Size([271798, 256])
torch.Size([33736, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 8.486552238464355  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 8.492459774017334  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.5233802795410156  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

pseudo mini batch 3 input nodes size: 2104668
----------------------------------------before load block subtensor 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 0.7506699562072754  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 0.7506699562072754  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.5347199440002441  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.5349650382995605  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 0.7927169799804688  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.1528892517089844  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.0819091796875 GB
    Memory Allocated: 1.1528892517089844  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

first layer input nodes number: 2104668
first layer output nodes number: 1834994
edges number: 17024265
torch.Size([2104668, 100])
torch.Size([1834994, 256])
input nodes number: 1834994
output nodes number: 1016661
edges number: 21621759
torch.Size([1834994, 256])
torch.Size([1016661, 256])
input nodes number: 1016661
output nodes number: 326134
edges number: 8459956
torch.Size([1016661, 256])
torch.Size([326134, 256])
torch.Size([32833, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.4100341796875 GB
    Memory Allocated: 10.412130355834961  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.4100341796875 GB
    Memory Allocated: 10.417879581451416  GigaBytes
Max Memory Allocated: 10.8130784034729  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 1.8327927589416504  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

pseudo mini batch 4 input nodes size: 2122800
----------------------------------------before load block subtensor 
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 0.7925586700439453  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 0.7925586700439453  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 1.5833635330200195  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 1.5836009979248047  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 0.7993059158325195  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 1.1938953399658203  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 22.1990966796875 GB
    Memory Allocated: 1.1938953399658203  GigaBytes
Max Memory Allocated: 11.379944324493408  GigaBytes

first layer input nodes number: 2122800
first layer output nodes number: 1897354
edges number: 17462803
torch.Size([2122800, 100])
torch.Size([1897354, 256])
input nodes number: 1897354
output nodes number: 1158224
edges number: 25253394
torch.Size([1897354, 256])
torch.Size([1158224, 256])
input nodes number: 1158224
output nodes number: 335551
edges number: 9101997
torch.Size([1158224, 256])
torch.Size([335551, 256])
torch.Size([31832, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 17.3905029296875 GB
    Memory Allocated: 11.118196487426758  GigaBytes
Max Memory Allocated: 11.391898155212402  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 17.3905029296875 GB
    Memory Allocated: 11.123770713806152  GigaBytes
Max Memory Allocated: 11.391898155212402  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 1.94401216506958  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

pseudo mini batch 5 input nodes size: 1975895
----------------------------------------before load block subtensor 
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 0.799130916595459  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 0.799130916595459  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 1.5352091789245605  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 1.5354547500610352  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 0.7444124221801758  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 1.0643949508666992  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 1.0643949508666992  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

first layer input nodes number: 1975895
first layer output nodes number: 1596912
edges number: 15013048
torch.Size([1975895, 100])
torch.Size([1596912, 256])
input nodes number: 1596912
output nodes number: 827492
edges number: 18325278
torch.Size([1596912, 256])
torch.Size([827492, 256])
input nodes number: 827492
output nodes number: 302902
edges number: 8307880
torch.Size([827492, 256])
torch.Size([302902, 256])
torch.Size([32907, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 9.017773151397705  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 9.02353572845459  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.3670654296875 GB
    Memory Allocated: 1.6711316108703613  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 20.3709716796875 GB
    Memory Allocated: 1.6736454963684082  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 20.3709716796875 GB
    Memory Allocated: 1.6736454963684082  GigaBytes
Max Memory Allocated: 12.33379077911377  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.35580281416575116 |0.48693517843882245 |0.3457955519358317 |0.0001685619354248047 |0.17392146587371826 |0.005708217620849609 |
----------------------------------------------------------pseudo_mini_loss sum 11.023653030395508
Total (block generation + training)time/epoch 427.31925678253174
Training time/epoch 8.444196224212646
Training time without block to device /epoch 5.522585153579712
Training time without total dataloading part /epoch 3.1250216960906982
load block tensor time/epoch 2.134816884994507
block to device time/epoch 2.9216110706329346
input features size transfer per epoch 8.046627044677734e-07
blocks size to device per epoch 5.364418029785156e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  30116346
Number of first layer input nodes during this epoch:  12359749
Number of first layer output nodes during this epoch:  10456573
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  337408
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 100])
layers.0.fc_neigh.weight, torch.Size([256, 100])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([47, 256])
layers.3.fc_neigh.weight, torch.Size([47, 256])
----------------------------------------
un-trainable parameters
