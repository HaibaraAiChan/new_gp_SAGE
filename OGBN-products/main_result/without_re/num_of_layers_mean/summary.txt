4-layer graphsage model + mean 
fan-out = 10, 25,30,40
full batch train OOM
2-batches OOM

now use Betty w/o re-partition
3 batches break OOM
batches: 
4
8
16
32
64
128
256
512 
1024
---------------------------------------------------------------------------
computation eff
{3: 6988473.142209151, 4: 7369443.451421326, 8: 10755453.219287915, 16: 19937744.733959105, 32: 23271690.48083898, 64: 27764294.70788566, 128: 32482844.338110186, 256: 33139405.318092257, 512: 34280851.75371144, 1024: 33411127.737670068}
time
{3: 2.506157875061035, 4: 2.975405693054199, 8: 3.5301332473754883, 16: 3.1604344844818115, 32: 4.628453016281128, 64: 6.363028049468994, 128: 8.851359844207764, 256: 14.07154107093811, 512: 20.645092487335205, 1024: 31.64606499671936}

CUDA max mem
{3: 14.148282051086426, 4: 13.614392280578613, 8: 11.166667938232422, 16: 9.29109811782837, 32: 8.457416534423828, 64: 7.119265556335449, 128: 6.824272632598877, 256: 5.424062252044678, 512: 4.655151844024658, 1024: 3.5102081298828125}

=====================================================================================

then find the number of batches break OOM in  5-layer model



