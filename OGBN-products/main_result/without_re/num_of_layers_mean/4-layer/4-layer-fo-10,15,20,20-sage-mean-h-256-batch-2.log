main start at this time 1656196710.3248658
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.12125897407531738
global_2_local spend time (sec) 0.34149813652038574
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.020761966705322266
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 922613, 20: 186421, 14: 695, 15: 673, 7: 655, 10: 640, 11: 624, 13: 615, 16: 614, 18: 604, 19: 584, 12: 583, 9: 576, 17: 556, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.06269121170043945
auxiliary_graph
Graph(num_nodes=1119184, num_edges=36540905,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.4799947738647461
remove nodes length  922613

auxiliary_graph.remove_nodes spent  2.1151058673858643
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=36540905,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  1.537020206451416

the counter of shared neighbor distribution
Counter({1.0: 31140054, 2.0: 3562032, 3.0: 936314, 4.0: 353346, 5.0: 158050, 6.0: 74884, 7.0: 40914, 8.0: 22002, 9.0: 14150, 10.0: 9804, 11.0: 6358, 15.0: 4674, 12.0: 4526, 14.0: 4146, 13.0: 3320, 18.0: 2748, 16.0: 2586, 17.0: 1756, 19.0: 1404, 20.0: 1266})
36344334
Convert a graph into a bidirected graph: 2.001 seconds
Metis partitioning: 8.391 seconds
Split the graph: 4.600 seconds
Construct subgraphs: 0.008 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  15.014809608459473
99724
96847
total k batches seeds list generation spend  25.896047830581665
after graph partition
graph partition algorithm spend time 26.6091091632843
99724
96847
partition_len_list
[579028, 602544]
REG selection method  spend 27.174588680267334
time for parepare:  0.21889257431030273
local_output_nid generation:  0.014547586441040039
local_in_edges_tensor generation:  0.031074047088623047
mini_batch_src_global generation:  0.06570219993591309
r_  generation:  0.8594110012054443
local_output_nid generation:  0.01246953010559082
local_in_edges_tensor generation:  0.04290032386779785
mini_batch_src_global generation:  0.07840347290039062
r_  generation:  0.8765621185302734
----------------------check_connections_block total spend ----------------------------- 2.5597822666168213
generate_one_block  2.5915565490722656
generate_one_block  1.0373177528381348
The real block id is  2
get_global_graph_edges_ids_block function  spend 1.3187298774719238
gen group dst list time:  0.03933548927307129
time for parepare:  0.4174983501434326
local_output_nid generation:  0.08194804191589355
local_in_edges_tensor generation:  0.3132143020629883
mini_batch_src_global generation:  0.3438534736633301
r_  generation:  4.720819473266602
local_output_nid generation:  0.09506797790527344
local_in_edges_tensor generation:  0.2552933692932129
mini_batch_src_global generation:  0.4766521453857422
r_  generation:  5.305910348892212
----------------------check_connections_block total spend ----------------------------- 13.732570886611938
generate_one_block  6.404398441314697
generate_one_block  6.409620046615601
The real block id is  1
get_global_graph_edges_ids_block function  spend 1.5429482460021973
gen group dst list time:  0.09987545013427734
time for parepare:  0.43369126319885254
local_output_nid generation:  0.22810053825378418
local_in_edges_tensor generation:  0.6199252605438232
mini_batch_src_global generation:  0.5359423160552979
r_  generation:  7.922349214553833
local_output_nid generation:  0.2343764305114746
local_in_edges_tensor generation:  0.5167920589447021
mini_batch_src_global generation:  0.704596996307373
r_  generation:  8.832305431365967
----------------------check_connections_block total spend ----------------------------- 22.84060287475586
generate_one_block  10.34784197807312
generate_one_block  10.505614042282104
The real block id is  0
get_global_graph_edges_ids_block function  spend 1.222989797592163
gen group dst list time:  0.16373324394226074
time for parepare:  0.4650237560272217
local_output_nid generation:  0.4192318916320801
local_in_edges_tensor generation:  0.8237013816833496
mini_batch_src_global generation:  0.5543203353881836
r_  generation:  8.759379386901855
local_output_nid generation:  0.4505774974822998
local_in_edges_tensor generation:  0.7409603595733643
mini_batch_src_global generation:  0.6721374988555908
r_  generation:  8.714526414871216
----------------------check_connections_block total spend ----------------------------- 24.90052580833435
generate_one_block  11.173255443572998
generate_one_block  10.96256422996521
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

connection checking time:  64.03348183631897
block generation total time  59.43216848373413
average batch blocks generation time:  7.429021060466766
block dataloader generation time/epoch 159.8535430431366
pseudo mini batch 0 input nodes size: 2108767
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012569427490234375  GigaBytes
Max Memory Allocated: 0.0012569427490234375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.8045654296875 GB
    Memory Allocated: 0.7868342399597168  GigaBytes
Max Memory Allocated: 0.7868342399597168  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.8065185546875 GB
    Memory Allocated: 0.7875776290893555  GigaBytes
Max Memory Allocated: 0.7875776290893555  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.8065185546875 GB
    Memory Allocated: 0.7875776290893555  GigaBytes
Max Memory Allocated: 0.7875776290893555  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 2.2225341796875 GB
    Memory Allocated: 1.1273984909057617  GigaBytes
Max Memory Allocated: 1.1273984909057617  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.2225341796875 GB
    Memory Allocated: 1.1273984909057617  GigaBytes
Max Memory Allocated: 1.1273984909057617  GigaBytes

first layer input nodes number: 2108767
first layer output nodes number: 1843027
edges number: 16760572
torch.Size([2108767, 100])
torch.Size([1843027, 256])
input nodes number: 1843027
output nodes number: 1241548
edges number: 16315897
torch.Size([1843027, 256])
torch.Size([1241548, 256])
input nodes number: 1241548
output nodes number: 579028
edges number: 10567630
torch.Size([1241548, 256])
torch.Size([579028, 256])
torch.Size([99724, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 15.5389404296875 GB
    Memory Allocated: 11.971161365509033  GigaBytes
Max Memory Allocated: 12.37807321548462  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 15.5389404296875 GB
    Memory Allocated: 11.988623142242432  GigaBytes
Max Memory Allocated: 12.37807321548462  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.3455810546875 GB
    Memory Allocated: 1.7948026657104492  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

pseudo mini batch 1 input nodes size: 2083830
----------------------------------------before load block subtensor 
 Nvidia-smi: 21.3455810546875 GB
    Memory Allocated: 0.8062963485717773  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 21.3455810546875 GB
    Memory Allocated: 0.8062963485717773  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 21.3455810546875 GB
    Memory Allocated: 1.5825839042663574  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 21.3475341796875 GB
    Memory Allocated: 1.583305835723877  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 21.3475341796875 GB
    Memory Allocated: 0.7969851493835449  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 21.3475341796875 GB
    Memory Allocated: 1.152172565460205  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 21.3475341796875 GB
    Memory Allocated: 1.152172565460205  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

first layer input nodes number: 2083830
first layer output nodes number: 1813170
edges number: 16760734
torch.Size([2083830, 100])
torch.Size([1813170, 256])
input nodes number: 1813170
output nodes number: 1286621
edges number: 17629855
torch.Size([1813170, 256])
torch.Size([1286621, 256])
input nodes number: 1286621
output nodes number: 602544
edges number: 11373682
torch.Size([1286621, 256])
torch.Size([602544, 256])
torch.Size([96847, 47])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 18.8533935546875 GB
    Memory Allocated: 12.127427577972412  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 18.8533935546875 GB
    Memory Allocated: 12.144888877868652  GigaBytes
Max Memory Allocated: 12.979933261871338  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 20.6580810546875 GB
    Memory Allocated: 1.8356118202209473  GigaBytes
Max Memory Allocated: 13.184201717376709  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 20.6600341796875 GB
    Memory Allocated: 1.8381257057189941  GigaBytes
Max Memory Allocated: 13.184201717376709  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 20.6600341796875 GB
    Memory Allocated: 1.8381257057189941  GigaBytes
Max Memory Allocated: 13.184201717376709  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.35368895530700684 |0.5891995429992676 |0.6571711301803589 |0.00027108192443847656 |0.12209963798522949 |0.007054567337036133 |
----------------------------------------------------------pseudo_mini_loss sum 11.271672248840332
Total (block generation + training)time/epoch 163.65362787246704
Training time/epoch 3.7997405529022217
Training time without block to device /epoch 2.6213414669036865
Training time without total dataloading part /epoch 1.5661382675170898
load block tensor time/epoch 0.7073779106140137
block to device time/epoch 1.1783990859985352
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  11558535
Number of first layer input nodes during this epoch:  4192597
Number of first layer output nodes during this epoch:  3656197
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  337408
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 100])
layers.0.fc_neigh.weight, torch.Size([256, 100])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([47, 256])
layers.3.fc_neigh.weight, torch.Size([47, 256])
----------------------------------------
un-trainable parameters
