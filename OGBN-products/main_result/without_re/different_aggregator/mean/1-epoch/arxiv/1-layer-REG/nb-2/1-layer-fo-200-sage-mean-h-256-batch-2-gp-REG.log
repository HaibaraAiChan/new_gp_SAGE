main start at this time 1658034933.7186174
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  128
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 3.814697265625e-05  GigaBytes
Max Memory Allocated: 3.814697265625e-05  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 3.814697265625e-05  GigaBytes
Max Memory Allocated: 3.814697265625e-05  GigaBytes

The real block id is  0
get_global_graph_edges_ids_block function  spend 0.03492236137390137
global_2_local spend time (sec) 0.03609728813171387
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.006185054779052734
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 70509, 1: 13428, 2: 11706, 3: 9277, 4: 7320, 5: 6222, 6: 4868, 7: 4045, 8: 3472, 9: 2976, 10: 2599, 11: 2203, 12: 1937, 13: 1656, 14: 1434, 15: 1289, 16: 1111, 17: 1030, 18: 948, 19: 836, 20: 807, 21: 717, 200: 575, 22: 556, 24: 525, 23: 519, 25: 483, 26: 409, 27: 390, 28: 370, 29: 329, 31: 300, 32: 273, 30: 261, 33: 261, 34: 231, 36: 226, 35: 200, 39: 200, 37: 196, 38: 186, 41: 167, 42: 165, 40: 161, 45: 142, 43: 138, 44: 135, 48: 112, 46: 106, 47: 105, 51: 104, 49: 91, 55: 90, 50: 89, 52: 81, 53: 79, 54: 78, 58: 73, 56: 71, 61: 69, 67: 68, 57: 68, 72: 63, 60: 63, 62: 62, 59: 55, 65: 54, 63: 52, 66: 51, 64: 49, 69: 47, 70: 44, 71: 43, 68: 42, 77: 40, 86: 39, 87: 38, 74: 36, 75: 35, 82: 35, 81: 35, 84: 33, 73: 32, 80: 31, 76: 31, 105: 30, 94: 29, 98: 29, 83: 29, 95: 27, 112: 27, 79: 27, 85: 27, 91: 27, 99: 26, 88: 25, 111: 25, 92: 24, 101: 24, 89: 24, 90: 23, 93: 22, 78: 22, 97: 21, 96: 20, 103: 20, 109: 20, 122: 20, 117: 19, 104: 18, 113: 18, 123: 18, 100: 18, 106: 17, 108: 17, 133: 17, 107: 17, 130: 16, 116: 16, 102: 16, 115: 14, 125: 14, 128: 14, 127: 13, 134: 13, 161: 13, 153: 13, 118: 13, 136: 13, 120: 12, 121: 12, 146: 12, 124: 12, 114: 12, 145: 11, 151: 11, 140: 11, 157: 11, 155: 11, 166: 11, 110: 10, 170: 10, 150: 10, 132: 9, 135: 9, 129: 9, 141: 9, 119: 9, 152: 8, 181: 8, 143: 8, 126: 8, 156: 8, 162: 8, 137: 8, 165: 8, 149: 7, 186: 7, 148: 7, 182: 7, 154: 7, 172: 7, 199: 6, 168: 6, 144: 6, 197: 6, 159: 6, 139: 6, 178: 6, 194: 6, 167: 6, 171: 5, 131: 5, 176: 5, 185: 5, 142: 5, 147: 5, 177: 5, 160: 5, 173: 5, 195: 5, 138: 4, 179: 4, 190: 4, 183: 4, 175: 4, 198: 4, 163: 4, 164: 4, 192: 3, 196: 3, 191: 3, 174: 3, 158: 3, 187: 3, 169: 2, 193: 2, 184: 2, 188: 2, 180: 2, 189: 2})

A = g.adjacency_matrix() spent  0.018400907516479492
auxiliary_graph
Graph(num_nodes=161450, num_edges=44597267,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0872187614440918
remove nodes length  70509

auxiliary_graph.remove_nodes spent  2.1750097274780273
after remove non output nodes the auxiliary_graph
Graph(num_nodes=90941, num_edges=44597267,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  1.9826123714447021

the counter of shared neighbor distribution
Counter({1.0: 32153036, 2.0: 7734430, 3.0: 2556662, 4.0: 978318, 5.0: 436336, 6.0: 220856, 7.0: 125792, 8.0: 77806, 9.0: 51272, 10.0: 35676, 11.0: 25592, 12.0: 19254, 13.0: 14676, 14.0: 11782, 15.0: 9404, 16.0: 7328, 17.0: 6098, 18.0: 5070, 19.0: 4234, 20.0: 3628, 21.0: 3120, 22.0: 2762, 23.0: 2260, 24.0: 1978, 25.0: 1794, 26.0: 1616, 27.0: 1436, 28.0: 1278, 29.0: 1160, 30.0: 1032, 31.0: 930, 33.0: 836, 32.0: 820, 34.0: 664, 35.0: 588, 36.0: 540, 37.0: 466, 38.0: 446, 39.0: 414, 40.0: 372, 41.0: 342, 43.0: 324, 44.0: 298, 42.0: 292, 45.0: 262, 48.0: 220, 47.0: 184, 49.0: 184, 46.0: 178, 50.0: 148, 54.0: 134, 52.0: 132, 53.0: 130, 55.0: 124, 56.0: 124, 51.0: 110, 59.0: 102, 58.0: 102, 57.0: 90, 61.0: 80, 60.0: 68, 62.0: 68, 64.0: 64, 66.0: 60, 63.0: 54, 67.0: 52, 65.0: 52, 70.0: 46, 68.0: 44, 72.0: 36, 75.0: 34, 69.0: 34, 71.0: 32, 79.0: 32, 78.0: 30, 74.0: 26, 80.0: 24, 77.0: 22, 81.0: 22, 76.0: 20, 73.0: 20, 83.0: 18, 84.0: 16, 82.0: 14, 87.0: 14, 88.0: 12, 95.0: 10, 97.0: 8, 90.0: 6, 105.0: 6, 94.0: 6, 93.0: 6, 86.0: 6, 99.0: 4, 89.0: 4, 92.0: 4, 107.0: 4, 91.0: 4, 111.0: 2, 122.0: 2, 120.0: 2, 85.0: 2, 112.0: 2, 96.0: 2, 101.0: 2, 127.0: 2, 98.0: 2, 104.0: 2, 110.0: 2})
44506326
Convert a graph into a bidirected graph: 2.059 seconds
Metis partitioning: 6.761 seconds
Split the graph: 6.525 seconds
Construct subgraphs: 0.043 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  15.406685829162598
46499
44442
total k batches seeds list generation spend  26.60256004333496
after graph partition
graph partition algorithm spend time 26.776417016983032
46499
44442
partition_len_list
[72356, 108671]
REG selection method  spend 26.86238956451416
time for parepare:  0.017724275588989258
local_output_nid generation:  0.00438380241394043
local_in_edges_tensor generation:  0.0071544647216796875
mini_batch_src_global generation:  0.015131950378417969
r_  generation:  0.14024972915649414
local_output_nid generation:  0.005820512771606445
local_in_edges_tensor generation:  0.019649744033813477
mini_batch_src_global generation:  0.029345273971557617
r_  generation:  0.2271873950958252
----------------------check_connections_block total spend ----------------------------- 0.557884931564331
generate_one_block  0.18739676475524902
generate_one_block  0.29898810386657715
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 3.814697265625e-05  GigaBytes
Max Memory Allocated: 3.814697265625e-05  GigaBytes

connection checking time:  0.557884931564331
block generation total time  0.48638486862182617
average batch blocks generation time:  0.24319243431091309
block dataloader generation time/epoch 28.0171856880188
pseudo mini batch 0 input nodes size: 72356
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 3.814697265625e-05  GigaBytes
Max Memory Allocated: 3.814697265625e-05  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 3.814697265625e-05  GigaBytes
Max Memory Allocated: 3.814697265625e-05  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0526123046875 GB
    Memory Allocated: 0.03519439697265625  GigaBytes
Max Memory Allocated: 0.03519439697265625  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0526123046875 GB
    Memory Allocated: 0.03554105758666992  GigaBytes
Max Memory Allocated: 0.03554105758666992  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0526123046875 GB
    Memory Allocated: 0.03554105758666992  GigaBytes
Max Memory Allocated: 0.03554105758666992  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1365966796875 GB
    Memory Allocated: 0.03861093521118164  GigaBytes
Max Memory Allocated: 0.03861093521118164  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1365966796875 GB
    Memory Allocated: 0.03861093521118164  GigaBytes
Max Memory Allocated: 0.03861093521118164  GigaBytes

----------------input nodes number: 72356
----------------output nodes number: 46499
----------------edges number: 411925
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1365966796875 GB
    Memory Allocated: 0.03949689865112305  GigaBytes
Max Memory Allocated: 0.041031837463378906  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3748779296875 GB
    Memory Allocated: 0.07184171676635742  GigaBytes
Max Memory Allocated: 0.08725881576538086  GigaBytes

h_neigh size torch.Size([46499, 40])
torch.Size([46499, 40])
torch.Size([46499, 40])
----------------------------------------after rst
 Nvidia-smi: 1.3748779296875 GB
    Memory Allocated: 0.07877063751220703  GigaBytes
Max Memory Allocated: 0.08725881576538086  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3748779296875 GB
    Memory Allocated: 0.07184171676635742  GigaBytes
Max Memory Allocated: 0.08725881576538086  GigaBytes

torch.Size([46499, 40])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3748779296875 GB
    Memory Allocated: 0.07877063751220703  GigaBytes
Max Memory Allocated: 0.08725881576538086  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3748779296875 GB
    Memory Allocated: 0.08570051193237305  GigaBytes
Max Memory Allocated: 0.08725881576538086  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3944091796875 GB
    Memory Allocated: 0.04970836639404297  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

pseudo mini batch 1 input nodes size: 108671
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.3944091796875 GB
    Memory Allocated: 0.04250907897949219  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.3944091796875 GB
    Memory Allocated: 0.04250907897949219  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09524345397949219  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09557485580444336  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.06007194519042969  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.0652008056640625  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.0652008056640625  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------input nodes number: 108671
----------------output nodes number: 44442
----------------edges number: 688279
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.06634187698364258  GigaBytes
Max Memory Allocated: 0.09955835342407227  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09945106506347656  GigaBytes
Max Memory Allocated: 0.11418581008911133  GigaBytes

h_neigh size torch.Size([44442, 40])
torch.Size([44442, 40])
torch.Size([44442, 40])
----------------------------------------after rst
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.10607385635375977  GigaBytes
Max Memory Allocated: 0.11418581008911133  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09945106506347656  GigaBytes
Max Memory Allocated: 0.11418581008911133  GigaBytes

torch.Size([44442, 40])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09914493560791016  GigaBytes
Max Memory Allocated: 0.11418581008911133  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.10607433319091797  GigaBytes
Max Memory Allocated: 0.11418581008911133  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07133054733276367  GigaBytes
Max Memory Allocated: 0.12003898620605469  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07140684127807617  GigaBytes
Max Memory Allocated: 0.12003898620605469  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07140684127807617  GigaBytes
Max Memory Allocated: 0.12003898620605469  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.03729593753814697 |0.17361092567443848 |0.38996410369873047 |0.0002589225769042969 |0.0022814273834228516 |0.0011134147644042969 |
----------------------------------------------------------pseudo_mini_loss sum 3.8567540645599365
Total (block generation + training)time/epoch 29.232035160064697
Training time/epoch 1.2143945693969727
Training time without block to device /epoch 0.8671727180480957
Training time without total dataloading part /epoch 0.7861223220825195
load block tensor time/epoch 0.07459187507629395
block to device time/epoch 0.34722185134887695
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  181027
Number of first layer input nodes during this epoch:  181027
Number of first layer output nodes during this epoch:  90941
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=128, out_features=40, bias=False)
      (fc_neigh): Linear(in_features=128, out_features=40, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  10240
trainable parameters
layers.0.fc_self.weight, torch.Size([40, 128])
layers.0.fc_neigh.weight, torch.Size([40, 128])
----------------------------------------
un-trainable parameters
