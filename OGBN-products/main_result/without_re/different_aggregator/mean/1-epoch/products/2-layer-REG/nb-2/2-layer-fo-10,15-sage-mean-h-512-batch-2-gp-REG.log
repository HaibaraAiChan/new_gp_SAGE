main start at this time 1658188912.903325
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.000560760498046875  GigaBytes
Max Memory Allocated: 0.000560760498046875  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.000560760498046875  GigaBytes
Max Memory Allocated: 0.000560760498046875  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.08321309089660645
global_2_local spend time (sec) 0.31465816497802734
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.015866518020629883
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 809158, 15: 189452, 14: 695, 7: 655, 10: 640, 11: 624, 13: 615, 12: 583, 9: 576, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.04961037635803223
auxiliary_graph
Graph(num_nodes=1005729, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.4908630847930908
remove nodes length  809158

auxiliary_graph.remove_nodes spent  1.2863445281982422
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.9237620830535889

the counter of shared neighbor distribution
Counter({1.0: 19991684, 2.0: 1794372, 3.0: 401822, 4.0: 133762, 5.0: 53900, 6.0: 23014, 7.0: 13780, 8.0: 6972, 9.0: 5604, 10.0: 3978, 14.0: 3312, 12.0: 3152, 15.0: 3114, 11.0: 2724, 13.0: 2078})
22443268
Convert a graph into a bidirected graph: 1.157 seconds
Metis partitioning: 4.936 seconds
Split the graph: 2.537 seconds
Construct subgraphs: 0.067 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  8.707324981689453
99297
97274
total k batches seeds list generation spend  15.997333288192749
after graph partition
graph partition algorithm spend time 16.43477153778076
99297
97274
partition_len_list
[516761, 537341]
REG selection method  spend 16.963667154312134
time for parepare:  0.20412850379943848
local_output_nid generation:  0.012655496597290039
local_in_edges_tensor generation:  0.016151905059814453
mini_batch_src_global generation:  0.043839216232299805
r_  generation:  0.6579022407531738
local_output_nid generation:  0.013870000839233398
local_in_edges_tensor generation:  0.03810596466064453
mini_batch_src_global generation:  0.07034087181091309
r_  generation:  0.7010607719421387
----------------------check_connections_block total spend ----------------------------- 2.0275352001190186
generate_one_block  1.8723397254943848
generate_one_block  0.8519365787506104
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.49727439880371094
gen group dst list time:  0.028867483139038086
time for parepare:  0.4047999382019043
local_output_nid generation:  0.08507180213928223
local_in_edges_tensor generation:  0.20876026153564453
mini_batch_src_global generation:  0.16437602043151855
r_  generation:  2.6231205463409424
local_output_nid generation:  0.16006016731262207
local_in_edges_tensor generation:  0.17038631439208984
mini_batch_src_global generation:  0.21084904670715332
r_  generation:  2.870832920074463
----------------------check_connections_block total spend ----------------------------- 7.917551517486572
generate_one_block  3.583244800567627
generate_one_block  3.8426883220672607
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.000560760498046875  GigaBytes
Max Memory Allocated: 0.000560760498046875  GigaBytes

connection checking time:  9.94508671760559
block generation total time  10.150209426879883
average batch blocks generation time:  2.5375523567199707
block dataloader generation time/epoch 38.53932023048401
pseudo mini batch 0 input nodes size: 1016987
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.000560760498046875  GigaBytes
Max Memory Allocated: 0.000560760498046875  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.000560760498046875  GigaBytes
Max Memory Allocated: 0.000560760498046875  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.3794670104980469  GigaBytes
Max Memory Allocated: 0.3794670104980469  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.3802070617675781  GigaBytes
Max Memory Allocated: 0.3802070617675781  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.3802070617675781  GigaBytes
Max Memory Allocated: 0.3802070617675781  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.4301948547363281  GigaBytes
Max Memory Allocated: 0.4301948547363281  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.4301948547363281  GigaBytes
Max Memory Allocated: 0.4301948547363281  GigaBytes

first layer input nodes number: 1016987
first layer output nodes number: 516761
edges number: 5014888
----------------------------------------before model layer 0
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.4416227340698242  GigaBytes
Max Memory Allocated: 0.4611539840698242  GigaBytes

torch.Size([1016987, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.4416227340698242  GigaBytes
Max Memory Allocated: 0.4611539840698242  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.4588623046875 GB
    Memory Allocated: 1.6622982025146484  GigaBytes
Max Memory Allocated: 1.6622982025146484  GigaBytes

h_neigh size torch.Size([516761, 512])
torch.Size([516761, 512])
torch.Size([516761, 512])
----------------------------------------after rst
 Nvidia-smi: 5.4315185546875 GB
    Memory Allocated: 2.6486263275146484  GigaBytes
Max Memory Allocated: 3.6349544525146484  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 5.4315185546875 GB
    Memory Allocated: 1.6622982025146484  GigaBytes
Max Memory Allocated: 3.6349544525146484  GigaBytes

torch.Size([516761, 512])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 5.4315185546875 GB
    Memory Allocated: 2.6486263275146484  GigaBytes
Max Memory Allocated: 3.6349544525146484  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 5.6795654296875 GB
    Memory Allocated: 2.8950371742248535  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

----------------input nodes number: 516761
----------------output nodes number: 99297
----------------edges number: 1466321
----------------------------------------before mean aggregator
 Nvidia-smi: 5.6815185546875 GB
    Memory Allocated: 2.899627685546875  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 5.6815185546875 GB
    Memory Allocated: 3.118072986602783  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

h_neigh size torch.Size([99297, 47])
torch.Size([99297, 47])
torch.Size([99297, 47])
----------------------------------------after rst
 Nvidia-smi: 5.6815185546875 GB
    Memory Allocated: 3.1354589462280273  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 5.6815185546875 GB
    Memory Allocated: 3.118072986602783  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

torch.Size([99297, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 5.6815185546875 GB
    Memory Allocated: 3.1354589462280273  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 5.6815185546875 GB
    Memory Allocated: 3.152845859527588  GigaBytes
Max Memory Allocated: 3.8813652992248535  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.5292949676513672  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

pseudo mini batch 1 input nodes size: 1064152
----------------------------------------before load block subtensor 
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.39815473556518555  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.39815473556518555  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.7945823669433594  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.7953071594238281  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.4156608581542969  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.4657449722290039  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.4657449722290039  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

first layer input nodes number: 1064152
first layer output nodes number: 537341
edges number: 5285728
----------------------------------------before model layer 0
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.4779644012451172  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

torch.Size([1064152, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 7.6717529296875 GB
    Memory Allocated: 0.4779644012451172  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 8.7049560546875 GB
    Memory Allocated: 1.7449140548706055  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

h_neigh size torch.Size([537341, 512])
torch.Size([537341, 512])
torch.Size([537341, 512])
----------------------------------------after rst
 Nvidia-smi: 10.7557373046875 GB
    Memory Allocated: 2.7703046798706055  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 10.7557373046875 GB
    Memory Allocated: 1.7449140548706055  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

torch.Size([537341, 512])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 10.7557373046875 GB
    Memory Allocated: 2.7703046798706055  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 10.7557373046875 GB
    Memory Allocated: 3.026528835296631  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------input nodes number: 537341
----------------output nodes number: 97274
----------------edges number: 1436395
----------------------------------------before mean aggregator
 Nvidia-smi: 10.7557373046875 GB
    Memory Allocated: 3.031935691833496  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 10.7576904296875 GB
    Memory Allocated: 3.245929718017578  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

h_neigh size torch.Size([97274, 47])
torch.Size([97274, 47])
torch.Size([97274, 47])
----------------------------------------after rst
 Nvidia-smi: 10.7576904296875 GB
    Memory Allocated: 3.2629613876342773  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 10.7576904296875 GB
    Memory Allocated: 3.245929718017578  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

torch.Size([97274, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 10.7576904296875 GB
    Memory Allocated: 3.245575428009033  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 10.7576904296875 GB
    Memory Allocated: 3.2629618644714355  GigaBytes
Max Memory Allocated: 4.91399621963501  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 11.8221435546875 GB
    Memory Allocated: 0.5493807792663574  GigaBytes
Max Memory Allocated: 5.1073431968688965  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 11.8221435546875 GB
    Memory Allocated: 0.5505023002624512  GigaBytes
Max Memory Allocated: 5.1073431968688965  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 11.8221435546875 GB
    Memory Allocated: 0.5505023002624512  GigaBytes
Max Memory Allocated: 5.1073431968688965  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.16466009616851807 |0.22551071643829346 |0.4193762540817261 |0.00023806095123291016 |0.028281092643737793 |0.002968311309814453 |
----------------------------------------------------------pseudo_mini_loss sum 5.711383819580078
Total (block generation + training)time/epoch 40.26481103897095
Training time/epoch 1.7251582145690918
Training time without block to device /epoch 1.2741367816925049
Training time without total dataloading part /epoch 0.898759126663208
load block tensor time/epoch 0.32932019233703613
block to device time/epoch 0.4510214328765869
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  3135241
Number of first layer input nodes during this epoch:  2081139
Number of first layer output nodes during this epoch:  1054102
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=512, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  150528
trainable parameters
layers.0.fc_self.weight, torch.Size([512, 100])
layers.0.fc_neigh.weight, torch.Size([512, 100])
layers.1.fc_self.weight, torch.Size([47, 512])
layers.1.fc_neigh.weight, torch.Size([47, 512])
----------------------------------------
un-trainable parameters
