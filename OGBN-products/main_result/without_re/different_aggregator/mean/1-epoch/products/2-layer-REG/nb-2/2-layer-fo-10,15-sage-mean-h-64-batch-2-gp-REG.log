main start at this time 1658188781.2956698
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 7.05718994140625e-05  GigaBytes
Max Memory Allocated: 7.05718994140625e-05  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 7.05718994140625e-05  GigaBytes
Max Memory Allocated: 7.05718994140625e-05  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.09579777717590332
global_2_local spend time (sec) 0.31296443939208984
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.01670360565185547
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 809158, 15: 189452, 14: 695, 7: 655, 10: 640, 11: 624, 13: 615, 12: 583, 9: 576, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.05010056495666504
auxiliary_graph
Graph(num_nodes=1005729, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.49453067779541016
remove nodes length  809158

auxiliary_graph.remove_nodes spent  1.2785992622375488
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.9403011798858643

the counter of shared neighbor distribution
Counter({1.0: 19991684, 2.0: 1794372, 3.0: 401822, 4.0: 133762, 5.0: 53900, 6.0: 23014, 7.0: 13780, 8.0: 6972, 9.0: 5604, 10.0: 3978, 14.0: 3312, 12.0: 3152, 15.0: 3114, 11.0: 2724, 13.0: 2078})
22443268
Convert a graph into a bidirected graph: 1.164 seconds
Metis partitioning: 4.987 seconds
Split the graph: 2.454 seconds
Construct subgraphs: 0.085 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  8.700275182723999
99297
97274
total k batches seeds list generation spend  16.003689289093018
after graph partition
graph partition algorithm spend time 16.55915880203247
99297
97274
partition_len_list
[516761, 537341]
REG selection method  spend 17.10006594657898
time for parepare:  0.2330007553100586
local_output_nid generation:  0.013427019119262695
local_in_edges_tensor generation:  0.020596027374267578
mini_batch_src_global generation:  0.05786323547363281
r_  generation:  0.6721243858337402
local_output_nid generation:  0.013913631439208984
local_in_edges_tensor generation:  0.03907203674316406
mini_batch_src_global generation:  0.059424638748168945
r_  generation:  0.7715086936950684
----------------------check_connections_block total spend ----------------------------- 2.16789174079895
generate_one_block  2.372452735900879
generate_one_block  1.143989086151123
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.5403964519500732
gen group dst list time:  0.02948784828186035
time for parepare:  0.40454697608947754
local_output_nid generation:  0.08829426765441895
local_in_edges_tensor generation:  0.1905972957611084
mini_batch_src_global generation:  0.163377046585083
r_  generation:  2.60064435005188
local_output_nid generation:  0.12132763862609863
local_in_edges_tensor generation:  0.17648816108703613
mini_batch_src_global generation:  0.23648381233215332
r_  generation:  2.8469972610473633
----------------------check_connections_block total spend ----------------------------- 7.8553900718688965
generate_one_block  3.5598928928375244
generate_one_block  3.446568489074707
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 7.05718994140625e-05  GigaBytes
Max Memory Allocated: 7.05718994140625e-05  GigaBytes

connection checking time:  10.023281812667847
block generation total time  10.522903203964233
average batch blocks generation time:  2.6307258009910583
block dataloader generation time/epoch 39.19222807884216
pseudo mini batch 0 input nodes size: 1016987
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 7.05718994140625e-05  GigaBytes
Max Memory Allocated: 7.05718994140625e-05  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 7.05718994140625e-05  GigaBytes
Max Memory Allocated: 7.05718994140625e-05  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.37897682189941406  GigaBytes
Max Memory Allocated: 0.37897682189941406  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.3797168731689453  GigaBytes
Max Memory Allocated: 0.3797168731689453  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.3797168731689453  GigaBytes
Max Memory Allocated: 0.3797168731689453  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.4297046661376953  GigaBytes
Max Memory Allocated: 0.4297046661376953  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.4297046661376953  GigaBytes
Max Memory Allocated: 0.4297046661376953  GigaBytes

first layer input nodes number: 1016987
first layer output nodes number: 516761
edges number: 5014888
----------------------------------------before model layer 0
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.4411325454711914  GigaBytes
Max Memory Allocated: 0.4606637954711914  GigaBytes

torch.Size([1016987, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.4411325454711914  GigaBytes
Max Memory Allocated: 0.4606637954711914  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.4725341796875 GB
    Memory Allocated: 0.7986855506896973  GigaBytes
Max Memory Allocated: 0.8707647323608398  GigaBytes

h_neigh size torch.Size([516761, 64])
torch.Size([516761, 64])
torch.Size([516761, 64])
----------------------------------------after rst
 Nvidia-smi: 2.7225341796875 GB
    Memory Allocated: 0.9218912124633789  GigaBytes
Max Memory Allocated: 1.0450968742370605  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.7225341796875 GB
    Memory Allocated: 0.7986855506896973  GigaBytes
Max Memory Allocated: 1.0450968742370605  GigaBytes

torch.Size([516761, 64])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.7225341796875 GB
    Memory Allocated: 0.9218912124633789  GigaBytes
Max Memory Allocated: 1.0450968742370605  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.7225341796875 GB
    Memory Allocated: 0.952692985534668  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

----------------input nodes number: 516761
----------------output nodes number: 99297
----------------edges number: 1466321
----------------------------------------before mean aggregator
 Nvidia-smi: 2.7225341796875 GB
    Memory Allocated: 0.9572834968566895  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.7244873046875 GB
    Memory Allocated: 1.0100092887878418  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

h_neigh size torch.Size([99297, 47])
torch.Size([99297, 47])
torch.Size([99297, 47])
----------------------------------------after rst
 Nvidia-smi: 2.7244873046875 GB
    Memory Allocated: 1.027395248413086  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 2.7244873046875 GB
    Memory Allocated: 1.0100092887878418  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

torch.Size([99297, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.7244873046875 GB
    Memory Allocated: 1.027395248413086  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 2.7244873046875 GB
    Memory Allocated: 1.0447821617126465  GigaBytes
Max Memory Allocated: 1.0758986473083496  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 2.9920654296875 GB
    Memory Allocated: 0.5292191505432129  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

pseudo mini batch 1 input nodes size: 1064152
----------------------------------------before load block subtensor 
 Nvidia-smi: 2.9920654296875 GB
    Memory Allocated: 0.3971743583679199  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 2.9920654296875 GB
    Memory Allocated: 0.3971743583679199  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.7936587333679199  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.7943835258483887  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.4147372245788574  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.46482133865356445  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.46482133865356445  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

first layer input nodes number: 1064152
first layer output nodes number: 537341
edges number: 5285728
----------------------------------------before model layer 0
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.4774942398071289  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

torch.Size([1064152, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.3885498046875 GB
    Memory Allocated: 0.4774942398071289  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 0.847165584564209  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

h_neigh size torch.Size([537341, 64])
torch.Size([537341, 64])
torch.Size([537341, 64])
----------------------------------------after rst
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 0.9752779006958008  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 0.847165584564209  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

torch.Size([537341, 64])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 0.9752779006958008  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.0073060989379883  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------input nodes number: 537341
----------------output nodes number: 97274
----------------edges number: 1436395
----------------------------------------before mean aggregator
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.012883186340332  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.0645337104797363  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

h_neigh size torch.Size([97274, 47])
torch.Size([97274, 47])
torch.Size([97274, 47])
----------------------------------------after rst
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.0815653800964355  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.0645337104797363  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

torch.Size([97274, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.0641794204711914  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 3.5975341796875 GB
    Memory Allocated: 1.0815658569335938  GigaBytes
Max Memory Allocated: 1.2461552619934082  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 3.6014404296875 GB
    Memory Allocated: 0.5483670234680176  GigaBytes
Max Memory Allocated: 1.293020248413086  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 3.6014404296875 GB
    Memory Allocated: 0.5485081672668457  GigaBytes
Max Memory Allocated: 1.293020248413086  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 3.6014404296875 GB
    Memory Allocated: 0.5485081672668457  GigaBytes
Max Memory Allocated: 1.293020248413086  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.24030613899230957 |0.23457038402557373 |0.4124494791030884 |0.00025010108947753906 |0.009790420532226562 |0.002779245376586914 |
----------------------------------------------------------pseudo_mini_loss sum 6.983132362365723
Total (block generation + training)time/epoch 40.99813461303711
Training time/epoch 1.8055150508880615
Training time without block to device /epoch 1.336374282836914
Training time without total dataloading part /epoch 0.8477592468261719
load block tensor time/epoch 0.48061227798461914
block to device time/epoch 0.46914076805114746
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  3135241
Number of first layer input nodes during this epoch:  2081139
Number of first layer output nodes during this epoch:  1054102
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=64, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=64, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=64, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=64, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  18816
trainable parameters
layers.0.fc_self.weight, torch.Size([64, 100])
layers.0.fc_neigh.weight, torch.Size([64, 100])
layers.1.fc_self.weight, torch.Size([47, 64])
layers.1.fc_neigh.weight, torch.Size([47, 64])
----------------------------------------
un-trainable parameters
