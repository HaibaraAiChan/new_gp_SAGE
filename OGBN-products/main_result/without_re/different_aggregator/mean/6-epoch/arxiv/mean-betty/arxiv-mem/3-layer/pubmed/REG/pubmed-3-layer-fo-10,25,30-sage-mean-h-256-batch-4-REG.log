main start at this time 1657074156.7340796
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  500
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0014476776123046875  GigaBytes
Max Memory Allocated: 0.0014476776123046875  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0014476776123046875  GigaBytes
Max Memory Allocated: 0.0014476776123046875  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.003367900848388672
global_2_local spend time (sec) 5.936622619628906e-05
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0004494190216064453
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 293, 1: 26, 3: 6, 2: 6, 6: 4, 4: 3, 8: 3, 5: 2, 17: 2, 7: 1, 18: 1, 22: 1, 9: 1, 30: 1, 11: 1, 10: 1, 29: 1})

A = g.adjacency_matrix() spent  0.0003414154052734375
auxiliary_graph
Graph(num_nodes=353, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0005240440368652344
remove nodes length  293

auxiliary_graph.remove_nodes spent  0.001528024673461914
after remove non output nodes the auxiliary_graph
Graph(num_nodes=60, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007770061492919922

the counter of shared neighbor distribution
Counter({1.0: 6})
6
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.001 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0019609928131103516
15
15
15
15
total k batches seeds list generation spend  0.009749174118041992
after graph partition
graph partition algorithm spend time 0.022288084030151367
15
15
15
15
partition_len_list
[126, 65, 91, 71]
REG selection method  spend 0.022480010986328125
time for parepare:  3.7670135498046875e-05
local_output_nid generation:  2.384185791015625e-06
local_in_edges_tensor generation:  0.00010967254638671875
mini_batch_src_global generation:  2.6464462280273438e-05
r_  generation:  5.793571472167969e-05
local_output_nid generation:  2.384185791015625e-06
local_in_edges_tensor generation:  0.00010347366333007812
mini_batch_src_global generation:  1.7404556274414062e-05
r_  generation:  3.147125244140625e-05
local_output_nid generation:  2.6226043701171875e-06
local_in_edges_tensor generation:  9.918212890625e-05
mini_batch_src_global generation:  1.621246337890625e-05
r_  generation:  3.4332275390625e-05
local_output_nid generation:  2.6226043701171875e-06
local_in_edges_tensor generation:  9.751319885253906e-05
mini_batch_src_global generation:  1.5735626220703125e-05
r_  generation:  2.956390380859375e-05
----------------------check_connections_block total spend ----------------------------- 0.0008969306945800781
generate_one_block  0.0026199817657470703
generate_one_block  0.0010883808135986328
generate_one_block  0.001112222671508789
generate_one_block  0.0010478496551513672
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0013272762298583984
gen group dst list time:  3.528594970703125e-05
time for parepare:  0.00021529197692871094
local_output_nid generation:  1.1920928955078125e-05
local_in_edges_tensor generation:  0.00019979476928710938
mini_batch_src_global generation:  4.57763671875e-05
r_  generation:  0.00038933753967285156
local_output_nid generation:  8.821487426757812e-06
local_in_edges_tensor generation:  0.0001232624053955078
mini_batch_src_global generation:  3.814697265625e-05
r_  generation:  0.0001838207244873047
local_output_nid generation:  9.298324584960938e-06
local_in_edges_tensor generation:  0.00012421607971191406
mini_batch_src_global generation:  5.316734313964844e-05
r_  generation:  0.00033020973205566406
local_output_nid generation:  7.152557373046875e-06
local_in_edges_tensor generation:  0.00011992454528808594
mini_batch_src_global generation:  4.267692565917969e-05
r_  generation:  0.0002913475036621094
----------------------check_connections_block total spend ----------------------------- 0.0025949478149414062
generate_one_block  0.0016951560974121094
generate_one_block  0.0012612342834472656
generate_one_block  0.0015017986297607422
generate_one_block  0.0013954639434814453
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0007939338684082031
gen group dst list time:  6.937980651855469e-05
time for parepare:  0.0006086826324462891
local_output_nid generation:  5.984306335449219e-05
local_in_edges_tensor generation:  0.00030159950256347656
mini_batch_src_global generation:  0.00011658668518066406
r_  generation:  0.0013263225555419922
local_output_nid generation:  3.24249267578125e-05
local_in_edges_tensor generation:  0.0001659393310546875
mini_batch_src_global generation:  9.72747802734375e-05
r_  generation:  0.0006284713745117188
local_output_nid generation:  5.9604644775390625e-05
local_in_edges_tensor generation:  0.00021004676818847656
mini_batch_src_global generation:  0.00014472007751464844
r_  generation:  0.0015521049499511719
local_output_nid generation:  4.9591064453125e-05
local_in_edges_tensor generation:  0.0001900196075439453
mini_batch_src_global generation:  0.0001418590545654297
r_  generation:  0.001172780990600586
----------------------check_connections_block total spend ----------------------------- 0.008214235305786133
generate_one_block  0.002912282943725586
generate_one_block  0.0018634796142578125
generate_one_block  0.003114938735961914
generate_one_block  0.002576589584350586
----------===============-------------===============-------------the number of batches *****---- 4

original number of batches:  4
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0014476776123046875  GigaBytes
Max Memory Allocated: 0.0014476776123046875  GigaBytes

connection checking time:  0.011706113815307617
block generation total time  0.02218937873840332
average batch blocks generation time:  0.0018491148948669434
block dataloader generation time/epoch 0.06761789321899414
pseudo mini batch 0 input nodes size: 2299
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0014476776123046875  GigaBytes
Max Memory Allocated: 0.0014476776123046875  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0014476776123046875  GigaBytes
Max Memory Allocated: 0.0014476776123046875  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.005730152130126953  GigaBytes
Max Memory Allocated: 0.005730152130126953  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.005730628967285156  GigaBytes
Max Memory Allocated: 0.005730628967285156  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.005730628967285156  GigaBytes
Max Memory Allocated: 0.005730628967285156  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.005770683288574219  GigaBytes
Max Memory Allocated: 0.005770683288574219  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.005770683288574219  GigaBytes
Max Memory Allocated: 0.005770683288574219  GigaBytes

first layer input nodes number: 2299
first layer output nodes number: 818
edges number: 4049
----------------------------------------before model layer 0
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.005794048309326172  GigaBytes
Max Memory Allocated: 0.005809307098388672  GigaBytes

torch.Size([2299, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.005794048309326172  GigaBytes
Max Memory Allocated: 0.005809307098388672  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2655029296875 GB
    Memory Allocated: 0.008131980895996094  GigaBytes
Max Memory Allocated: 0.00887918472290039  GigaBytes

torch.Size([818, 256])
torch.Size([818, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.008912086486816406  GigaBytes
Max Memory Allocated: 0.009692192077636719  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.008131980895996094  GigaBytes
Max Memory Allocated: 0.009692192077636719  GigaBytes

torch.Size([818, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.008912086486816406  GigaBytes
Max Memory Allocated: 0.009692192077636719  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009107112884521484  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

input nodes number: 818
output nodes number: 126
edges number: 1142
----------------------------------------before model layer 1
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009114265441894531  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

torch.Size([818, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009114265441894531  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009364128112792969  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

torch.Size([126, 256])
torch.Size([126, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009484291076660156  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009364128112792969  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

torch.Size([126, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009484291076660156  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009514331817626953  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

----------------input nodes number: 126
----------------output nodes number: 15
----------------edges number: 114
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009515762329101562  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009532451629638672  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

torch.Size([15, 3])
torch.Size([15, 3])
----------------------------------------after rst
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009532928466796875  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009532451629638672  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

torch.Size([15, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009532928466796875  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2674560546875 GB
    Memory Allocated: 0.009534358978271484  GigaBytes
Max Memory Allocated: 0.009887218475341797  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007309436798095703  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

pseudo mini batch 1 input nodes size: 1210
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007179737091064453  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007179737091064453  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009433746337890625  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009434223175048828  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005151271820068359  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005169391632080078  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005169391632080078  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

first layer input nodes number: 1210
first layer output nodes number: 353
edges number: 1780
----------------------------------------before model layer 0
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005181312561035156  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([1210, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005181312561035156  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006190299987792969  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([353, 256])
torch.Size([353, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006526947021484375  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006190299987792969  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([353, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006526947021484375  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006611347198486328  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

input nodes number: 353
output nodes number: 65
edges number: 425
----------------------------------------before model layer 1
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006615161895751953  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([353, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006615161895751953  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006743907928466797  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([65, 256])
torch.Size([65, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006805896759033203  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006743907928466797  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([65, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006805896759033203  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006821632385253906  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------input nodes number: 65
----------------output nodes number: 15
----------------edges number: 50
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006823062896728516  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006839752197265625  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([15, 3])
torch.Size([15, 3])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006840229034423828  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006839752197265625  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([15, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006839752197265625  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006840705871582031  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005213737487792969  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

pseudo mini batch 2 input nodes size: 2649
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005151271820068359  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.005151271820068359  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010085582733154297  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.0100860595703125  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007831573486328125  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007876396179199219  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007876396179199219  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

first layer input nodes number: 2649
first layer output nodes number: 752
edges number: 4822
----------------------------------------before model layer 0
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007902145385742188  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([2649, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007902145385742188  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010059356689453125  GigaBytes
Max Memory Allocated: 0.011195182800292969  GigaBytes

torch.Size([752, 256])
torch.Size([752, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010776519775390625  GigaBytes
Max Memory Allocated: 0.011493682861328125  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010059356689453125  GigaBytes
Max Memory Allocated: 0.011493682861328125  GigaBytes

torch.Size([752, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010776519775390625  GigaBytes
Max Memory Allocated: 0.011493682861328125  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010955810546875  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

input nodes number: 752
output nodes number: 91
edges number: 1014
----------------------------------------before model layer 1
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010962486267089844  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

torch.Size([752, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.010962486267089844  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011144638061523438  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

torch.Size([91, 256])
torch.Size([91, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011231422424316406  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011144638061523438  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

torch.Size([91, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011231422424316406  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.01125335693359375  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

----------------input nodes number: 91
----------------output nodes number: 15
----------------edges number: 76
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.01125478744506836  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011271476745605469  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

torch.Size([15, 3])
torch.Size([15, 3])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011271953582763672  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011271476745605469  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

torch.Size([15, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011271476745605469  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011272430419921875  GigaBytes
Max Memory Allocated: 0.0116729736328125  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007970809936523438  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

pseudo mini batch 3 input nodes size: 1857
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007831573486328125  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.007831573486328125  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011290550231933594  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.011291027069091797  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006356239318847656  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.0063915252685546875  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.0063915252685546875  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

first layer input nodes number: 1857
first layer output nodes number: 603
edges number: 3628
----------------------------------------before model layer 0
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.0064105987548828125  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([1857, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.0064105987548828125  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00813913345336914  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([603, 256])
torch.Size([603, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00871419906616211  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00813913345336914  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([603, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00871419906616211  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.008858203887939453  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

input nodes number: 603
output nodes number: 71
edges number: 849
----------------------------------------before model layer 1
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00886392593383789  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([603, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00886392593383789  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009006977081298828  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([71, 256])
torch.Size([71, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009074687957763672  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009006977081298828  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([71, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009074687957763672  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009091854095458984  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------input nodes number: 71
----------------output nodes number: 15
----------------edges number: 56
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009093284606933594  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009109973907470703  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([15, 3])
torch.Size([15, 3])
----------------------------------------after rst
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009110450744628906  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009109973907470703  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

torch.Size([15, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009109973907470703  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.00911092758178711  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.006466865539550781  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009362220764160156  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.2694091796875 GB
    Memory Allocated: 0.009362220764160156  GigaBytes
Max Memory Allocated: 0.012420177459716797  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.004963815212249756 |0.08681517839431763 |0.2026979923248291 |0.00017124414443969727 |0.0031291842460632324 |0.0032455921173095703 |
----------------------------------------------------------pseudo_mini_loss sum 1.1115232706069946
Total (block generation + training)time/epoch 1.275862693786621
Training time/epoch 1.207927942276001
Training time without block to device /epoch 0.8606672286987305
Training time without total dataloading part /epoch 0.8272392749786377
load block tensor time/epoch 0.019855260848999023
block to device time/epoch 0.3472607135772705
input features size transfer per epoch 5.364418029785156e-07
blocks size to device per epoch 3.5762786865234375e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  10894
Number of first layer input nodes during this epoch:  8015
Number of first layer output nodes during this epoch:  2526
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=500, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=500, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=3, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=3, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  388608
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 500])
layers.0.fc_neigh.weight, torch.Size([256, 500])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([3, 256])
layers.2.fc_neigh.weight, torch.Size([3, 256])
----------------------------------------
un-trainable parameters
