main start at this time 1657103033.105536
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  500
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0024242401123046875  GigaBytes
Max Memory Allocated: 0.0024242401123046875  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0024242401123046875  GigaBytes
Max Memory Allocated: 0.0024242401123046875  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.0021822452545166016
global_2_local spend time (sec) 7.104873657226562e-05
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003571510314941406
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 294, 1: 26, 2: 6, 3: 6, 6: 4, 4: 3, 8: 3, 5: 2, 17: 2, 18: 1, 7: 1, 31: 1, 22: 1, 10: 1, 29: 1, 9: 1, 11: 1})

A = g.adjacency_matrix() spent  0.0003616809844970703
auxiliary_graph
Graph(num_nodes=354, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0004105567932128906
remove nodes length  294

auxiliary_graph.remove_nodes spent  0.00168609619140625
after remove non output nodes the auxiliary_graph
Graph(num_nodes=60, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0008244514465332031

the counter of shared neighbor distribution
Counter({1.0: 6})
6
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.00174713134765625
30
30
total k batches seeds list generation spend  0.009112358093261719
after graph partition
graph partition algorithm spend time 0.04179048538208008
30
30
partition_len_list
[181, 173]
REG selection method  spend 0.04203009605407715
time for parepare:  0.00010204315185546875
local_output_nid generation:  1.2636184692382812e-05
local_in_edges_tensor generation:  0.00035858154296875
mini_batch_src_global generation:  6.341934204101562e-05
r_  generation:  0.000152587890625
local_output_nid generation:  8.821487426757812e-06
local_in_edges_tensor generation:  0.0002732276916503906
mini_batch_src_global generation:  4.982948303222656e-05
r_  generation:  0.00012803077697753906
----------------------check_connections_block total spend ----------------------------- 0.0015232563018798828
generate_one_block  0.00450897216796875
generate_one_block  0.0025110244750976562
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.0020923614501953125
gen group dst list time:  5.316734313964844e-05
time for parepare:  0.0005018711090087891
local_output_nid generation:  3.409385681152344e-05
local_in_edges_tensor generation:  0.0005865097045898438
mini_batch_src_global generation:  0.00013518333435058594
r_  generation:  0.0008995532989501953
local_output_nid generation:  2.193450927734375e-05
local_in_edges_tensor generation:  0.0002319812774658203
mini_batch_src_global generation:  0.00013828277587890625
r_  generation:  0.0009219646453857422
----------------------check_connections_block total spend ----------------------------- 0.00407099723815918
generate_one_block  0.0028228759765625
generate_one_block  0.0027778148651123047
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0015072822570800781
gen group dst list time:  8.678436279296875e-05
time for parepare:  0.0007543563842773438
local_output_nid generation:  9.894371032714844e-05
local_in_edges_tensor generation:  0.0004100799560546875
mini_batch_src_global generation:  0.0002694129943847656
r_  generation:  0.003376483917236328
local_output_nid generation:  9.369850158691406e-05
local_in_edges_tensor generation:  0.0003116130828857422
mini_batch_src_global generation:  0.0005328655242919922
r_  generation:  0.0038149356842041016
----------------------check_connections_block total spend ----------------------------- 0.011755704879760742
generate_one_block  0.005750417709350586
generate_one_block  0.005772590637207031
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0019485950469970703
gen group dst list time:  0.0001697540283203125
time for parepare:  0.0013992786407470703
local_output_nid generation:  0.0003955364227294922
local_in_edges_tensor generation:  0.0010724067687988281
mini_batch_src_global generation:  0.0012466907501220703
r_  generation:  0.012584686279296875
local_output_nid generation:  0.00029397010803222656
local_in_edges_tensor generation:  0.0011086463928222656
mini_batch_src_global generation:  0.0013120174407958984
r_  generation:  0.01077413558959961
----------------------check_connections_block total spend ----------------------------- 0.036040306091308594
generate_one_block  0.018246173858642578
generate_one_block  0.01567363739013672
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.001729726791381836
gen group dst list time:  0.0004558563232421875
time for parepare:  0.0015628337860107422
local_output_nid generation:  0.0009992122650146484
local_in_edges_tensor generation:  0.002064943313598633
mini_batch_src_global generation:  0.0016019344329833984
r_  generation:  0.01824784278869629
local_output_nid generation:  0.0007982254028320312
local_in_edges_tensor generation:  0.00170135498046875
mini_batch_src_global generation:  0.0018286705017089844
r_  generation:  0.01564788818359375
----------------------check_connections_block total spend ----------------------------- 0.05275559425354004
generate_one_block  0.024208784103393555
generate_one_block  0.021230220794677734
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0024242401123046875  GigaBytes
Max Memory Allocated: 0.0024242401123046875  GigaBytes

connection checking time:  0.10614585876464844
block generation total time  0.10350251197814941
average batch blocks generation time:  0.010350251197814941
block dataloader generation time/epoch 0.2745499610900879
pseudo mini batch 0 input nodes size: 16831
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0024242401123046875  GigaBytes
Max Memory Allocated: 0.0024242401123046875  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0024242401123046875  GigaBytes
Max Memory Allocated: 0.0024242401123046875  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0526123046875 GB
    Memory Allocated: 0.03377485275268555  GigaBytes
Max Memory Allocated: 0.03377485275268555  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0526123046875 GB
    Memory Allocated: 0.03377532958984375  GigaBytes
Max Memory Allocated: 0.03377532958984375  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0526123046875 GB
    Memory Allocated: 0.03377532958984375  GigaBytes
Max Memory Allocated: 0.03377532958984375  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1170654296875 GB
    Memory Allocated: 0.034584999084472656  GigaBytes
Max Memory Allocated: 0.034584999084472656  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1170654296875 GB
    Memory Allocated: 0.034584999084472656  GigaBytes
Max Memory Allocated: 0.034584999084472656  GigaBytes

first layer input nodes number: 16831
first layer output nodes number: 13616
edges number: 53907
----------------------------------------before model layer 0
 Nvidia-smi: 1.1170654296875 GB
    Memory Allocated: 0.034811973571777344  GigaBytes
Max Memory Allocated: 0.03501319885253906  GigaBytes

torch.Size([16831, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1170654296875 GB
    Memory Allocated: 0.034811973571777344  GigaBytes
Max Memory Allocated: 0.03501319885253906  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3553466796875 GB
    Memory Allocated: 0.07364130020141602  GigaBytes
Max Memory Allocated: 0.08609771728515625  GigaBytes

torch.Size([13616, 256])
torch.Size([13616, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.08731317520141602  GigaBytes
Max Memory Allocated: 0.10098505020141602  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.07432794570922852  GigaBytes
Max Memory Allocated: 0.10098505020141602  GigaBytes

torch.Size([13616, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.08799982070922852  GigaBytes
Max Memory Allocated: 0.10098505020141602  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.09055948257446289  GigaBytes
Max Memory Allocated: 0.10423135757446289  GigaBytes

input nodes number: 13616
output nodes number: 5404
edges number: 41487
----------------------------------------before model layer 1
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.09070158004760742  GigaBytes
Max Memory Allocated: 0.10423135757446289  GigaBytes

torch.Size([13616, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.09070158004760742  GigaBytes
Max Memory Allocated: 0.10423135757446289  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3826904296875 GB
    Memory Allocated: 0.10135984420776367  GigaBytes
Max Memory Allocated: 0.10423135757446289  GigaBytes

torch.Size([5404, 256])
torch.Size([5404, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.10651350021362305  GigaBytes
Max Memory Allocated: 0.11166715621948242  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.10135984420776367  GigaBytes
Max Memory Allocated: 0.11166715621948242  GigaBytes

torch.Size([5404, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.10651350021362305  GigaBytes
Max Memory Allocated: 0.11166715621948242  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.10836601257324219  GigaBytes
Max Memory Allocated: 0.11351966857910156  GigaBytes

input nodes number: 5404
output nodes number: 1382
edges number: 10818
----------------------------------------before model layer 2
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.10841703414916992  GigaBytes
Max Memory Allocated: 0.11351966857910156  GigaBytes

torch.Size([5404, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.10841703414916992  GigaBytes
Max Memory Allocated: 0.11351966857910156  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.1111445426940918  GigaBytes
Max Memory Allocated: 0.11351966857910156  GigaBytes

torch.Size([1382, 256])
torch.Size([1382, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11246252059936523  GigaBytes
Max Memory Allocated: 0.11383199691772461  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.1111445426940918  GigaBytes
Max Memory Allocated: 0.11383199691772461  GigaBytes

torch.Size([1382, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11246252059936523  GigaBytes
Max Memory Allocated: 0.11383199691772461  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11284351348876953  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

input nodes number: 1382
output nodes number: 181
edges number: 1807
----------------------------------------before model layer 3
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11285543441772461  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

torch.Size([1382, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11285543441772461  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11321687698364258  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

torch.Size([181, 256])
torch.Size([181, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11338949203491211  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11321687698364258  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

torch.Size([181, 256])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11338949203491211  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.1134328842163086  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

----------------input nodes number: 181
----------------output nodes number: 30
----------------edges number: 153
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.1134347915649414  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11346673965454102  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

torch.Size([30, 3])
torch.Size([30, 3])
----------------------------------------after rst
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11346721649169922  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11346673965454102  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

torch.Size([30, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11346721649169922  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.4022216796875 GB
    Memory Allocated: 0.11346864700317383  GigaBytes
Max Memory Allocated: 0.11416149139404297  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.4178466796875 GB
    Memory Allocated: 0.038817405700683594  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

pseudo mini batch 1 input nodes size: 14692
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.4178466796875 GB
    Memory Allocated: 0.03620100021362305  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.4178466796875 GB
    Memory Allocated: 0.03620100021362305  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.0635671615600586  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.0635676383972168  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.032216548919677734  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.03294515609741211  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.03294515609741211  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

first layer input nodes number: 14692
first layer output nodes number: 10827
edges number: 46675
----------------------------------------before model layer 0
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.03313589096069336  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([14692, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.03313589096069336  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.06401681900024414  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([10827, 256])
torch.Size([10827, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07434225082397461  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.06401681900024414  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([10827, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07434225082397461  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07768869400024414  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

input nodes number: 10827
output nodes number: 4070
edges number: 36082
----------------------------------------before model layer 1
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07780027389526367  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([10827, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.07780027389526367  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.08586263656616211  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([4070, 256])
torch.Size([4070, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.08974409103393555  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.08586263656616211  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([4070, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.08974409103393555  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.0907144546508789  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

input nodes number: 4070
output nodes number: 1278
edges number: 12589
----------------------------------------before model layer 2
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09075450897216797  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([4070, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4471435546875 GB
    Memory Allocated: 0.09075450897216797  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09423208236694336  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([1278, 256])
torch.Size([1278, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.0963597297668457  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09491682052612305  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([1278, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09613561630249023  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.0966644287109375  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

input nodes number: 1278
output nodes number: 173
edges number: 1997
----------------------------------------before model layer 3
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09667539596557617  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([1278, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09667539596557617  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09702253341674805  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([173, 256])
torch.Size([173, 256])
----------------------------------------after rst
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09718751907348633  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09702253341674805  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([173, 256])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09718751907348633  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09722900390625  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------input nodes number: 173
----------------output nodes number: 30
----------------edges number: 144
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09723091125488281  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09726285934448242  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([30, 3])
torch.Size([30, 3])
----------------------------------------after rst
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09726333618164062  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09726285934448242  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

torch.Size([30, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09726285934448242  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.09726381301879883  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.4490966796875 GB
    Memory Allocated: 0.034533023834228516  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.03938150405883789  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.03938150405883789  GigaBytes
Max Memory Allocated: 0.1199498176574707  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.013442397117614746 |0.1786731481552124 |0.40388524532318115 |0.0002313852310180664 |0.006290316581726074 |0.0030846595764160156 |
----------------------------------------------------------pseudo_mini_loss sum 1.1489307880401611
Total (block generation + training)time/epoch 1.4886317253112793
Training time/epoch 1.2137963771820068
Training time without block to device /epoch 0.856450080871582
Training time without total dataloading part /epoch 0.8238985538482666
load block tensor time/epoch 0.026884794235229492
block to device time/epoch 0.3573462963104248
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 2.384185791015625e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  68454
Number of first layer input nodes during this epoch:  31523
Number of first layer output nodes during this epoch:  24443
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=500, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=500, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (4): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=3, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=3, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  650752
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 500])
layers.0.fc_neigh.weight, torch.Size([256, 500])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([256, 256])
layers.3.fc_neigh.weight, torch.Size([256, 256])
layers.4.fc_self.weight, torch.Size([3, 256])
layers.4.fc_neigh.weight, torch.Size([3, 256])
----------------------------------------
un-trainable parameters
