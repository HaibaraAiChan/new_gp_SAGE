main start at this time 1657101360.3492794
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  500
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0019359588623046875  GigaBytes
Max Memory Allocated: 0.0019359588623046875  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0019359588623046875  GigaBytes
Max Memory Allocated: 0.0019359588623046875  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.0024776458740234375
global_2_local spend time (sec) 6.699562072753906e-05
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0004603862762451172
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 294, 1: 26, 2: 6, 3: 6, 6: 4, 4: 3, 8: 3, 5: 2, 17: 2, 31: 1, 7: 1, 9: 1, 18: 1, 10: 1, 29: 1, 11: 1, 22: 1})

A = g.adjacency_matrix() spent  0.00030422210693359375
auxiliary_graph
Graph(num_nodes=354, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.00043582916259765625
remove nodes length  294

auxiliary_graph.remove_nodes spent  0.0014638900756835938
after remove non output nodes the auxiliary_graph
Graph(num_nodes=60, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007474422454833984

the counter of shared neighbor distribution
Counter({1.0: 6})
6
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0015556812286376953
30
30
total k batches seeds list generation spend  0.008177757263183594
after graph partition
graph partition algorithm spend time 0.15729403495788574
30
30
partition_len_list
[210, 144]
REG selection method  spend 0.1574862003326416
time for parepare:  3.886222839355469e-05
local_output_nid generation:  3.814697265625e-06
local_in_edges_tensor generation:  0.00011157989501953125
mini_batch_src_global generation:  3.0279159545898438e-05
r_  generation:  8.273124694824219e-05
local_output_nid generation:  4.0531158447265625e-06
local_in_edges_tensor generation:  0.0001087188720703125
mini_batch_src_global generation:  2.09808349609375e-05
r_  generation:  5.245208740234375e-05
----------------------check_connections_block total spend ----------------------------- 0.0005884170532226562
generate_one_block  0.0023894309997558594
generate_one_block  0.0011525154113769531
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.009717702865600586
gen group dst list time:  2.47955322265625e-05
time for parepare:  0.00026297569274902344
local_output_nid generation:  1.9550323486328125e-05
local_in_edges_tensor generation:  0.00018858909606933594
mini_batch_src_global generation:  6.842613220214844e-05
r_  generation:  0.0007007122039794922
local_output_nid generation:  1.33514404296875e-05
local_in_edges_tensor generation:  0.00014019012451171875
mini_batch_src_global generation:  6.771087646484375e-05
r_  generation:  0.0004940032958984375
----------------------check_connections_block total spend ----------------------------- 0.0022814273834228516
generate_one_block  0.002070903778076172
generate_one_block  0.0017650127410888672
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0009627342224121094
gen group dst list time:  5.91278076171875e-05
time for parepare:  0.0006823539733886719
local_output_nid generation:  0.0001125335693359375
local_in_edges_tensor generation:  0.00040793418884277344
mini_batch_src_global generation:  0.0003323554992675781
r_  generation:  0.0043010711669921875
local_output_nid generation:  8.082389831542969e-05
local_in_edges_tensor generation:  0.00026607513427734375
mini_batch_src_global generation:  0.0004010200500488281
r_  generation:  0.002941131591796875
----------------------check_connections_block total spend ----------------------------- 0.011488676071166992
generate_one_block  0.006603240966796875
generate_one_block  0.004517555236816406
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0016169548034667969
gen group dst list time:  0.00017762184143066406
time for parepare:  0.0012013912200927734
local_output_nid generation:  0.00041675567626953125
local_in_edges_tensor generation:  0.0009741783142089844
mini_batch_src_global generation:  0.0011143684387207031
r_  generation:  0.010750532150268555
local_output_nid generation:  0.0002796649932861328
local_in_edges_tensor generation:  0.00061798095703125
mini_batch_src_global generation:  0.0008854866027832031
r_  generation:  0.006808042526245117
----------------------check_connections_block total spend ----------------------------- 0.027821779251098633
generate_one_block  0.014391899108886719
generate_one_block  0.010454416275024414
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0019359588623046875  GigaBytes
Max Memory Allocated: 0.0019359588623046875  GigaBytes

connection checking time:  0.04218029975891113
block generation total time  0.043344974517822266
average batch blocks generation time:  0.005418121814727783
block dataloader generation time/epoch 0.2651681900024414
pseudo mini batch 0 input nodes size: 11947
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0019359588623046875  GigaBytes
Max Memory Allocated: 0.0019359588623046875  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0019359588623046875  GigaBytes
Max Memory Allocated: 0.0019359588623046875  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0408935546875 GB
    Memory Allocated: 0.024188995361328125  GigaBytes
Max Memory Allocated: 0.024188995361328125  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0408935546875 GB
    Memory Allocated: 0.024189472198486328  GigaBytes
Max Memory Allocated: 0.024189472198486328  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0408935546875 GB
    Memory Allocated: 0.024189472198486328  GigaBytes
Max Memory Allocated: 0.024189472198486328  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024553775787353516  GigaBytes
Max Memory Allocated: 0.024553775787353516  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024553775787353516  GigaBytes
Max Memory Allocated: 0.024553775787353516  GigaBytes

first layer input nodes number: 11947
first layer output nodes number: 5975
edges number: 32733
----------------------------------------before model layer 0
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024687767028808594  GigaBytes
Max Memory Allocated: 0.024809837341308594  GigaBytes

torch.Size([11947, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024687767028808594  GigaBytes
Max Memory Allocated: 0.024809837341308594  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.042371273040771484  GigaBytes
Max Memory Allocated: 0.04841423034667969  GigaBytes

torch.Size([5975, 256])
torch.Size([5975, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.04806947708129883  GigaBytes
Max Memory Allocated: 0.054090023040771484  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.042371273040771484  GigaBytes
Max Memory Allocated: 0.054090023040771484  GigaBytes

torch.Size([5975, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.04806947708129883  GigaBytes
Max Memory Allocated: 0.054090023040771484  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.04981660842895508  GigaBytes
Max Memory Allocated: 0.05551481246948242  GigaBytes

input nodes number: 5975
output nodes number: 1552
edges number: 13615
----------------------------------------before model layer 1
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.04987335205078125  GigaBytes
Max Memory Allocated: 0.05551481246948242  GigaBytes

torch.Size([5975, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.04987335205078125  GigaBytes
Max Memory Allocated: 0.05551481246948242  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.052947998046875  GigaBytes
Max Memory Allocated: 0.05551481246948242  GigaBytes

torch.Size([1552, 256])
torch.Size([1552, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.0544281005859375  GigaBytes
Max Memory Allocated: 0.055908203125  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.052947998046875  GigaBytes
Max Memory Allocated: 0.055908203125  GigaBytes

torch.Size([1552, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.0544281005859375  GigaBytes
Max Memory Allocated: 0.055908203125  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.054798126220703125  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

input nodes number: 1552
output nodes number: 210
edges number: 2150
----------------------------------------before model layer 2
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.054811954498291016  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

torch.Size([1552, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.054811954498291016  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3221435546875 GB
    Memory Allocated: 0.05523061752319336  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

torch.Size([210, 256])
torch.Size([210, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05543088912963867  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05523061752319336  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

torch.Size([210, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05543088912963867  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05548095703125  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

----------------input nodes number: 210
----------------output nodes number: 30
----------------edges number: 183
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.055483341217041016  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.055515289306640625  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

torch.Size([30, 3])
torch.Size([30, 3])
----------------------------------------after rst
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05551576614379883  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.055515289306640625  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

torch.Size([30, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05551576614379883  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3240966796875 GB
    Memory Allocated: 0.05551719665527344  GigaBytes
Max Memory Allocated: 0.056278228759765625  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.027242183685302734  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

pseudo mini batch 1 input nodes size: 9133
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.026126861572265625  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.026126861572265625  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.04313850402832031  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.043138980865478516  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.020885467529296875  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.021140098571777344  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.021140098571777344  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

first layer input nodes number: 9133
first layer output nodes number: 3817
edges number: 22962
----------------------------------------before model layer 0
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.021236896514892578  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([9133, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.021236896514892578  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.0331416130065918  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([3817, 256])
torch.Size([3817, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.03678178787231445  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.03217315673828125  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([3817, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.035813331604003906  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.0375218391418457  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

input nodes number: 3817
output nodes number: 1062
edges number: 9425
----------------------------------------before model layer 1
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.037558555603027344  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([3817, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.037558555603027344  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.040157318115234375  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([1062, 256])
torch.Size([1062, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.04117012023925781  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.040157318115234375  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([1062, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.04117012023925781  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.04142332077026367  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

input nodes number: 1062
output nodes number: 144
edges number: 1460
----------------------------------------before model layer 2
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.041432857513427734  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([1062, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.041432857513427734  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04172086715698242  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([144, 256])
torch.Size([144, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04185819625854492  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04172086715698242  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([144, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04185819625854492  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04189252853393555  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------input nodes number: 144
----------------output nodes number: 30
----------------edges number: 114
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04189443588256836  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04192543029785156  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([30, 3])
torch.Size([30, 3])
----------------------------------------after rst
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.041925907135009766  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04192543029785156  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

torch.Size([30, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04192543029785156  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.04192638397216797  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.021662235260009766  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.3358154296875 GB
    Memory Allocated: 0.02553415298461914  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.3358154296875 GB
    Memory Allocated: 0.02553415298461914  GigaBytes
Max Memory Allocated: 0.0622248649597168  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.008618712425231934 |0.17052483558654785 |0.39731788635253906 |0.00019168853759765625 |0.0059773921966552734 |0.002155303955078125 |
----------------------------------------------------------pseudo_mini_loss sum 1.1011912822723389
Total (block generation + training)time/epoch 1.4395489692687988
Training time/epoch 1.1740949153900146
Training time without block to device /epoch 0.833045244216919
Training time without total dataloading part /epoch 0.8091292381286621
load block tensor time/epoch 0.017237424850463867
block to device time/epoch 0.3410496711730957
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  33840
Number of first layer input nodes during this epoch:  21080
Number of first layer output nodes during this epoch:  9792
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=500, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=500, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=3, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=3, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  519680
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 500])
layers.0.fc_neigh.weight, torch.Size([256, 500])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([3, 256])
layers.3.fc_neigh.weight, torch.Size([3, 256])
----------------------------------------
un-trainable parameters
