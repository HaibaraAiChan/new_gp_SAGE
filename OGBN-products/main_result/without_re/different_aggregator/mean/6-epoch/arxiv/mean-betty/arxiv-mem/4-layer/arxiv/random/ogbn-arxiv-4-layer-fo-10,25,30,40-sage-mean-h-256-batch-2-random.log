main start at this time 1657097294.4599664
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  128
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012969970703125  GigaBytes
Max Memory Allocated: 0.0012969970703125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012969970703125  GigaBytes
Max Memory Allocated: 0.0012969970703125  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.05011916160583496
number of batches is  2
batch size is  45471
random selection method spend 0.0074558258056640625
time for parepare:  0.019496917724609375
local_output_nid generation:  0.01606917381286621
local_in_edges_tensor generation:  0.014454364776611328
mini_batch_src_global generation:  0.01526021957397461
r_  generation:  0.1705164909362793
local_output_nid generation:  0.021321773529052734
local_in_edges_tensor generation:  0.010068178176879883
mini_batch_src_global generation:  0.017164945602416992
r_  generation:  0.17877578735351562
----------------------check_connections_block total spend ----------------------------- 0.5411224365234375
generate_one_block  0.1993556022644043
generate_one_block  0.1988816261291504
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.027333736419677734
gen group dst list time:  0.0075914859771728516
time for parepare:  0.019160032272338867
local_output_nid generation:  0.024708271026611328
local_in_edges_tensor generation:  0.04740309715270996
mini_batch_src_global generation:  0.043192386627197266
r_  generation:  0.4715244770050049
local_output_nid generation:  0.031371355056762695
local_in_edges_tensor generation:  0.046661376953125
mini_batch_src_global generation:  0.05278658866882324
r_  generation:  0.4964582920074463
----------------------check_connections_block total spend ----------------------------- 1.4550113677978516
generate_one_block  0.6465456485748291
generate_one_block  0.6221413612365723
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03809309005737305
gen group dst list time:  0.013941764831542969
time for parepare:  0.018650293350219727
local_output_nid generation:  0.029892683029174805
local_in_edges_tensor generation:  0.058828115463256836
mini_batch_src_global generation:  0.048583269119262695
r_  generation:  0.5125002861022949
local_output_nid generation:  0.037253618240356445
local_in_edges_tensor generation:  0.05273008346557617
mini_batch_src_global generation:  0.055792808532714844
r_  generation:  0.5270934104919434
----------------------check_connections_block total spend ----------------------------- 1.5812911987304688
generate_one_block  0.6414303779602051
generate_one_block  0.6775350570678711
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.02567601203918457
gen group dst list time:  0.01244044303894043
time for parepare:  0.019748687744140625
local_output_nid generation:  0.03839683532714844
local_in_edges_tensor generation:  0.03871035575866699
mini_batch_src_global generation:  0.030947208404541016
r_  generation:  0.4021115303039551
local_output_nid generation:  0.04102373123168945
local_in_edges_tensor generation:  0.03346872329711914
mini_batch_src_global generation:  0.040125370025634766
r_  generation:  0.396587610244751
----------------------check_connections_block total spend ----------------------------- 1.2348854541778564
generate_one_block  0.46770143508911133
generate_one_block  0.46349573135375977
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012969970703125  GigaBytes
Max Memory Allocated: 0.0012969970703125  GigaBytes

connection checking time:  4.271188020706177
block generation total time  3.5188496112823486
average batch blocks generation time:  1.7594248056411743
block dataloader generation time/epoch 9.199485301971436
pseudo mini batch 0 input nodes size: 166966
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012969970703125  GigaBytes
Max Memory Allocated: 0.0012969970703125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0012969970703125  GigaBytes
Max Memory Allocated: 0.0012969970703125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0975341796875 GB
    Memory Allocated: 0.0813751220703125  GigaBytes
Max Memory Allocated: 0.0813751220703125  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0975341796875 GB
    Memory Allocated: 0.08171415328979492  GigaBytes
Max Memory Allocated: 0.08171415328979492  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0975341796875 GB
    Memory Allocated: 0.08171415328979492  GigaBytes
Max Memory Allocated: 0.08171415328979492  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2010498046875 GB
    Memory Allocated: 0.11541891098022461  GigaBytes
Max Memory Allocated: 0.11541891098022461  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2010498046875 GB
    Memory Allocated: 0.11541891098022461  GigaBytes
Max Memory Allocated: 0.11541891098022461  GigaBytes

first layer input nodes number: 166966
first layer output nodes number: 166291
edges number: 1041208
----------------------------------------before model layer 0
 Nvidia-smi: 1.2205810546875 GB
    Memory Allocated: 0.11790227890014648  GigaBytes
Max Memory Allocated: 0.1217813491821289  GigaBytes

torch.Size([166966, 128])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2205810546875 GB
    Memory Allocated: 0.11790227890014648  GigaBytes
Max Memory Allocated: 0.1217813491821289  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.8182373046875 GB
    Memory Allocated: 0.3649458885192871  GigaBytes
Max Memory Allocated: 0.3649458885192871  GigaBytes

torch.Size([166291, 256])
torch.Size([166291, 256])
----------------------------------------after rst
 Nvidia-smi: 2.1385498046875 GB
    Memory Allocated: 0.5235333442687988  GigaBytes
Max Memory Allocated: 0.6821208000183105  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.1385498046875 GB
    Memory Allocated: 0.3649458885192871  GigaBytes
Max Memory Allocated: 0.6821208000183105  GigaBytes

torch.Size([166291, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.1385498046875 GB
    Memory Allocated: 0.5235333442687988  GigaBytes
Max Memory Allocated: 0.6821208000183105  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.1385498046875 GB
    Memory Allocated: 0.5631804466247559  GigaBytes
Max Memory Allocated: 0.7217679023742676  GigaBytes

input nodes number: 166291
output nodes number: 162355
edges number: 1558836
----------------------------------------before model layer 1
 Nvidia-smi: 2.1385498046875 GB
    Memory Allocated: 0.5663180351257324  GigaBytes
Max Memory Allocated: 0.7217679023742676  GigaBytes

torch.Size([166291, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 2.1385498046875 GB
    Memory Allocated: 0.5663180351257324  GigaBytes
Max Memory Allocated: 0.7217679023742676  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.3709716796875 GB
    Memory Allocated: 0.8889689445495605  GigaBytes
Max Memory Allocated: 0.8889689445495605  GigaBytes

torch.Size([162355, 256])
torch.Size([162355, 256])
----------------------------------------after rst
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 1.0438027381896973  GigaBytes
Max Memory Allocated: 1.198636531829834  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 0.8889689445495605  GigaBytes
Max Memory Allocated: 1.198636531829834  GigaBytes

torch.Size([162355, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 1.0438027381896973  GigaBytes
Max Memory Allocated: 1.198636531829834  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 1.0825114250183105  GigaBytes
Max Memory Allocated: 1.2373452186584473  GigaBytes

input nodes number: 162355
output nodes number: 134582
edges number: 1477862
----------------------------------------before model layer 2
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 1.085343837738037  GigaBytes
Max Memory Allocated: 1.2373452186584473  GigaBytes

torch.Size([162355, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 2.6834716796875 GB
    Memory Allocated: 1.085343837738037  GigaBytes
Max Memory Allocated: 1.2373452186584473  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.8143310546875 GB
    Memory Allocated: 1.354611873626709  GigaBytes
Max Memory Allocated: 1.354611873626709  GigaBytes

torch.Size([134582, 256])
torch.Size([134582, 256])
----------------------------------------after rst
 Nvidia-smi: 3.0721435546875 GB
    Memory Allocated: 1.483518123626709  GigaBytes
Max Memory Allocated: 1.612424373626709  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 3.0721435546875 GB
    Memory Allocated: 1.355170726776123  GigaBytes
Max Memory Allocated: 1.612424373626709  GigaBytes

torch.Size([134582, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 3.0721435546875 GB
    Memory Allocated: 1.484076976776123  GigaBytes
Max Memory Allocated: 1.612424373626709  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5156049728393555  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

----------------input nodes number: 134582
----------------output nodes number: 45471
----------------edges number: 424442
----------------------------------------before mean aggregator
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5170602798461914  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5708436965942383  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

torch.Size([45471, 40])
torch.Size([45471, 40])
----------------------------------------after rst
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5776195526123047  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5708436965942383  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

torch.Size([45471, 40])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5776195526123047  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 3.1053466796875 GB
    Memory Allocated: 1.5843963623046875  GigaBytes
Max Memory Allocated: 1.6445112228393555  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.19665861129760742  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

pseudo mini batch 1 input nodes size: 166958
----------------------------------------before load block subtensor 
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.08978796005249023  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.08978796005249023  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.16986608505249023  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.17020511627197266  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.08978796005249023  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.12342596054077148  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.12342596054077148  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

first layer input nodes number: 166958
first layer output nodes number: 166291
edges number: 1041088
----------------------------------------before model layer 0
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.12590932846069336  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([166958, 128])
----------------------------------------before mean aggregator
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.12590932846069336  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.3729519844055176  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([166291, 256])
torch.Size([166291, 256])
----------------------------------------after rst
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.5315394401550293  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.3729519844055176  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([166291, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.5315394401550293  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.5711865425109863  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

input nodes number: 166291
output nodes number: 162244
edges number: 1558321
----------------------------------------before model layer 1
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.5743241310119629  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([166291, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.5743241310119629  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.8967633247375488  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([162244, 256])
torch.Size([162244, 256])
----------------------------------------after rst
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.0514912605285645  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 0.8967633247375488  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([162244, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.0514912605285645  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.0901732444763184  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

input nodes number: 162244
output nodes number: 134251
edges number: 1471432
----------------------------------------before model layer 2
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.093217372894287  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([162244, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.093217372894287  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.3624348640441895  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([134251, 256])
torch.Size([134251, 256])
----------------------------------------after rst
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.4913411140441895  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.3629937171936035  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([134251, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.4913411140441895  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.5239081382751465  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------input nodes number: 134251
----------------output nodes number: 45470
----------------edges number: 421837
----------------------------------------before mean aggregator
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.525442123413086  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.5792417526245117  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([45470, 40])
torch.Size([45470, 40])
----------------------------------------after rst
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.5860176086425781  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.5792417526245117  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

torch.Size([45470, 40])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.5792417526245117  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 4.1561279296875 GB
    Memory Allocated: 1.5868172645568848  GigaBytes
Max Memory Allocated: 1.788863182067871  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 4.1580810546875 GB
    Memory Allocated: 0.19677734375  GigaBytes
Max Memory Allocated: 1.7895145416259766  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 4.1600341796875 GB
    Memory Allocated: 0.199371337890625  GigaBytes
Max Memory Allocated: 1.7895145416259766  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 4.1600341796875 GB
    Memory Allocated: 0.199371337890625  GigaBytes
Max Memory Allocated: 1.7895145416259766  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.04037666320800781 |0.18872499465942383 |0.42172205448150635 |0.0002601146697998047 |0.021899700164794922 |0.002293825149536133 |
----------------------------------------------------------pseudo_mini_loss sum 6.494068145751953
Total (block generation + training)time/epoch 10.58532166481018
Training time/epoch 1.3852226734161377
Training time without block to device /epoch 1.00777268409729
Training time without total dataloading part /epoch 0.8900575637817383
load block tensor time/epoch 0.08075332641601562
block to device time/epoch 0.37744998931884766
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1259938
Number of first layer input nodes during this epoch:  333924
Number of first layer output nodes during this epoch:  332582
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=128, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=128, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=40, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=40, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  348160
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 128])
layers.0.fc_neigh.weight, torch.Size([256, 128])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([40, 256])
layers.3.fc_neigh.weight, torch.Size([40, 256])
----------------------------------------
un-trainable parameters
