main start at this time 1657072172.981539
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
153431
23831
55703
# Nodes: 232965
# Edges: 114615892
# Train: 153431
# Val: 23831
# Test: 55703
# Classes: 41

#nodes: 232965
#edges: 114615892
#classes: 41
----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  602
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

connection checking time:  0
block generation total time  0
average batch blocks generation time:  0
block dataloader generation time/epoch 0.4958667755126953
pseudo mini batch 0 input nodes size: 230242
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.5350341796875 GB
    Memory Allocated: 0.5180611610412598  GigaBytes
Max Memory Allocated: 0.5180611610412598  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.5350341796875 GB
    Memory Allocated: 0.5192928314208984  GigaBytes
Max Memory Allocated: 0.5192928314208984  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.5350341796875 GB
    Memory Allocated: 0.5192928314208984  GigaBytes
Max Memory Allocated: 0.5192928314208984  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.6971435546875 GB
    Memory Allocated: 0.6072301864624023  GigaBytes
Max Memory Allocated: 0.6072301864624023  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.6971435546875 GB
    Memory Allocated: 0.6072301864624023  GigaBytes
Max Memory Allocated: 0.6072301864624023  GigaBytes

first layer input nodes number: 230242
first layer output nodes number: 229680
edges number: 2238768
----------------------------------------before model layer 0
 Nvidia-smi: 1.7166748046875 GB
    Memory Allocated: 0.6107301712036133  GigaBytes
Max Memory Allocated: 0.6190705299377441  GigaBytes

torch.Size([230242, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.7166748046875 GB
    Memory Allocated: 0.6107301712036133  GigaBytes
Max Memory Allocated: 0.6190705299377441  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.5076904296875 GB
    Memory Allocated: 1.362931728363037  GigaBytes
Max Memory Allocated: 1.6603727340698242  GigaBytes

torch.Size([229680, 256])
torch.Size([229680, 256])
----------------------------------------after rst
 Nvidia-smi: 3.7283935546875 GB
    Memory Allocated: 1.5819716453552246  GigaBytes
Max Memory Allocated: 1.801011562347412  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.7283935546875 GB
    Memory Allocated: 1.362931728363037  GigaBytes
Max Memory Allocated: 1.801011562347412  GigaBytes

torch.Size([229680, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.7283935546875 GB
    Memory Allocated: 1.5819716453552246  GigaBytes
Max Memory Allocated: 1.801011562347412  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.7283935546875 GB
    Memory Allocated: 1.6367316246032715  GigaBytes
Max Memory Allocated: 1.855771541595459  GigaBytes

input nodes number: 229680
output nodes number: 224623
edges number: 5315071
----------------------------------------before model layer 1
 Nvidia-smi: 3.7283935546875 GB
    Memory Allocated: 1.640127182006836  GigaBytes
Max Memory Allocated: 1.855771541595459  GigaBytes

torch.Size([229680, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.7283935546875 GB
    Memory Allocated: 1.640127182006836  GigaBytes
Max Memory Allocated: 1.855771541595459  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.0701904296875 GB
    Memory Allocated: 2.110462188720703  GigaBytes
Max Memory Allocated: 2.110462188720703  GigaBytes

torch.Size([224623, 256])
torch.Size([224623, 256])
----------------------------------------after rst
 Nvidia-smi: 4.4998779296875 GB
    Memory Allocated: 2.325305938720703  GigaBytes
Max Memory Allocated: 2.540149688720703  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 4.4998779296875 GB
    Memory Allocated: 2.111088752746582  GigaBytes
Max Memory Allocated: 2.540149688720703  GigaBytes

torch.Size([224623, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 4.4998779296875 GB
    Memory Allocated: 2.325932502746582  GigaBytes
Max Memory Allocated: 2.540149688720703  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 4.5545654296875 GB
    Memory Allocated: 2.3788604736328125  GigaBytes
Max Memory Allocated: 2.5937042236328125  GigaBytes

----------------input nodes number: 224623
----------------output nodes number: 153431
----------------edges number: 4248792
----------------------------------------before mean aggregator
 Nvidia-smi: 4.5545654296875 GB
    Memory Allocated: 2.3822078704833984  GigaBytes
Max Memory Allocated: 2.5937042236328125  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.7010498046875 GB
    Memory Allocated: 2.5849266052246094  GigaBytes
Max Memory Allocated: 2.707815170288086  GigaBytes

torch.Size([153431, 41])
torch.Size([153431, 41])
----------------------------------------after rst
 Nvidia-smi: 4.7010498046875 GB
    Memory Allocated: 2.60836124420166  GigaBytes
Max Memory Allocated: 2.707815170288086  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 4.7010498046875 GB
    Memory Allocated: 2.5849266052246094  GigaBytes
Max Memory Allocated: 2.707815170288086  GigaBytes

torch.Size([153431, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.7010498046875 GB
    Memory Allocated: 2.60836124420166  GigaBytes
Max Memory Allocated: 2.707815170288086  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 4.7010498046875 GB
    Memory Allocated: 2.6317968368530273  GigaBytes
Max Memory Allocated: 2.707815170288086  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 5.4080810546875 GB
    Memory Allocated: 0.8057746887207031  GigaBytes
Max Memory Allocated: 2.900130271911621  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 5.4119873046875 GB
    Memory Allocated: 0.8092041015625  GigaBytes
Max Memory Allocated: 2.900130271911621  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.4119873046875 GB
    Memory Allocated: 0.8092041015625  GigaBytes
Max Memory Allocated: 2.900130271911621  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.19077849388122559 |0.38207268714904785 |0.8002662658691406 |0.00024318695068359375 |0.05308890342712402 |0.0044498443603515625 |
----------------------------------------------------------pseudo_mini_loss sum 10.840394973754883
Total (block generation + training)time/epoch 1.954418659210205
Training time/epoch 1.4582912921905518
Training time without block to device /epoch 1.076218605041504
Training time without total dataloading part /epoch 0.8580482006072998
load block tensor time/epoch 0.19077849388122559
block to device time/epoch 0.38207268714904785
input features size transfer per epoch 1.341104507446289e-07
blocks size to device per epoch 1.043081283569336e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  684545
Number of first layer input nodes during this epoch:  230242
Number of first layer output nodes during this epoch:  229680
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=602, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=602, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=41, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=41, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  460288
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 602])
layers.0.fc_neigh.weight, torch.Size([256, 602])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([41, 256])
layers.2.fc_neigh.weight, torch.Size([41, 256])
----------------------------------------
un-trainable parameters
