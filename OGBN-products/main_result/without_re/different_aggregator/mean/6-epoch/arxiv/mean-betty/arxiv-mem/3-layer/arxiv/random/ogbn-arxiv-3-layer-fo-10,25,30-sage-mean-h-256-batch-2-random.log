main start at this time 1657071978.4201949
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

ogbn-arxiv
# Nodes: 169343
# Edges: 2315598
# Train: 90941
# Val: 29799
# Test: 48603
# Classes: 40

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  128
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0008087158203125  GigaBytes
Max Memory Allocated: 0.0008087158203125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0008087158203125  GigaBytes
Max Memory Allocated: 0.0008087158203125  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.026617765426635742
number of batches is  2
batch size is  45471
random selection method spend 0.007061481475830078
time for parepare:  0.019043445587158203
local_output_nid generation:  0.019715547561645508
local_in_edges_tensor generation:  0.015380382537841797
mini_batch_src_global generation:  0.011896848678588867
r_  generation:  0.15604615211486816
local_output_nid generation:  0.02114391326904297
local_in_edges_tensor generation:  0.010272026062011719
mini_batch_src_global generation:  0.015320777893066406
r_  generation:  0.16617512702941895
----------------------check_connections_block total spend ----------------------------- 0.5073957443237305
generate_one_block  0.18647289276123047
generate_one_block  0.18333792686462402
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.03610563278198242
gen group dst list time:  0.006852865219116211
time for parepare:  0.019321918487548828
local_output_nid generation:  0.02763962745666504
local_in_edges_tensor generation:  0.04807543754577637
mini_batch_src_global generation:  0.04005718231201172
r_  generation:  0.4518768787384033
local_output_nid generation:  0.029991626739501953
local_in_edges_tensor generation:  0.043196916580200195
mini_batch_src_global generation:  0.047515869140625
r_  generation:  0.4464535713195801
----------------------check_connections_block total spend ----------------------------- 1.3632903099060059
generate_one_block  0.5546629428863525
generate_one_block  0.5749766826629639
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0268399715423584
gen group dst list time:  0.011659622192382812
time for parepare:  0.01880502700805664
local_output_nid generation:  0.028908729553222656
local_in_edges_tensor generation:  0.03800368309020996
mini_batch_src_global generation:  0.030661821365356445
r_  generation:  0.36522603034973145
local_output_nid generation:  0.03576207160949707
local_in_edges_tensor generation:  0.03254532814025879
mini_batch_src_global generation:  0.03715229034423828
r_  generation:  0.37351512908935547
----------------------check_connections_block total spend ----------------------------- 1.1351099014282227
generate_one_block  0.44626331329345703
generate_one_block  0.45616841316223145
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0008087158203125  GigaBytes
Max Memory Allocated: 0.0008087158203125  GigaBytes

connection checking time:  2.4984002113342285
block generation total time  2.032071352005005
average batch blocks generation time:  1.0160356760025024
block dataloader generation time/epoch 5.70991325378418
pseudo mini batch 0 input nodes size: 165285
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0008087158203125  GigaBytes
Max Memory Allocated: 0.0008087158203125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0008087158203125  GigaBytes
Max Memory Allocated: 0.0008087158203125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0975341796875 GB
    Memory Allocated: 0.07962274551391602  GigaBytes
Max Memory Allocated: 0.07962274551391602  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0975341796875 GB
    Memory Allocated: 0.07996177673339844  GigaBytes
Max Memory Allocated: 0.07996177673339844  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0975341796875 GB
    Memory Allocated: 0.07996177673339844  GigaBytes
Max Memory Allocated: 0.07996177673339844  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2010498046875 GB
    Memory Allocated: 0.10095453262329102  GigaBytes
Max Memory Allocated: 0.10095453262329102  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2010498046875 GB
    Memory Allocated: 0.10095453262329102  GigaBytes
Max Memory Allocated: 0.10095453262329102  GigaBytes

first layer input nodes number: 165285
first layer output nodes number: 161349
edges number: 1028307
----------------------------------------before model layer 0
 Nvidia-smi: 1.2010498046875 GB
    Memory Allocated: 0.10342121124267578  GigaBytes
Max Memory Allocated: 0.10725212097167969  GigaBytes

torch.Size([165285, 128])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2010498046875 GB
    Memory Allocated: 0.10342121124267578  GigaBytes
Max Memory Allocated: 0.10725212097167969  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.7830810546875 GB
    Memory Allocated: 0.3432950973510742  GigaBytes
Max Memory Allocated: 0.3432950973510742  GigaBytes

torch.Size([161349, 256])
torch.Size([161349, 256])
----------------------------------------after rst
 Nvidia-smi: 2.0916748046875 GB
    Memory Allocated: 0.4975919723510742  GigaBytes
Max Memory Allocated: 0.6518888473510742  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 2.0916748046875 GB
    Memory Allocated: 0.3432950973510742  GigaBytes
Max Memory Allocated: 0.6518888473510742  GigaBytes

torch.Size([161349, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 2.0916748046875 GB
    Memory Allocated: 0.4975919723510742  GigaBytes
Max Memory Allocated: 0.6518888473510742  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 2.0916748046875 GB
    Memory Allocated: 0.5360608100891113  GigaBytes
Max Memory Allocated: 0.6903576850891113  GigaBytes

input nodes number: 161349
output nodes number: 131744
edges number: 1358839
----------------------------------------before model layer 1
 Nvidia-smi: 2.0916748046875 GB
    Memory Allocated: 0.5384511947631836  GigaBytes
Max Memory Allocated: 0.6903576850891113  GigaBytes

torch.Size([161349, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 2.0916748046875 GB
    Memory Allocated: 0.5384511947631836  GigaBytes
Max Memory Allocated: 0.6903576850891113  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.2694091796875 GB
    Memory Allocated: 0.8010053634643555  GigaBytes
Max Memory Allocated: 0.8010053634643555  GigaBytes

torch.Size([131744, 256])
torch.Size([131744, 256])
----------------------------------------after rst
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 0.9266462326049805  GigaBytes
Max Memory Allocated: 1.0522871017456055  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 0.8010053634643555  GigaBytes
Max Memory Allocated: 1.0522871017456055  GigaBytes

torch.Size([131744, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 0.9266462326049805  GigaBytes
Max Memory Allocated: 1.0522871017456055  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 0.9580564498901367  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

----------------input nodes number: 131744
----------------output nodes number: 45471
----------------edges number: 392238
----------------------------------------before mean aggregator
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 0.9597077369689941  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 1.013110637664795  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

torch.Size([45471, 40])
torch.Size([45471, 40])
----------------------------------------after rst
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 1.0198864936828613  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 1.013110637664795  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

torch.Size([45471, 40])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 1.0198864936828613  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 2.5233154296875 GB
    Memory Allocated: 1.0266633033752441  GigaBytes
Max Memory Allocated: 1.0836973190307617  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.1517019271850586  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

pseudo mini batch 1 input nodes size: 165144
----------------------------------------before load block subtensor 
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.08754730224609375  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.08754730224609375  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.16629409790039062  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.16663312911987305  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.08748006820678711  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.10918664932250977  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.10918664932250977  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

first layer input nodes number: 165144
first layer output nodes number: 161346
edges number: 1028866
----------------------------------------before model layer 0
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.11161994934082031  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([165144, 128])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.11161994934082031  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.3514857292175293  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([161346, 256])
torch.Size([161346, 256])
----------------------------------------after rst
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.5057826042175293  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.3514857292175293  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([161346, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.5057826042175293  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.54425048828125  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

input nodes number: 161346
output nodes number: 131822
edges number: 1362393
----------------------------------------before model layer 1
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.5466423034667969  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([161346, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.5466423034667969  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.8092060089111328  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([131822, 256])
torch.Size([131822, 256])
----------------------------------------after rst
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.9349212646484375  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.8092060089111328  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([131822, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.9349212646484375  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.9663500785827637  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------input nodes number: 131822
----------------output nodes number: 45470
----------------edges number: 393022
----------------------------------------before mean aggregator
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 0.9678888320922852  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 1.0217432975769043  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([45470, 40])
torch.Size([45470, 40])
----------------------------------------after rst
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 1.0285191535949707  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 1.0217432975769043  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

torch.Size([45470, 40])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 1.0217432975769043  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 3.0858154296875 GB
    Memory Allocated: 1.028519630432129  GigaBytes
Max Memory Allocated: 1.2243494987487793  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 3.2401123046875 GB
    Memory Allocated: 0.15281295776367188  GigaBytes
Max Memory Allocated: 1.2265548706054688  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 3.2420654296875 GB
    Memory Allocated: 0.15443038940429688  GigaBytes
Max Memory Allocated: 1.2265548706054688  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 3.2420654296875 GB
    Memory Allocated: 0.15443038940429688  GigaBytes
Max Memory Allocated: 1.2265548706054688  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.02911698818206787 |0.17209458351135254 |0.400287389755249 |0.00022292137145996094 |0.011866569519042969 |0.001720428466796875 |
----------------------------------------------------------pseudo_mini_loss sum 4.598382949829102
Total (block generation + training)time/epoch 6.963169574737549
Training time/epoch 1.2523870468139648
Training time without block to device /epoch 0.9081978797912598
Training time without total dataloading part /epoch 0.8264741897583008
load block tensor time/epoch 0.05823397636413574
block to device time/epoch 0.3441891670227051
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  916690
Number of first layer input nodes during this epoch:  330429
Number of first layer output nodes during this epoch:  322695
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=128, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=128, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=40, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=40, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  217088
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 128])
layers.0.fc_neigh.weight, torch.Size([256, 128])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([40, 256])
layers.2.fc_neigh.weight, torch.Size([40, 256])
----------------------------------------
un-trainable parameters
