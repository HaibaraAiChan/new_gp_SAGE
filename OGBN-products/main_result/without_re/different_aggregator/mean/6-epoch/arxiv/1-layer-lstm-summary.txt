1 layer fanout=10
sage + lstm
hidden 256

2 batch

    in-degree 
    batch 0: {1: 6589, 2: 6002, 3: 4958, 4: 4011, 5: 3362, 6: 2742, 7: 2291, 8: 1966, 9: 1662, 10: 12887}  
    total output nodes: 46470
    cuda memory consumption: 
    0.1903	0.099	0.118	0.123	0.1278	0.122	0.125	0.1169	0.11	1.025


    batch 1: {1: 6839, 2: 5704, 3: 4319, 4: 3309, 5: 2860, 6: 2126, 7: 1754, 8: 1506, 9: 1314, 10: 14740}
    total output nodes: 44471

    cuda memory consumption: 
    0.1891	0.092	0.0994	0.1022	0.1085	0.0949	0.09	0.0889	0.0811	1.088

4 batches
batch 0:{1: 3551, 2: 3190, 3: 2559, 4: 2102, 5: 1706, 6: 1369, 7: 1162, 8: 1010, 9: 808, 10: 5751}
batch 1:{1: 2954, 2: 2744, 3: 2334, 4: 1892, 5: 1582, 6: 1317, 7: 1111, 8: 952, 9: 850, 10: 7091}
batch 2:{1: 4413, 2: 3651, 3: 2678, 4: 2017, 5: 1727, 6: 1261, 7: 980, 8: 846, 9: 674, 10: 4201}
batch 3:{1: 2510, 2: 2121, 3: 1706, 4: 1309, 5: 1207, 6: 921, 7: 792, 8: 664, 9: 644, 10: 10584}