main start at this time 1656402530.4795625
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  1433
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.06725025177001953  GigaBytes
Max Memory Allocated: 0.06725025177001953  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.06725025177001953  GigaBytes
Max Memory Allocated: 0.06725025177001953  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0010540485382080078
global_2_local spend time (sec) 0.0001239776611328125
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.00039839744567871094
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 488, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 8: 3, 10: 3, 12: 2, 25: 2, 19: 1, 11: 1, 21: 1})

A = g.adjacency_matrix() spent  0.00032520294189453125
auxiliary_graph
Graph(num_nodes=628, num_edges=436,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0004570484161376953
remove nodes length  488

auxiliary_graph.remove_nodes spent  0.0017209053039550781
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=436,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0008285045623779297

the counter of shared neighbor distribution
Counter({1.0: 250, 2.0: 30, 3.0: 14, 4.0: 2})
296
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.001 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0018970966339111328
69
71
total k batches seeds list generation spend  0.009366512298583984
after graph partition
graph partition algorithm spend time 0.05175900459289551
69
71
partition_len_list
[307, 327]
REG selection method  spend 0.05211329460144043
time for parepare:  8.940696716308594e-05
local_output_nid generation:  1.52587890625e-05
local_in_edges_tensor generation:  0.0001838207244873047
mini_batch_src_global generation:  4.8160552978515625e-05
r_  generation:  0.00018906593322753906
local_output_nid generation:  1.049041748046875e-05
local_in_edges_tensor generation:  0.00013566017150878906
mini_batch_src_global generation:  3.123283386230469e-05
r_  generation:  0.00014257431030273438
----------------------check_connections_block total spend ----------------------------- 0.0010521411895751953
generate_one_block  0.002602100372314453
generate_one_block  0.0014510154724121094
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005810260772705078
gen group dst list time:  3.9577484130859375e-05
time for parepare:  0.00017762184143066406
local_output_nid generation:  2.9325485229492188e-05
local_in_edges_tensor generation:  0.0002491474151611328
mini_batch_src_global generation:  6.67572021484375e-05
r_  generation:  0.0006859302520751953
local_output_nid generation:  3.24249267578125e-05
local_in_edges_tensor generation:  0.00019168853759765625
mini_batch_src_global generation:  8.130073547363281e-05
r_  generation:  0.0006680488586425781
----------------------check_connections_block total spend ----------------------------- 0.0025682449340820312
generate_one_block  0.0019655227661132812
generate_one_block  0.001979351043701172
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.06725025177001953  GigaBytes
Max Memory Allocated: 0.06725025177001953  GigaBytes

connection checking time:  0.0036203861236572266
block generation total time  0.007997989654541016
average batch blocks generation time:  0.001999497413635254
block dataloader generation time/epoch 0.06920266151428223
pseudo mini batch 0 input nodes size: 819
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.06725025177001953  GigaBytes
Max Memory Allocated: 0.06725025177001953  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.06725025177001953  GigaBytes
Max Memory Allocated: 0.06725025177001953  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.07162237167358398  GigaBytes
Max Memory Allocated: 0.07162237167358398  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.07162332534790039  GigaBytes
Max Memory Allocated: 0.07162332534790039  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.07162332534790039  GigaBytes
Max Memory Allocated: 0.07162332534790039  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1658935546875 GB
    Memory Allocated: 0.07163763046264648  GigaBytes
Max Memory Allocated: 0.07163763046264648  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1658935546875 GB
    Memory Allocated: 0.07163763046264648  GigaBytes
Max Memory Allocated: 0.07163763046264648  GigaBytes

first layer input nodes number: 819
first layer output nodes number: 307
edges number: 1503
torch.Size([819, 1433])
torch.Size([307, 256])
torch.Size([69, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4080810546875 GB
    Memory Allocated: 0.20409154891967773  GigaBytes
Max Memory Allocated: 0.2103252410888672  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.4080810546875 GB
    Memory Allocated: 0.20409440994262695  GigaBytes
Max Memory Allocated: 0.2103252410888672  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.1391921043395996  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

pseudo mini batch 1 input nodes size: 712
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.13914871215820312  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.13914871215820312  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.14313650131225586  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.14313745498657227  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.1387643814086914  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.1387786865234375  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.1387786865234375  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

first layer input nodes number: 712
first layer output nodes number: 327
edges number: 1453
torch.Size([712, 1433])
torch.Size([327, 256])
torch.Size([71, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.2696256637573242  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.5369873046875 GB
    Memory Allocated: 0.26962804794311523  GigaBytes
Max Memory Allocated: 0.3219943046569824  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.6307373046875 GB
    Memory Allocated: 0.1388077735900879  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.27358055114746094  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.27358055114746094  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.015066146850585938 |0.17293071746826172 |0.27423036098480225 |0.00017392635345458984 |0.03968000411987305 |0.005762338638305664 |
----------------------------------------------------------pseudo_mini_loss sum 1.9466502666473389
Total (block generation + training)time/epoch 1.1084785461425781
Training time/epoch 1.0390281677246094
Training time without block to device /epoch 0.6931667327880859
Training time without total dataloading part /epoch 0.6339309215545654
load block tensor time/epoch 0.030132293701171875
block to device time/epoch 0.34586143493652344
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  2165
Number of first layer input nodes during this epoch:  1531
Number of first layer output nodes during this epoch:  634
----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.27358007431030273  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006737709045410156
global_2_local spend time (sec) 0.00014638900756835938
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003132820129394531
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 493, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 8: 3, 10: 3, 25: 2, 12: 2, 11: 1, 21: 1, 19: 1})

A = g.adjacency_matrix() spent  0.00015997886657714844
auxiliary_graph
Graph(num_nodes=633, num_edges=430,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.00046372413635253906
remove nodes length  493

auxiliary_graph.remove_nodes spent  0.0010058879852294922
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=430,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007822513580322266

the counter of shared neighbor distribution
Counter({1.0: 244, 2.0: 30, 3.0: 14, 4.0: 2})
290
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.001 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0017256736755371094
72
68
total k batches seeds list generation spend  0.006474494934082031
after graph partition
graph partition algorithm spend time 0.0349123477935791
72
68
partition_len_list
[342, 298]
REG selection method  spend 0.03534531593322754
time for parepare:  0.00015091896057128906
local_output_nid generation:  1.7881393432617188e-05
local_in_edges_tensor generation:  0.0003063678741455078
mini_batch_src_global generation:  6.628036499023438e-05
r_  generation:  0.0002911090850830078
local_output_nid generation:  1.7642974853515625e-05
local_in_edges_tensor generation:  0.0002856254577636719
mini_batch_src_global generation:  6.031990051269531e-05
r_  generation:  0.00028014183044433594
----------------------check_connections_block total spend ----------------------------- 0.0018754005432128906
generate_one_block  0.004197597503662109
generate_one_block  0.0024428367614746094
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0008001327514648438
gen group dst list time:  4.9114227294921875e-05
time for parepare:  0.00022292137145996094
local_output_nid generation:  5.245208740234375e-05
local_in_edges_tensor generation:  0.00032258033752441406
mini_batch_src_global generation:  9.894371032714844e-05
r_  generation:  0.0010237693786621094
local_output_nid generation:  4.553794860839844e-05
local_in_edges_tensor generation:  0.00025844573974609375
mini_batch_src_global generation:  0.00010538101196289062
r_  generation:  0.0008668899536132812
----------------------check_connections_block total spend ----------------------------- 0.003549337387084961
generate_one_block  0.0029463768005371094
generate_one_block  0.0032455921173095703
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.27358007431030273  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

connection checking time:  0.0054247379302978516
block generation total time  0.012832403182983398
average batch blocks generation time:  0.0032081007957458496
block dataloader generation time/epoch 0.06427979469299316
pseudo mini batch 0 input nodes size: 888
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.2782769203186035  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.2782778739929199  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.2742891311645508  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.2743043899536133  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.2743043899536133  GigaBytes
Max Memory Allocated: 0.38402700424194336  GigaBytes

first layer input nodes number: 888
first layer output nodes number: 342
edges number: 1625
torch.Size([888, 1433])
torch.Size([342, 256])
torch.Size([72, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.4198431968688965  GigaBytes
Max Memory Allocated: 0.426544189453125  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.6932373046875 GB
    Memory Allocated: 0.4198460578918457  GigaBytes
Max Memory Allocated: 0.426544189453125  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2743363380432129  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

pseudo mini batch 1 input nodes size: 654
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2742900848388672  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2742900848388672  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2782778739929199  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27827882766723633  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27353715896606445  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

first layer input nodes number: 654
first layer output nodes number: 298
edges number: 1342
torch.Size([654, 1433])
torch.Size([298, 256])
torch.Size([68, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.39302587509155273  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.39302825927734375  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.014216899871826172 |0.00037872791290283203 |0.039696335792541504 |0.0001302957534790039 |0.03940629959106445 |0.0038764476776123047 |
----------------------------------------------------------pseudo_mini_loss sum 4.5321364402771
Total (block generation + training)time/epoch 0.6942323446273804
Training time/epoch 0.22047734260559082
Training time without block to device /epoch 0.21971988677978516
Training time without total dataloading part /epoch 0.16234230995178223
load block tensor time/epoch 0.028433799743652344
block to device time/epoch 0.0007574558258056641
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  2182
Number of first layer input nodes during this epoch:  1542
Number of first layer output nodes during this epoch:  640
----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2735772132873535  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006372928619384766
global_2_local spend time (sec) 0.00015044212341308594
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003135204315185547
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 489, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 8: 3, 10: 3, 12: 2, 25: 2, 19: 1, 11: 1, 21: 1})

A = g.adjacency_matrix() spent  0.0001552104949951172
auxiliary_graph
Graph(num_nodes=629, num_edges=432,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0005002021789550781
remove nodes length  489

auxiliary_graph.remove_nodes spent  0.0008847713470458984
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=432,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007703304290771484

the counter of shared neighbor distribution
Counter({1.0: 248, 2.0: 30, 3.0: 12, 4.0: 2})
292
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0013096332550048828
72
68
total k batches seeds list generation spend  0.0059430599212646484
after graph partition
graph partition algorithm spend time 0.050894975662231445
72
68
partition_len_list
[354, 282]
REG selection method  spend 0.05121755599975586
time for parepare:  7.605552673339844e-05
local_output_nid generation:  8.821487426757812e-06
local_in_edges_tensor generation:  0.00015306472778320312
mini_batch_src_global generation:  3.981590270996094e-05
r_  generation:  0.00016164779663085938
local_output_nid generation:  1.0013580322265625e-05
local_in_edges_tensor generation:  0.00014829635620117188
mini_batch_src_global generation:  3.409385681152344e-05
r_  generation:  0.00014281272888183594
----------------------check_connections_block total spend ----------------------------- 0.0009729862213134766
generate_one_block  0.0018317699432373047
generate_one_block  0.0014352798461914062
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0004951953887939453
gen group dst list time:  3.075599670410156e-05
time for parepare:  0.0001404285430908203
local_output_nid generation:  3.123283386230469e-05
local_in_edges_tensor generation:  0.00020766258239746094
mini_batch_src_global generation:  8.106231689453125e-05
r_  generation:  0.0006079673767089844
local_output_nid generation:  2.7418136596679688e-05
local_in_edges_tensor generation:  0.00015425682067871094
mini_batch_src_global generation:  7.557868957519531e-05
r_  generation:  0.0004906654357910156
----------------------check_connections_block total spend ----------------------------- 0.002180337905883789
generate_one_block  0.0018146038055419922
generate_one_block  0.0019555091857910156
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2735772132873535  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

connection checking time:  0.0031533241271972656
block generation total time  0.007037162780761719
average batch blocks generation time:  0.0017592906951904297
block dataloader generation time/epoch 0.06504861513773601
pseudo mini batch 0 input nodes size: 871
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2781863212585449  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.27818727493286133  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2741985321044922  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2742147445678711  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7557373046875 GB
    Memory Allocated: 0.2742147445678711  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

first layer input nodes number: 871
first layer output nodes number: 354
edges number: 1667
torch.Size([871, 1433])
torch.Size([354, 256])
torch.Size([72, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7596435546875 GB
    Memory Allocated: 0.42384815216064453  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7596435546875 GB
    Memory Allocated: 0.42385101318359375  GigaBytes
Max Memory Allocated: 0.532386302947998  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2742476463317871  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

pseudo mini batch 1 input nodes size: 644
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2741994857788086  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2741994857788086  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27818727493286133  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27818822860717773  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353715896606445  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 644
first layer output nodes number: 282
edges number: 1287
torch.Size([644, 1433])
torch.Size([282, 256])
torch.Size([68, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.3890066146850586  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.3890089988708496  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.01278233528137207 |0.0003020763397216797 |0.03759956359863281 |0.0001131296157836914 |0.03887295722961426 |0.0038878917694091797 |
----------------------------------------------------------pseudo_mini_loss sum 5.720517635345459
Total (block generation + training)time/epoch 0.5553049246470133
Training time/epoch 0.21072149276733398
Training time without block to device /epoch 0.21011734008789062
Training time without total dataloading part /epoch 0.1570591926574707
load block tensor time/epoch 0.02556467056274414
block to device time/epoch 0.0006041526794433594
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 2 |
Number of nodes for computation during this epoch:  2151
Number of first layer input nodes during this epoch:  1515
Number of first layer output nodes during this epoch:  636
----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735772132873535  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.000629425048828125
global_2_local spend time (sec) 0.0001277923583984375
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0002760887145996094
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 489, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 8: 3, 10: 3, 25: 2, 12: 2, 21: 1, 11: 1, 19: 1})

A = g.adjacency_matrix() spent  0.00013685226440429688
auxiliary_graph
Graph(num_nodes=629, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0004062652587890625
remove nodes length  489

auxiliary_graph.remove_nodes spent  0.0007340908050537109
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0006589889526367188

the counter of shared neighbor distribution
Counter({1.0: 248, 2.0: 30, 3.0: 14, 4.0: 2})
294
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0012784004211425781
70
70
total k batches seeds list generation spend  0.005236387252807617
after graph partition
graph partition algorithm spend time 0.061522722244262695
70
70
partition_len_list
[332, 308]
REG selection method  spend 0.0618283748626709
time for parepare:  8.845329284667969e-05
local_output_nid generation:  1.1444091796875e-05
local_in_edges_tensor generation:  0.00016689300537109375
mini_batch_src_global generation:  4.1961669921875e-05
r_  generation:  0.00016260147094726562
local_output_nid generation:  1.2159347534179688e-05
local_in_edges_tensor generation:  0.0001647472381591797
mini_batch_src_global generation:  4.220008850097656e-05
r_  generation:  0.00017333030700683594
----------------------check_connections_block total spend ----------------------------- 0.0010867118835449219
generate_one_block  0.0019223690032958984
generate_one_block  0.0016589164733886719
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0006775856018066406
gen group dst list time:  4.029273986816406e-05
time for parepare:  0.0001850128173828125
local_output_nid generation:  4.4345855712890625e-05
local_in_edges_tensor generation:  0.0003631114959716797
mini_batch_src_global generation:  0.00011682510375976562
r_  generation:  0.0010302066802978516
local_output_nid generation:  4.506111145019531e-05
local_in_edges_tensor generation:  0.00020503997802734375
mini_batch_src_global generation:  8.606910705566406e-05
r_  generation:  0.0006508827209472656
----------------------check_connections_block total spend ----------------------------- 0.0033190250396728516
generate_one_block  0.002533435821533203
generate_one_block  0.001993417739868164
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735772132873535  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

connection checking time:  0.0044057369232177734
block generation total time  0.008108139038085938
average batch blocks generation time:  0.0020270347595214844
block dataloader generation time/epoch 0.0688408613204956
pseudo mini batch 0 input nodes size: 840
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27802085876464844  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27802181243896484  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740330696105957  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740483283996582  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740483283996582  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 840
first layer output nodes number: 332
edges number: 1571
torch.Size([840, 1433])
torch.Size([332, 256])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.4155764579772949  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.41557931900024414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740802764892578  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

pseudo mini batch 1 input nodes size: 711
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740340232849121  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740340232849121  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27802181243896484  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27802276611328125  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353715896606445  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 711
first layer output nodes number: 308
edges number: 1407
torch.Size([711, 1433])
torch.Size([308, 256])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.39928150177001953  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.39928388595581055  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735781669616699  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735781669616699  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735781669616699  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.01315927505493164 |0.0004000663757324219 |0.03734564781188965 |0.00011658668518066406 |0.035595059394836426 |0.002376556396484375 |
----------------------------------------------------------pseudo_mini_loss sum 8.251544952392578
Total (block generation + training)time/epoch 0.4879738688468933
Training time/epoch 0.20561718940734863
Training time without block to device /epoch 0.2048170566558838
Training time without total dataloading part /epoch 0.14849114418029785
load block tensor time/epoch 0.02631855010986328
block to device time/epoch 0.0008001327514648438
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 3 |
Number of nodes for computation during this epoch:  2191
Number of first layer input nodes during this epoch:  1551
Number of first layer output nodes during this epoch:  640
----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006413459777832031
global_2_local spend time (sec) 0.00015115737915039062
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003044605255126953
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 490, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 10: 3, 8: 3, 25: 2, 12: 2, 21: 1, 11: 1, 19: 1})

A = g.adjacency_matrix() spent  0.00015115737915039062
auxiliary_graph
Graph(num_nodes=630, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.00048613548278808594
remove nodes length  490

auxiliary_graph.remove_nodes spent  0.0008320808410644531
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007634162902832031

the counter of shared neighbor distribution
Counter({1.0: 250, 2.0: 30, 3.0: 12, 4.0: 2})
294
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0012869834899902344
70
70
total k batches seeds list generation spend  0.005866050720214844
after graph partition
graph partition algorithm spend time 0.04414534568786621
70
70
partition_len_list
[325, 311]
REG selection method  spend 0.04445981979370117
time for parepare:  6.961822509765625e-05
local_output_nid generation:  8.58306884765625e-06
local_in_edges_tensor generation:  0.000141143798828125
mini_batch_src_global generation:  3.1948089599609375e-05
r_  generation:  0.00013184547424316406
local_output_nid generation:  8.58306884765625e-06
local_in_edges_tensor generation:  0.00013589859008789062
mini_batch_src_global generation:  3.0279159545898438e-05
r_  generation:  0.00013685226440429688
----------------------check_connections_block total spend ----------------------------- 0.0008740425109863281
generate_one_block  0.0016527175903320312
generate_one_block  0.0014553070068359375
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005738735198974609
gen group dst list time:  3.4809112548828125e-05
time for parepare:  0.0001659393310546875
local_output_nid generation:  3.4332275390625e-05
local_in_edges_tensor generation:  0.0002448558807373047
mini_batch_src_global generation:  6.961822509765625e-05
r_  generation:  0.0006966590881347656
local_output_nid generation:  3.1948089599609375e-05
local_in_edges_tensor generation:  0.0001933574676513672
mini_batch_src_global generation:  8.0108642578125e-05
r_  generation:  0.0006308555603027344
----------------------check_connections_block total spend ----------------------------- 0.0025420188903808594
generate_one_block  0.002089977264404297
generate_one_block  0.0019807815551757812
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

connection checking time:  0.0034160614013671875
block generation total time  0.007178783416748047
average batch blocks generation time:  0.0017946958541870117
block dataloader generation time/epoch 0.06712260246276855
pseudo mini batch 0 input nodes size: 826
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27794599533081055  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27794694900512695  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2739582061767578  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2739734649658203  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2739734649658203  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 826
first layer output nodes number: 325
edges number: 1573
torch.Size([826, 1433])
torch.Size([325, 256])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.41468048095703125  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.41468334197998047  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2740049362182617  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

pseudo mini batch 1 input nodes size: 687
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2739591598510742  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2739591598510742  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27794694900512695  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27794790267944336  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353715896606445  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 687
first layer output nodes number: 311
edges number: 1379
torch.Size([687, 1433])
torch.Size([311, 256])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.3962240219116211  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.3962264060974121  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.014131665229797363 |0.00034928321838378906 |0.03612387180328369 |0.000118255615234375 |0.036934852600097656 |0.0039255619049072266 |
----------------------------------------------------------pseudo_mini_loss sum 7.326116561889648
Total (block generation + training)time/epoch 0.4439864635467529
Training time/epoch 0.2076425552368164
Training time without block to device /epoch 0.20694398880004883
Training time without total dataloading part /epoch 0.15027952194213867
load block tensor time/epoch 0.028263330459594727
block to device time/epoch 0.0006985664367675781
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 4 |
Number of nodes for computation during this epoch:  2149
Number of first layer input nodes during this epoch:  1513
Number of first layer output nodes during this epoch:  636
----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735772132873535  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006182193756103516
global_2_local spend time (sec) 0.0001475811004638672
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003027915954589844
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 491, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 10: 3, 8: 3, 12: 2, 25: 2, 19: 1, 11: 1, 21: 1})

A = g.adjacency_matrix() spent  0.0001513957977294922
auxiliary_graph
Graph(num_nodes=631, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0004596710205078125
remove nodes length  491

auxiliary_graph.remove_nodes spent  0.0007243156433105469
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0006575584411621094

the counter of shared neighbor distribution
Counter({1.0: 248, 2.0: 30, 3.0: 14, 4.0: 2})
294
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0012238025665283203
70
70
total k batches seeds list generation spend  0.0054166316986083984
after graph partition
graph partition algorithm spend time 0.06828880310058594
70
70
partition_len_list
[328, 303]
REG selection method  spend 0.06867599487304688
time for parepare:  0.0001246929168701172
local_output_nid generation:  1.430511474609375e-05
local_in_edges_tensor generation:  0.0002491474151611328
mini_batch_src_global generation:  5.936622619628906e-05
r_  generation:  0.00020813941955566406
local_output_nid generation:  9.5367431640625e-06
local_in_edges_tensor generation:  0.00015974044799804688
mini_batch_src_global generation:  3.695487976074219e-05
r_  generation:  0.00015926361083984375
----------------------check_connections_block total spend ----------------------------- 0.0012865066528320312
generate_one_block  0.0018587112426757812
generate_one_block  0.0016183853149414062
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0006906986236572266
gen group dst list time:  3.933906555175781e-05
time for parepare:  0.00016951560974121094
local_output_nid generation:  4.100799560546875e-05
local_in_edges_tensor generation:  0.0002770423889160156
mini_batch_src_global generation:  8.440017700195312e-05
r_  generation:  0.0008215904235839844
local_output_nid generation:  3.552436828613281e-05
local_in_edges_tensor generation:  0.0002086162567138672
mini_batch_src_global generation:  9.846687316894531e-05
r_  generation:  0.0007524490356445312
----------------------check_connections_block total spend ----------------------------- 0.0029540061950683594
generate_one_block  0.0022568702697753906
generate_one_block  0.0015954971313476562
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735772132873535  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

connection checking time:  0.004240512847900391
block generation total time  0.007329463958740234
average batch blocks generation time:  0.0018323659896850586
block dataloader generation time/epoch 0.07024733225504558
pseudo mini batch 0 input nodes size: 836
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353620529174805  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2779994010925293  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2780003547668457  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27401161193847656  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27402687072753906  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27402687072753906  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 836
first layer output nodes number: 328
edges number: 1577
torch.Size([836, 1433])
torch.Size([328, 256])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.41659021377563477  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.416593074798584  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27405881881713867  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

pseudo mini batch 1 input nodes size: 672
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27401256561279297  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27401256561279297  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2780003547668457  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2780013084411621  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27353715896606445  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.27355051040649414  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

first layer input nodes number: 672
first layer output nodes number: 303
edges number: 1352
torch.Size([672, 1433])
torch.Size([303, 256])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.39499568939208984  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.39499807357788086  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.7635498046875 GB
    Memory Allocated: 0.2735776901245117  GigaBytes
Max Memory Allocated: 0.5362339019775391  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.012828707695007324 |0.0003050565719604492 |0.03970503807067871 |0.00011181831359863281 |0.03927624225616455 |0.0039055347442626953 |
----------------------------------------------------------pseudo_mini_loss sum 7.209804534912109
Total (block generation + training)time/epoch 0.4204219579696655
Training time/epoch 0.21658849716186523
Training time without block to device /epoch 0.21597838401794434
Training time without total dataloading part /epoch 0.16209173202514648
load block tensor time/epoch 0.02565741539001465
block to device time/epoch 0.0006101131439208984
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 5 |
Number of nodes for computation during this epoch:  2139
Number of first layer input nodes during this epoch:  1508
Number of first layer output nodes during this epoch:  631
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(1433, 1433, batch_first=True)
      (fc_self): Linear(in_features=1433, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=1433, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (lstm): LSTM(256, 256, batch_first=True)
      (fc_self): Linear(in_features=256, out_features=7, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=7, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  17702992
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([5732, 1433])
layers.0.lstm.weight_hh_l0, torch.Size([5732, 1433])
layers.0.lstm.bias_ih_l0, torch.Size([5732])
layers.0.lstm.bias_hh_l0, torch.Size([5732])
layers.0.fc_self.weight, torch.Size([256, 1433])
layers.0.fc_neigh.weight, torch.Size([256, 1433])
layers.1.lstm.weight_ih_l0, torch.Size([1024, 256])
layers.1.lstm.weight_hh_l0, torch.Size([1024, 256])
layers.1.lstm.bias_ih_l0, torch.Size([1024])
layers.1.lstm.bias_hh_l0, torch.Size([1024])
layers.1.fc_self.weight, torch.Size([7, 256])
layers.1.fc_neigh.weight, torch.Size([7, 256])
----------------------------------------
un-trainable parameters
