main start at this time 1658188977.6057415
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00112152099609375  GigaBytes
Max Memory Allocated: 0.00112152099609375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00112152099609375  GigaBytes
Max Memory Allocated: 0.00112152099609375  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.09749960899353027
global_2_local spend time (sec) 0.36459970474243164
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.017429113388061523
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 809158, 15: 189452, 14: 695, 7: 655, 10: 640, 11: 624, 13: 615, 12: 583, 9: 576, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.05089426040649414
auxiliary_graph
Graph(num_nodes=1005729, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.5842597484588623
remove nodes length  809158

auxiliary_graph.remove_nodes spent  1.2943370342254639
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.9483242034912109

the counter of shared neighbor distribution
Counter({1.0: 19991684, 2.0: 1794372, 3.0: 401822, 4.0: 133762, 5.0: 53900, 6.0: 23014, 7.0: 13780, 8.0: 6972, 9.0: 5604, 10.0: 3978, 14.0: 3312, 12.0: 3152, 15.0: 3114, 11.0: 2724, 13.0: 2078})
22443268
Convert a graph into a bidirected graph: 1.183 seconds
Metis partitioning: 5.036 seconds
Split the graph: 2.574 seconds
Construct subgraphs: 0.031 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  8.834783554077148
99297
97274
total k batches seeds list generation spend  16.447052717208862
after graph partition
graph partition algorithm spend time 16.942103385925293
99297
97274
partition_len_list
[516761, 537341]
REG selection method  spend 17.52807593345642
time for parepare:  0.22061395645141602
local_output_nid generation:  0.012963056564331055
local_in_edges_tensor generation:  0.016550540924072266
mini_batch_src_global generation:  0.048543691635131836
r_  generation:  0.6911971569061279
local_output_nid generation:  0.015727758407592773
local_in_edges_tensor generation:  0.03227591514587402
mini_batch_src_global generation:  0.06051993370056152
r_  generation:  0.7715904712677002
----------------------check_connections_block total spend ----------------------------- 2.1769635677337646
generate_one_block  2.340780735015869
generate_one_block  0.8661458492279053
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.5495469570159912
gen group dst list time:  0.029610395431518555
time for parepare:  0.40003108978271484
local_output_nid generation:  0.08642029762268066
local_in_edges_tensor generation:  0.21931719779968262
mini_batch_src_global generation:  0.16101789474487305
r_  generation:  2.6172029972076416
local_output_nid generation:  0.1393895149230957
local_in_edges_tensor generation:  0.19262194633483887
mini_batch_src_global generation:  0.2101423740386963
r_  generation:  2.8754429817199707
----------------------check_connections_block total spend ----------------------------- 7.871609210968018
generate_one_block  3.616366147994995
generate_one_block  3.678753614425659
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00112152099609375  GigaBytes
Max Memory Allocated: 0.00112152099609375  GigaBytes

connection checking time:  10.048572778701782
block generation total time  10.502046346664429
average batch blocks generation time:  2.625511586666107
block dataloader generation time/epoch 39.6289279460907
pseudo mini batch 0 input nodes size: 1016987
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00112152099609375  GigaBytes
Max Memory Allocated: 0.00112152099609375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00112152099609375  GigaBytes
Max Memory Allocated: 0.00112152099609375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.38002777099609375  GigaBytes
Max Memory Allocated: 0.38002777099609375  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.380767822265625  GigaBytes
Max Memory Allocated: 0.380767822265625  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.380767822265625  GigaBytes
Max Memory Allocated: 0.380767822265625  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.430755615234375  GigaBytes
Max Memory Allocated: 0.430755615234375  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.430755615234375  GigaBytes
Max Memory Allocated: 0.430755615234375  GigaBytes

first layer input nodes number: 1016987
first layer output nodes number: 516761
edges number: 5014888
----------------------------------------before model layer 0
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.4421834945678711  GigaBytes
Max Memory Allocated: 0.4617147445678711  GigaBytes

torch.Size([1016987, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.4421834945678711  GigaBytes
Max Memory Allocated: 0.4617147445678711  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.4451904296875 GB
    Memory Allocated: 2.647817611694336  GigaBytes
Max Memory Allocated: 2.647817611694336  GigaBytes

h_neigh size torch.Size([516761, 1024])
torch.Size([516761, 1024])
torch.Size([516761, 1024])
----------------------------------------after rst
 Nvidia-smi: 8.3905029296875 GB
    Memory Allocated: 4.619104385375977  GigaBytes
Max Memory Allocated: 6.590391159057617  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 8.3905029296875 GB
    Memory Allocated: 2.647817611694336  GigaBytes
Max Memory Allocated: 6.590391159057617  GigaBytes

torch.Size([516761, 1024])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 8.3905029296875 GB
    Memory Allocated: 4.619104385375977  GigaBytes
Max Memory Allocated: 6.590391159057617  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 8.8846435546875 GB
    Memory Allocated: 5.111926078796387  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

----------------input nodes number: 516761
----------------output nodes number: 99297
----------------edges number: 1466321
----------------------------------------before mean aggregator
 Nvidia-smi: 8.8865966796875 GB
    Memory Allocated: 5.116516590118408  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 9.0740966796875 GB
    Memory Allocated: 5.524355888366699  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

h_neigh size torch.Size([99297, 47])
torch.Size([99297, 47])
torch.Size([99297, 47])
----------------------------------------after rst
 Nvidia-smi: 9.0740966796875 GB
    Memory Allocated: 5.541741847991943  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 9.0740966796875 GB
    Memory Allocated: 5.524355888366699  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

torch.Size([99297, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 9.0740966796875 GB
    Memory Allocated: 5.541741847991943  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 9.0740966796875 GB
    Memory Allocated: 5.559128761291504  GigaBytes
Max Memory Allocated: 7.083212852478027  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.5304164886474609  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

pseudo mini batch 1 input nodes size: 1064152
----------------------------------------before load block subtensor 
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.3992762565612793  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.3992762565612793  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.7957038879394531  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.7964286804199219  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.4167823791503906  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.46686649322509766  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.46686649322509766  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

first layer input nodes number: 1064152
first layer output nodes number: 537341
edges number: 5285728
----------------------------------------before model layer 0
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.47908592224121094  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

torch.Size([1064152, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 13.0369873046875 GB
    Memory Allocated: 0.47908592224121094  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 15.0877685546875 GB
    Memory Allocated: 2.7704381942749023  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

h_neigh size torch.Size([537341, 1024])
torch.Size([537341, 1024])
torch.Size([537341, 1024])
----------------------------------------after rst
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 4.8202314376831055  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 2.7704381942749023  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

torch.Size([537341, 1024])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 4.8202314376831055  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.332679748535156  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------input nodes number: 537341
----------------output nodes number: 97274
----------------edges number: 1436395
----------------------------------------before mean aggregator
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.3380866050720215  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.737616062164307  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

h_neigh size torch.Size([97274, 47])
torch.Size([97274, 47])
torch.Size([97274, 47])
----------------------------------------after rst
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.754647731781006  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.737616062164307  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

torch.Size([97274, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.737261772155762  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 19.1893310546875 GB
    Memory Allocated: 5.754648208618164  GigaBytes
Max Memory Allocated: 9.100981712341309  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 21.3182373046875 GB
    Memory Allocated: 0.550513744354248  GigaBytes
Max Memory Allocated: 9.462310791015625  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 21.3201904296875 GB
    Memory Allocated: 0.5527567863464355  GigaBytes
Max Memory Allocated: 9.462310791015625  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 21.3201904296875 GB
    Memory Allocated: 0.5527567863464355  GigaBytes
Max Memory Allocated: 9.462310791015625  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.1698242425918579 |0.21222460269927979 |0.4458569288253784 |0.00020587444305419922 |0.04755687713623047 |0.0041217803955078125 |
----------------------------------------------------------pseudo_mini_loss sum 4.957395553588867
Total (block generation + training)time/epoch 41.47433280944824
Training time/epoch 1.8450965881347656
Training time without block to device /epoch 1.420647382736206
Training time without total dataloading part /epoch 0.991361141204834
load block tensor time/epoch 0.3396484851837158
block to device time/epoch 0.42444920539855957
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  3135241
Number of first layer input nodes during this epoch:  2081139
Number of first layer output nodes during this epoch:  1054102
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=1024, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=1024, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=1024, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=1024, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  301056
trainable parameters
layers.0.fc_self.weight, torch.Size([1024, 100])
layers.0.fc_neigh.weight, torch.Size([1024, 100])
layers.1.fc_self.weight, torch.Size([47, 1024])
layers.1.fc_neigh.weight, torch.Size([47, 1024])
----------------------------------------
un-trainable parameters
