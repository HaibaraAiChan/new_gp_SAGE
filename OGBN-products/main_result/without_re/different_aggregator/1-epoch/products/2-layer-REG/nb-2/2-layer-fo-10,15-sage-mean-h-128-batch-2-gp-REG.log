main start at this time 1658188847.2895555
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00014019012451171875  GigaBytes
Max Memory Allocated: 0.00014019012451171875  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00014019012451171875  GigaBytes
Max Memory Allocated: 0.00014019012451171875  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.08571028709411621
global_2_local spend time (sec) 0.31826114654541016
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.016152143478393555
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 809158, 15: 189452, 14: 695, 7: 655, 10: 640, 11: 624, 13: 615, 12: 583, 9: 576, 6: 550, 8: 512, 4: 456, 5: 445, 3: 374, 2: 221, 1: 173})

A = g.adjacency_matrix() spent  0.04956793785095215
auxiliary_graph
Graph(num_nodes=1005729, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.4789285659790039
remove nodes length  809158

auxiliary_graph.remove_nodes spent  1.2611782550811768
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=22639839,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.9249007701873779

the counter of shared neighbor distribution
Counter({1.0: 19991684, 2.0: 1794372, 3.0: 401822, 4.0: 133762, 5.0: 53900, 6.0: 23014, 7.0: 13780, 8.0: 6972, 9.0: 5604, 10.0: 3978, 14.0: 3312, 12.0: 3152, 15.0: 3114, 11.0: 2724, 13.0: 2078})
22443268
Convert a graph into a bidirected graph: 1.166 seconds
Metis partitioning: 4.967 seconds
Split the graph: 2.431 seconds
Construct subgraphs: 0.052 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  8.626092672348022
99297
97274
total k batches seeds list generation spend  15.867119073867798
after graph partition
graph partition algorithm spend time 16.33088755607605
99297
97274
partition_len_list
[516761, 537341]
REG selection method  spend 16.875500202178955
time for parepare:  0.20925688743591309
local_output_nid generation:  0.013476848602294922
local_in_edges_tensor generation:  0.023865222930908203
mini_batch_src_global generation:  0.04593682289123535
r_  generation:  0.7212808132171631
local_output_nid generation:  0.017988920211791992
local_in_edges_tensor generation:  0.031057119369506836
mini_batch_src_global generation:  0.05727338790893555
r_  generation:  0.7061805725097656
----------------------check_connections_block total spend ----------------------------- 2.1250483989715576
generate_one_block  2.3276383876800537
generate_one_block  0.876929759979248
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.7038609981536865
gen group dst list time:  0.028883695602416992
time for parepare:  0.3879992961883545
local_output_nid generation:  0.08141565322875977
local_in_edges_tensor generation:  0.18392252922058105
mini_batch_src_global generation:  0.16035699844360352
r_  generation:  2.5613327026367188
local_output_nid generation:  0.11977958679199219
local_in_edges_tensor generation:  0.23696660995483398
mini_batch_src_global generation:  0.20936059951782227
r_  generation:  2.8991634845733643
----------------------check_connections_block total spend ----------------------------- 7.847025632858276
generate_one_block  3.6660351753234863
generate_one_block  3.850999593734741
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00014019012451171875  GigaBytes
Max Memory Allocated: 0.00014019012451171875  GigaBytes

connection checking time:  9.972074031829834
block generation total time  10.72160291671753
average batch blocks generation time:  2.6804007291793823
block dataloader generation time/epoch 39.2986900806427
pseudo mini batch 0 input nodes size: 1016987
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00014019012451171875  GigaBytes
Max Memory Allocated: 0.00014019012451171875  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.00014019012451171875  GigaBytes
Max Memory Allocated: 0.00014019012451171875  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.3790464401245117  GigaBytes
Max Memory Allocated: 0.3790464401245117  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.37978649139404297  GigaBytes
Max Memory Allocated: 0.37978649139404297  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3963623046875 GB
    Memory Allocated: 0.37978649139404297  GigaBytes
Max Memory Allocated: 0.37978649139404297  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.42977428436279297  GigaBytes
Max Memory Allocated: 0.42977428436279297  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.42977428436279297  GigaBytes
Max Memory Allocated: 0.42977428436279297  GigaBytes

first layer input nodes number: 1016987
first layer output nodes number: 516761
edges number: 5014888
----------------------------------------before model layer 0
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.44120216369628906  GigaBytes
Max Memory Allocated: 0.46073341369628906  GigaBytes

torch.Size([1016987, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.44120216369628906  GigaBytes
Max Memory Allocated: 0.46073341369628906  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 2.7205810546875 GB
    Memory Allocated: 0.9219603538513184  GigaBytes
Max Memory Allocated: 0.9219603538513184  GigaBytes

h_neigh size torch.Size([516761, 128])
torch.Size([516761, 128])
torch.Size([516761, 128])
----------------------------------------after rst
 Nvidia-smi: 3.2166748046875 GB
    Memory Allocated: 1.1683712005615234  GigaBytes
Max Memory Allocated: 1.4147820472717285  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.2166748046875 GB
    Memory Allocated: 0.9219603538513184  GigaBytes
Max Memory Allocated: 1.4147820472717285  GigaBytes

torch.Size([516761, 128])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.2166748046875 GB
    Memory Allocated: 1.1683712005615234  GigaBytes
Max Memory Allocated: 1.4147820472717285  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.2166748046875 GB
    Memory Allocated: 1.2299742698669434  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

----------------input nodes number: 516761
----------------output nodes number: 99297
----------------edges number: 1466321
----------------------------------------before mean aggregator
 Nvidia-smi: 3.2166748046875 GB
    Memory Allocated: 1.2345647811889648  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.2186279296875 GB
    Memory Allocated: 1.310964584350586  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

h_neigh size torch.Size([99297, 47])
torch.Size([99297, 47])
torch.Size([99297, 47])
----------------------------------------after rst
 Nvidia-smi: 3.2186279296875 GB
    Memory Allocated: 1.32835054397583  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 3.2186279296875 GB
    Memory Allocated: 1.310964584350586  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

torch.Size([99297, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.2186279296875 GB
    Memory Allocated: 1.32835054397583  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 3.2186279296875 GB
    Memory Allocated: 1.3457374572753906  GigaBytes
Max Memory Allocated: 1.4763851165771484  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 3.7322998046875 GB
    Memory Allocated: 0.5284538269042969  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

pseudo mini batch 1 input nodes size: 1064152
----------------------------------------before load block subtensor 
 Nvidia-smi: 3.7322998046875 GB
    Memory Allocated: 0.39731359481811523  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 3.7322998046875 GB
    Memory Allocated: 0.39731359481811523  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.7937979698181152  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.794522762298584  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.41487646102905273  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.46496057510375977  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.46496057510375977  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

first layer input nodes number: 1064152
first layer output nodes number: 537341
edges number: 5285728
----------------------------------------before model layer 0
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.47718000411987305  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

torch.Size([1064152, 100])
----------------------------------------before mean aggregator
 Nvidia-smi: 4.1287841796875 GB
    Memory Allocated: 0.47718000411987305  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.1365966796875 GB
    Memory Allocated: 0.9749631881713867  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

h_neigh size torch.Size([537341, 128])
torch.Size([537341, 128])
torch.Size([537341, 128])
----------------------------------------after rst
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.231187343597412  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 0.9749631881713867  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

torch.Size([537341, 128])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.231187343597412  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.295243740081787  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------input nodes number: 537341
----------------output nodes number: 97274
----------------edges number: 1436395
----------------------------------------before mean aggregator
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.3006505966186523  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.375493049621582  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

h_neigh size torch.Size([97274, 47])
torch.Size([97274, 47])
torch.Size([97274, 47])
----------------------------------------after rst
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.3925247192382812  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.375493049621582  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

torch.Size([97274, 47])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.375138759613037  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 4.6522216796875 GB
    Memory Allocated: 1.3925251960754395  GigaBytes
Max Memory Allocated: 1.7689642906188965  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 4.9197998046875 GB
    Memory Allocated: 0.5486230850219727  GigaBytes
Max Memory Allocated: 1.837751865386963  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 4.9197998046875 GB
    Memory Allocated: 0.5489034652709961  GigaBytes
Max Memory Allocated: 1.837751865386963  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 4.9197998046875 GB
    Memory Allocated: 0.5489034652709961  GigaBytes
Max Memory Allocated: 1.837751865386963  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.16846227645874023 |0.21265602111816406 |0.4008059501647949 |0.000225067138671875 |0.012648344039916992 |0.0027251243591308594 |
----------------------------------------------------------pseudo_mini_loss sum 6.190797328948975
Total (block generation + training)time/epoch 40.90450692176819
Training time/epoch 1.605503797531128
Training time without block to device /epoch 1.1801917552947998
Training time without total dataloading part /epoch 0.8300838470458984
load block tensor time/epoch 0.33692455291748047
block to device time/epoch 0.4253120422363281
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  3135241
Number of first layer input nodes during this epoch:  2081139
Number of first layer output nodes during this epoch:  1054102
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=128, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=128, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=128, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=128, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  37632
trainable parameters
layers.0.fc_self.weight, torch.Size([128, 100])
layers.0.fc_neigh.weight, torch.Size([128, 100])
layers.1.fc_self.weight, torch.Size([47, 128])
layers.1.fc_neigh.weight, torch.Size([47, 128])
----------------------------------------
un-trainable parameters
