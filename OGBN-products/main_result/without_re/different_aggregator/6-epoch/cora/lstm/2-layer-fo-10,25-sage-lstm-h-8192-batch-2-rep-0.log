main start at this time 1656400853.0279233
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  1433
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 3.1697998046875 GB
    Memory Allocated: 2.1506776809692383  GigaBytes
Max Memory Allocated: 2.1506776809692383  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 3.1697998046875 GB
    Memory Allocated: 2.1506776809692383  GigaBytes
Max Memory Allocated: 2.1506776809692383  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0013303756713867188
global_2_local spend time (sec) 0.00010895729064941406
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0005793571472167969
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 488, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 8: 3, 10: 3, 12: 2, 25: 2, 19: 1, 11: 1, 21: 1})

A = g.adjacency_matrix() spent  0.0009198188781738281
auxiliary_graph
Graph(num_nodes=628, num_edges=436,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0006606578826904297
remove nodes length  488

auxiliary_graph.remove_nodes spent  0.001734018325805664
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=436,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0009100437164306641

the counter of shared neighbor distribution
Counter({1.0: 250, 2.0: 30, 3.0: 14, 4.0: 2})
296
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.001 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.001 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.003138303756713867
69
71
total k batches seeds list generation spend  0.012959003448486328
after graph partition
graph partition algorithm spend time 0.09645748138427734
69
71
partition_len_list
[307, 327]
REG selection method  spend 0.09674811363220215
time for parepare:  5.745887756347656e-05
local_output_nid generation:  9.5367431640625e-06
local_in_edges_tensor generation:  0.00011944770812988281
mini_batch_src_global generation:  4.1961669921875e-05
r_  generation:  0.0001232624053955078
local_output_nid generation:  1.0728836059570312e-05
local_in_edges_tensor generation:  0.00012135505676269531
mini_batch_src_global generation:  3.0279159545898438e-05
r_  generation:  0.0001285076141357422
----------------------check_connections_block total spend ----------------------------- 0.0008068084716796875
generate_one_block  0.002804994583129883
generate_one_block  0.0012538433074951172
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005252361297607422
gen group dst list time:  3.3855438232421875e-05
time for parepare:  0.00015020370483398438
local_output_nid generation:  2.3365020751953125e-05
local_in_edges_tensor generation:  0.00020456314086914062
mini_batch_src_global generation:  5.459785461425781e-05
r_  generation:  0.0005385875701904297
local_output_nid generation:  2.6226043701171875e-05
local_in_edges_tensor generation:  0.00015687942504882812
mini_batch_src_global generation:  6.67572021484375e-05
r_  generation:  0.0005371570587158203
----------------------check_connections_block total spend ----------------------------- 0.002076387405395508
generate_one_block  0.0016880035400390625
generate_one_block  0.0016269683837890625
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 3.1697998046875 GB
    Memory Allocated: 2.1506776809692383  GigaBytes
Max Memory Allocated: 2.1506776809692383  GigaBytes

connection checking time:  0.0028831958770751953
block generation total time  0.007373809814453125
average batch blocks generation time:  0.0018434524536132812
block dataloader generation time/epoch 0.11302471160888672
pseudo mini batch 0 input nodes size: 819
----------------------------------------before load block subtensor 
 Nvidia-smi: 3.1697998046875 GB
    Memory Allocated: 2.1506776809692383  GigaBytes
Max Memory Allocated: 2.1506776809692383  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 3.1697998046875 GB
    Memory Allocated: 2.1506776809692383  GigaBytes
Max Memory Allocated: 2.1506776809692383  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 3.1893310546875 GB
    Memory Allocated: 2.1550498008728027  GigaBytes
Max Memory Allocated: 2.1550498008728027  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 3.1893310546875 GB
    Memory Allocated: 2.155050754547119  GigaBytes
Max Memory Allocated: 2.155050754547119  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 3.1893310546875 GB
    Memory Allocated: 2.155050754547119  GigaBytes
Max Memory Allocated: 2.155050754547119  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 3.2537841796875 GB
    Memory Allocated: 2.1550650596618652  GigaBytes
Max Memory Allocated: 2.1550650596618652  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.2537841796875 GB
    Memory Allocated: 2.1550650596618652  GigaBytes
Max Memory Allocated: 2.1550650596618652  GigaBytes

first layer input nodes number: 819
first layer output nodes number: 307
edges number: 1503
torch.Size([819, 1433])
torch.Size([307, 8192])
torch.Size([69, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 3.6639404296875 GB
    Memory Allocated: 2.448497772216797  GigaBytes
Max Memory Allocated: 2.4620885848999023  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 3.6639404296875 GB
    Memory Allocated: 2.448500633239746  GigaBytes
Max Memory Allocated: 2.4620885848999023  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.304473876953125  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

pseudo mini batch 1 input nodes size: 712
----------------------------------------before load block subtensor 
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.3044304847717285  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.3044304847717285  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.308231830596924  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.30823278427124  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.303859710693359  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.3038740158081055  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.3038740158081055  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

first layer input nodes number: 712
first layer output nodes number: 327
edges number: 1453
torch.Size([712, 1433])
torch.Size([327, 8192])
torch.Size([71, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.613539218902588  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 8.6639404296875 GB
    Memory Allocated: 4.613541603088379  GigaBytes
Max Memory Allocated: 6.439218044281006  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 10.6639404296875 GB
    Memory Allocated: 4.303903102874756  GigaBytes
Max Memory Allocated: 8.602458953857422  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.602656841278076  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.602656841278076  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.416095495223999 |0.17997002601623535 |0.572014331817627 |0.00021708011627197266 |1.1702771186828613 |0.21735811233520508 |
----------------------------------------------------------pseudo_mini_loss sum 1.9474107027053833
Total (block generation + training)time/epoch 5.6501312255859375
Training time/epoch 5.5364930629730225
Training time without block to device /epoch 5.176553010940552
Training time without total dataloading part /epoch 3.7023751735687256
load block tensor time/epoch 0.832190990447998
block to device time/epoch 0.3599400520324707
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  2165
Number of first layer input nodes during this epoch:  1531
Number of first layer output nodes during this epoch:  634
----------------------------------------before generate dataloader block 
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.602656364440918  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0049896240234375
global_2_local spend time (sec) 0.00014019012451171875
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.00034332275390625
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 493, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 8: 3, 10: 3, 25: 2, 12: 2, 11: 1, 21: 1, 19: 1})

A = g.adjacency_matrix() spent  0.00018405914306640625
auxiliary_graph
Graph(num_nodes=633, num_edges=430,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.00046372413635253906
remove nodes length  493

auxiliary_graph.remove_nodes spent  0.0049343109130859375
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=430,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007343292236328125

the counter of shared neighbor distribution
Counter({1.0: 244, 2.0: 30, 3.0: 14, 4.0: 2})
290
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.001 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0017168521881103516
72
68
total k batches seeds list generation spend  0.010490894317626953
after graph partition
graph partition algorithm spend time 0.05048632621765137
72
68
partition_len_list
[342, 298]
REG selection method  spend 0.05080127716064453
time for parepare:  6.508827209472656e-05
local_output_nid generation:  6.9141387939453125e-06
local_in_edges_tensor generation:  0.0001289844512939453
mini_batch_src_global generation:  3.314018249511719e-05
r_  generation:  0.0001354217529296875
local_output_nid generation:  7.867813110351562e-06
local_in_edges_tensor generation:  0.00012421607971191406
mini_batch_src_global generation:  2.86102294921875e-05
r_  generation:  0.0001232624053955078
----------------------check_connections_block total spend ----------------------------- 0.0008273124694824219
generate_one_block  0.004522562026977539
generate_one_block  0.0012662410736083984
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005109310150146484
gen group dst list time:  3.4809112548828125e-05
time for parepare:  0.000141143798828125
local_output_nid generation:  3.24249267578125e-05
local_in_edges_tensor generation:  0.0002167224884033203
mini_batch_src_global generation:  6.866455078125e-05
r_  generation:  0.0005960464477539062
local_output_nid generation:  2.6464462280273438e-05
local_in_edges_tensor generation:  0.00015425682067871094
mini_batch_src_global generation:  7.557868957519531e-05
r_  generation:  0.0005190372467041016
----------------------check_connections_block total spend ----------------------------- 0.0021905899047851562
generate_one_block  0.0017957687377929688
generate_one_block  0.0016632080078125
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.602656364440918  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

connection checking time:  0.003017902374267578
block generation total time  0.009247779846191406
average batch blocks generation time:  0.0023119449615478516
block dataloader generation time/epoch 0.09310317039489746
pseudo mini batch 0 input nodes size: 888
----------------------------------------before load block subtensor 
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.602612495422363  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.602612495422363  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.607353210449219  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.607354164123535  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.603551864624023  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.603567123413086  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.603567123413086  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

first layer input nodes number: 888
first layer output nodes number: 342
edges number: 1625
torch.Size([888, 1433])
torch.Size([342, 8192])
torch.Size([72, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.926591873168945  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 13.6639404296875 GB
    Memory Allocated: 8.926594734191895  GigaBytes
Max Memory Allocated: 11.602656841278076  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.603599071502686  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

pseudo mini batch 1 input nodes size: 654
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.60355281829834  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.60355281829834  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.607044219970703  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.60704517364502  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602303504943848  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602316856384277  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602316856384277  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

first layer input nodes number: 654
first layer output nodes number: 298
edges number: 1342
torch.Size([654, 1433])
torch.Size([298, 8192])
torch.Size([68, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.884601593017578  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.88460397720337  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602344036102295  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602344036102295  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602344036102295  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.3864109516143799 |0.00035262107849121094 |0.3662937879562378 |0.00016057491302490234 |1.3753621578216553 |0.19089245796203613 |
----------------------------------------------------------pseudo_mini_loss sum 45.48917007446289
Total (block generation + training)time/epoch 5.445581555366516
Training time/epoch 5.167680025100708
Training time without block to device /epoch 5.166974782943726
Training time without total dataloading part /epoch 3.674525499343872
load block tensor time/epoch 0.7728219032287598
block to device time/epoch 0.0007052421569824219
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  2182
Number of first layer input nodes during this epoch:  1542
Number of first layer output nodes during this epoch:  640
----------------------------------------before generate dataloader block 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602343559265137  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0010199546813964844
global_2_local spend time (sec) 0.00017404556274414062
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003883838653564453
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 489, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 8: 3, 10: 3, 12: 2, 25: 2, 19: 1, 11: 1, 21: 1})

A = g.adjacency_matrix() spent  0.0001857280731201172
auxiliary_graph
Graph(num_nodes=629, num_edges=432,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0005383491516113281
remove nodes length  489

auxiliary_graph.remove_nodes spent  0.0015895366668701172
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=432,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0008146762847900391

the counter of shared neighbor distribution
Counter({1.0: 248, 2.0: 30, 3.0: 12, 4.0: 2})
292
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0015652179718017578
72
68
total k batches seeds list generation spend  0.007305622100830078
after graph partition
graph partition algorithm spend time 0.05705904960632324
72
68
partition_len_list
[354, 282]
REG selection method  spend 0.05750465393066406
time for parepare:  0.00012683868408203125
local_output_nid generation:  1.621246337890625e-05
local_in_edges_tensor generation:  0.00025010108947753906
mini_batch_src_global generation:  6.4849853515625e-05
r_  generation:  0.00027632713317871094
local_output_nid generation:  1.6689300537109375e-05
local_in_edges_tensor generation:  0.0002448558807373047
mini_batch_src_global generation:  5.984306335449219e-05
r_  generation:  0.00023603439331054688
----------------------check_connections_block total spend ----------------------------- 0.0016293525695800781
generate_one_block  0.005851268768310547
generate_one_block  0.0018472671508789062
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0007753372192382812
gen group dst list time:  5.245208740234375e-05
time for parepare:  0.0003211498260498047
local_output_nid generation:  5.078315734863281e-05
local_in_edges_tensor generation:  0.00033092498779296875
mini_batch_src_global generation:  0.00012922286987304688
r_  generation:  0.0009980201721191406
local_output_nid generation:  3.933906555175781e-05
local_in_edges_tensor generation:  0.0002396106719970703
mini_batch_src_global generation:  0.00011372566223144531
r_  generation:  0.000823974609375
----------------------check_connections_block total spend ----------------------------- 0.003596782684326172
generate_one_block  0.002346038818359375
generate_one_block  0.0023276805877685547
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602343559265137  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

connection checking time:  0.00522613525390625
block generation total time  0.012372255325317383
average batch blocks generation time:  0.0030930638313293457
block dataloader generation time/epoch 0.08944066365559895
pseudo mini batch 0 input nodes size: 871
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602302551269531  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.602302551269531  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.606952667236328  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.606953620910645  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.603461265563965  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.603477478027344  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6639404296875 GB
    Memory Allocated: 8.603477478027344  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

first layer input nodes number: 871
first layer output nodes number: 354
edges number: 1667
torch.Size([871, 1433])
torch.Size([354, 8192])
torch.Size([72, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.939451694488525  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.939454555511475  GigaBytes
Max Memory Allocated: 12.915725708007812  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.60351037979126  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

pseudo mini batch 1 input nodes size: 644
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.606900215148926  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.606901168823242  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602250099182129  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602263450622559  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602263450622559  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 644
first layer output nodes number: 282
edges number: 1287
torch.Size([644, 1433])
torch.Size([282, 8192])
torch.Size([68, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.868253707885742  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.868256092071533  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602290630340576  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602290630340576  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602290630340576  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.41114139556884766 |0.000536799430847168 |0.35394299030303955 |0.00016701221466064453 |1.290480375289917 |0.16331243515014648 |
----------------------------------------------------------pseudo_mini_loss sum 29.00403594970703
Total (block generation + training)time/epoch 5.323334455490112
Training time/epoch 4.996262073516846
Training time without block to device /epoch 4.995188474655151
Training time without total dataloading part /epoch 3.452493190765381
load block tensor time/epoch 0.8222827911376953
block to device time/epoch 0.001073598861694336
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 2 |
Number of nodes for computation during this epoch:  2151
Number of first layer input nodes during this epoch:  1515
Number of first layer output nodes during this epoch:  636
----------------------------------------before generate dataloader block 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602290153503418  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0009295940399169922
global_2_local spend time (sec) 0.00015163421630859375
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003192424774169922
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 489, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 8: 3, 10: 3, 25: 2, 12: 2, 21: 1, 11: 1, 19: 1})

A = g.adjacency_matrix() spent  0.00017380714416503906
auxiliary_graph
Graph(num_nodes=629, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0004532337188720703
remove nodes length  489

auxiliary_graph.remove_nodes spent  0.00122833251953125
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007102489471435547

the counter of shared neighbor distribution
Counter({1.0: 248, 2.0: 30, 3.0: 14, 4.0: 2})
294
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.001653909683227539
70
70
total k batches seeds list generation spend  0.00667262077331543
after graph partition
graph partition algorithm spend time 0.026099443435668945
70
70
partition_len_list
[332, 308]
REG selection method  spend 0.02648615837097168
time for parepare:  9.369850158691406e-05
local_output_nid generation:  1.2636184692382812e-05
local_in_edges_tensor generation:  0.0001914501190185547
mini_batch_src_global generation:  7.128715515136719e-05
r_  generation:  0.00019669532775878906
local_output_nid generation:  1.5497207641601562e-05
local_in_edges_tensor generation:  0.0001823902130126953
mini_batch_src_global generation:  4.458427429199219e-05
r_  generation:  0.00019240379333496094
----------------------check_connections_block total spend ----------------------------- 0.0012946128845214844
generate_one_block  0.0022940635681152344
generate_one_block  0.0013666152954101562
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005970001220703125
gen group dst list time:  3.3855438232421875e-05
time for parepare:  0.00014328956604003906
local_output_nid generation:  3.8623809814453125e-05
local_in_edges_tensor generation:  0.0002484321594238281
mini_batch_src_global generation:  8.0108642578125e-05
r_  generation:  0.0006339550018310547
local_output_nid generation:  2.765655517578125e-05
local_in_edges_tensor generation:  0.00017333030700683594
mini_batch_src_global generation:  8.392333984375e-05
r_  generation:  0.0005593299865722656
----------------------check_connections_block total spend ----------------------------- 0.002408742904663086
generate_one_block  0.002391338348388672
generate_one_block  0.0017864704132080078
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602290153503418  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

connection checking time:  0.0037033557891845703
block generation total time  0.00783848762512207
average batch blocks generation time:  0.0019596219062805176
block dataloader generation time/epoch 0.07818162441253662
pseudo mini batch 0 input nodes size: 840
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602249145507812  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602249145507812  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.60689926147461  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.606900215148926  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603461265563965  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603476524353027  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603476524353027  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 840
first layer output nodes number: 332
edges number: 1571
torch.Size([840, 1433])
torch.Size([332, 8192])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.91366195678711  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.913664817810059  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603508472442627  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

pseudo mini batch 1 input nodes size: 711
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.607257843017578  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.607258796691895  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602607727050781  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602621078491211  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602621078491211  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 711
first layer output nodes number: 308
edges number: 1407
torch.Size([711, 1433])
torch.Size([308, 8192])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.89581823348999  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.895820617675781  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602648735046387  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602648735046387  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602648735046387  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.3874551057815552 |0.0005296468734741211 |0.316270112991333 |0.00015628337860107422 |1.0806711912155151 |0.16327977180480957 |
----------------------------------------------------------pseudo_mini_loss sum 47.600074768066406
Total (block generation + training)time/epoch 5.114354610443115
Training time/epoch 4.442640542984009
Training time without block to device /epoch 4.4415812492370605
Training time without total dataloading part /epoch 2.957474946975708
load block tensor time/epoch 0.7749102115631104
block to device time/epoch 0.0010592937469482422
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 3 |
Number of nodes for computation during this epoch:  2191
Number of first layer input nodes during this epoch:  1551
Number of first layer output nodes during this epoch:  640
----------------------------------------before generate dataloader block 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602648258209229  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0010528564453125
global_2_local spend time (sec) 0.00017189979553222656
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0004019737243652344
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 490, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 10: 3, 8: 3, 25: 2, 12: 2, 21: 1, 11: 1, 19: 1})

A = g.adjacency_matrix() spent  0.00020647048950195312
auxiliary_graph
Graph(num_nodes=630, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0005552768707275391
remove nodes length  490

auxiliary_graph.remove_nodes spent  0.0013892650604248047
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0008304119110107422

the counter of shared neighbor distribution
Counter({1.0: 250, 2.0: 30, 3.0: 12, 4.0: 2})
294
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0015740394592285156
70
70
total k batches seeds list generation spend  0.0074863433837890625
after graph partition
graph partition algorithm spend time 0.04899740219116211
70
70
partition_len_list
[325, 311]
REG selection method  spend 0.04946255683898926
time for parepare:  7.62939453125e-05
local_output_nid generation:  8.821487426757812e-06
local_in_edges_tensor generation:  0.00021123886108398438
mini_batch_src_global generation:  5.507469177246094e-05
r_  generation:  0.00015687942504882812
local_output_nid generation:  2.3126602172851562e-05
local_in_edges_tensor generation:  0.00014519691467285156
mini_batch_src_global generation:  4.673004150390625e-05
r_  generation:  0.00016927719116210938
----------------------check_connections_block total spend ----------------------------- 0.0011172294616699219
generate_one_block  0.002560138702392578
generate_one_block  0.0015172958374023438
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005958080291748047
gen group dst list time:  4.00543212890625e-05
time for parepare:  0.00024771690368652344
local_output_nid generation:  4.9591064453125e-05
local_in_edges_tensor generation:  0.0002658367156982422
mini_batch_src_global generation:  0.00020647048950195312
r_  generation:  0.0006966590881347656
local_output_nid generation:  3.361701965332031e-05
local_in_edges_tensor generation:  0.00020241737365722656
mini_batch_src_global generation:  0.00015735626220703125
r_  generation:  0.00063323974609375
----------------------check_connections_block total spend ----------------------------- 0.003000974655151367
generate_one_block  0.0021436214447021484
generate_one_block  0.001992464065551758
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602648258209229  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

connection checking time:  0.004118204116821289
block generation total time  0.008213520050048828
average batch blocks generation time:  0.002053380012512207
block dataloader generation time/epoch 0.07643342018127441
pseudo mini batch 0 input nodes size: 826
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602606773376465  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.602606773376465  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.607256889343262  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.607257843017578  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603461265563965  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603476524353027  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6873779296875 GB
    Memory Allocated: 8.603476524353027  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 826
first layer output nodes number: 325
edges number: 1573
torch.Size([826, 1433])
torch.Size([325, 8192])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.913472175598145  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.913475036621094  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603507995605469  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

pseudo mini batch 1 input nodes size: 687
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.60713005065918  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.607131004333496  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602479934692383  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602493286132812  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602493286132812  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 687
first layer output nodes number: 311
edges number: 1379
torch.Size([687, 1433])
torch.Size([311, 8192])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.89329481124878  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.89329719543457  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.60252046585083  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.60252046585083  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.60252046585083  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.41173744201660156 |0.0003838539123535156 |0.29120635986328125 |0.00015091896057128906 |0.9782589673995972 |0.16663289070129395 |
----------------------------------------------------------pseudo_mini_loss sum 57.26018524169922
Total (block generation + training)time/epoch 4.947344160079956
Training time/epoch 4.2097015380859375
Training time without block to device /epoch 4.2089338302612305
Training time without total dataloading part /epoch 2.7058653831481934
load block tensor time/epoch 0.8234748840332031
block to device time/epoch 0.0007677078247070312
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 4 |
Number of nodes for computation during this epoch:  2149
Number of first layer input nodes during this epoch:  1513
Number of first layer output nodes during this epoch:  636
----------------------------------------before generate dataloader block 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602519989013672  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0008187294006347656
global_2_local spend time (sec) 0.0001571178436279297
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003407001495361328
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 491, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 10: 3, 8: 3, 12: 2, 25: 2, 19: 1, 11: 1, 21: 1})

A = g.adjacency_matrix() spent  0.0001876354217529297
auxiliary_graph
Graph(num_nodes=631, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0005168914794921875
remove nodes length  491

auxiliary_graph.remove_nodes spent  0.0008802413940429688
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=434,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007941722869873047

the counter of shared neighbor distribution
Counter({1.0: 248, 2.0: 30, 3.0: 14, 4.0: 2})
294
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0013277530670166016
70
70
total k batches seeds list generation spend  0.006253242492675781
after graph partition
graph partition algorithm spend time 0.05066084861755371
70
70
partition_len_list
[328, 303]
REG selection method  spend 0.05100131034851074
time for parepare:  6.651878356933594e-05
local_output_nid generation:  7.867813110351562e-06
local_in_edges_tensor generation:  0.0001385211944580078
mini_batch_src_global generation:  3.981590270996094e-05
r_  generation:  0.0001533031463623047
local_output_nid generation:  8.58306884765625e-06
local_in_edges_tensor generation:  0.00013756752014160156
mini_batch_src_global generation:  3.337860107421875e-05
r_  generation:  0.00013303756713867188
----------------------check_connections_block total spend ----------------------------- 0.0009090900421142578
generate_one_block  0.0018794536590576172
generate_one_block  0.0014259815216064453
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005784034729003906
gen group dst list time:  3.337860107421875e-05
time for parepare:  0.0001544952392578125
local_output_nid generation:  3.4332275390625e-05
local_in_edges_tensor generation:  0.00029158592224121094
mini_batch_src_global generation:  7.677078247070312e-05
r_  generation:  0.0006804466247558594
local_output_nid generation:  3.147125244140625e-05
local_in_edges_tensor generation:  0.00017952919006347656
mini_batch_src_global generation:  8.106231689453125e-05
r_  generation:  0.0022077560424804688
----------------------check_connections_block total spend ----------------------------- 0.004153251647949219
generate_one_block  0.001959562301635742
generate_one_block  0.0016655921936035156
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602519989013672  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

connection checking time:  0.0050623416900634766
block generation total time  0.00693058967590332
average batch blocks generation time:  0.00173264741897583
block dataloader generation time/epoch 0.0751707951227824
pseudo mini batch 0 input nodes size: 836
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602478981018066  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602478981018066  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.607129096984863  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.60713005065918  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603461265563965  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603476524353027  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603476524353027  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 836
first layer output nodes number: 328
edges number: 1577
torch.Size([836, 1433])
torch.Size([328, 8192])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.920293807983398  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.920296669006348  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603508472442627  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

pseudo mini batch 1 input nodes size: 672
----------------------------------------before load block subtensor 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.603462219238281  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.607049942016602  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.607050895690918  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602399826049805  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602413177490234  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602413177490234  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

first layer input nodes number: 672
first layer output nodes number: 303
edges number: 1352
torch.Size([672, 1433])
torch.Size([303, 8192])
torch.Size([70, 7])
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.884863376617432  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.884865760803223  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602440357208252  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602440357208252  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 14.6893310546875 GB
    Memory Allocated: 8.602440357208252  GigaBytes
Max Memory Allocated: 12.928219318389893  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.41039085388183594 |0.0004476308822631836 |0.35412800312042236 |0.00016379356384277344 |1.299845814704895 |0.18463730812072754 |
----------------------------------------------------------pseudo_mini_loss sum 81.15519714355469
Total (block generation + training)time/epoch 4.966845989227295
Training time/epoch 4.99508261680603
Training time without block to device /epoch 4.994187355041504
Training time without total dataloading part /epoch 3.492912530899048
load block tensor time/epoch 0.8207817077636719
block to device time/epoch 0.0008952617645263672
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 5 |
Number of nodes for computation during this epoch:  2139
Number of first layer input nodes during this epoch:  1508
Number of first layer output nodes during this epoch:  631
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (lstm): LSTM(1433, 1433, batch_first=True)
      (fc_self): Linear(in_features=1433, out_features=8192, bias=False)
      (fc_neigh): Linear(in_features=1433, out_features=8192, bias=False)
    )
    (1): SAGEConv(
      (lstm): LSTM(8192, 8192, batch_first=True)
      (fc_self): Linear(in_features=8192, out_features=7, bias=False)
      (fc_neigh): Linear(in_features=8192, out_features=7, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  576968784
trainable parameters
layers.0.lstm.weight_ih_l0, torch.Size([5732, 1433])
layers.0.lstm.weight_hh_l0, torch.Size([5732, 1433])
layers.0.lstm.bias_ih_l0, torch.Size([5732])
layers.0.lstm.bias_hh_l0, torch.Size([5732])
layers.0.fc_self.weight, torch.Size([8192, 1433])
layers.0.fc_neigh.weight, torch.Size([8192, 1433])
layers.1.lstm.weight_ih_l0, torch.Size([32768, 8192])
layers.1.lstm.weight_hh_l0, torch.Size([32768, 8192])
layers.1.lstm.bias_ih_l0, torch.Size([32768])
layers.1.lstm.bias_hh_l0, torch.Size([32768])
layers.1.fc_self.weight, torch.Size([7, 8192])
layers.1.fc_neigh.weight, torch.Size([7, 8192])
----------------------------------------
un-trainable parameters
