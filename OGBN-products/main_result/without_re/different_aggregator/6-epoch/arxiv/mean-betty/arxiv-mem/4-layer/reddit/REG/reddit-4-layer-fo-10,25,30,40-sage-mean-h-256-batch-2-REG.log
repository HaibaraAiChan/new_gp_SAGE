main start at this time 1657097689.7476847
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
153431
23831
55703
# Nodes: 232965
# Edges: 114615892
# Train: 153431
# Val: 23831
# Test: 55703
# Classes: 41

#nodes: 232965
#edges: 114615892
#classes: 41
----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  602
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.6117208003997803
global_2_local spend time (sec) 0.06014275550842285
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0578763484954834
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({40: 128251, 0: 72233, 1: 1391, 2: 1221, 3: 1053, 4: 986, 5: 920, 6: 875, 7: 814, 8: 799, 11: 702, 9: 695, 13: 691, 10: 690, 12: 684, 14: 652, 15: 643, 16: 607, 19: 606, 17: 598, 18: 563, 21: 562, 22: 556, 23: 543, 20: 538, 28: 532, 27: 528, 25: 525, 26: 521, 24: 521, 32: 520, 29: 511, 30: 509, 31: 480, 33: 467, 37: 465, 38: 459, 34: 458, 36: 447, 35: 444, 39: 404})

A = g.adjacency_matrix() spent  0.08756494522094727
auxiliary_graph
Graph(num_nodes=225664, num_edges=327958581,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.12128615379333496
remove nodes length  72233

auxiliary_graph.remove_nodes spent  19.65048575401306
after remove non output nodes the auxiliary_graph
Graph(num_nodes=153431, num_edges=327958581,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  13.579160451889038

the counter of shared neighbor distribution
Counter({1.0: 289477776, 2.0: 29084900, 3.0: 5471040, 4.0: 1661006, 5.0: 743546, 6.0: 411060, 7.0: 256134, 8.0: 168238, 9.0: 115996, 10.0: 83578, 11.0: 62060, 12.0: 47414, 13.0: 37292, 14.0: 29470, 15.0: 23804, 16.0: 20196, 17.0: 16566, 18.0: 14276, 19.0: 12164, 20.0: 9978, 21.0: 8368, 22.0: 7312, 23.0: 5784, 24.0: 4890, 25.0: 4824, 26.0: 3954, 27.0: 3586, 28.0: 2934, 30.0: 2712, 29.0: 2696, 31.0: 2294, 32.0: 2068, 33.0: 1608, 35.0: 1520, 34.0: 1506, 36.0: 1012, 37.0: 674, 38.0: 532, 39.0: 382})
327805150
Convert a graph into a bidirected graph: 25.322 seconds
Metis partitioning: 74.676 seconds
Split the graph: 35.073 seconds
Construct subgraphs: 0.066 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  135.29265832901
74484
78947
total k batches seeds list generation spend  215.07247376441956
after graph partition
graph partition algorithm spend time 215.79025602340698
74484
78947
partition_len_list
[169292, 153891]
REG selection method  spend 215.9425458908081
time for parepare:  0.029144763946533203
local_output_nid generation:  0.009042024612426758
local_in_edges_tensor generation:  0.04442930221557617
mini_batch_src_global generation:  0.08942985534667969
r_  generation:  0.8459553718566895
local_output_nid generation:  0.011052846908569336
local_in_edges_tensor generation:  0.05251955986022949
mini_batch_src_global generation:  0.10344719886779785
r_  generation:  0.8293483257293701
----------------------check_connections_block total spend ----------------------------- 2.3843727111816406
generate_one_block  1.2524802684783936
generate_one_block  1.3135316371917725
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.7284085750579834
gen group dst list time:  0.010417938232421875
time for parepare:  0.035936594009399414
local_output_nid generation:  0.04999136924743652
local_in_edges_tensor generation:  0.10858321189880371
mini_batch_src_global generation:  0.16592192649841309
r_  generation:  1.6010193824768066
local_output_nid generation:  0.03855562210083008
local_in_edges_tensor generation:  0.09506607055664062
mini_batch_src_global generation:  0.17505884170532227
r_  generation:  1.345872163772583
----------------------check_connections_block total spend ----------------------------- 4.257190942764282
generate_one_block  2.4728751182556152
generate_one_block  1.8628177642822266
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.6760373115539551
gen group dst list time:  0.019272804260253906
time for parepare:  0.04636359214782715
local_output_nid generation:  0.044189453125
local_in_edges_tensor generation:  0.1460576057434082
mini_batch_src_global generation:  0.1676161289215088
r_  generation:  1.7442421913146973
local_output_nid generation:  0.053856849670410156
local_in_edges_tensor generation:  0.12107419967651367
mini_batch_src_global generation:  0.20662879943847656
r_  generation:  1.5999436378479004
----------------------check_connections_block total spend ----------------------------- 4.842942714691162
generate_one_block  2.711832284927368
generate_one_block  2.146928310394287
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.2951052188873291
gen group dst list time:  0.0221250057220459
time for parepare:  0.04386615753173828
local_output_nid generation:  0.040190696716308594
local_in_edges_tensor generation:  0.08165454864501953
mini_batch_src_global generation:  0.07029175758361816
r_  generation:  0.811392068862915
local_output_nid generation:  0.051184892654418945
local_in_edges_tensor generation:  0.07515168190002441
mini_batch_src_global generation:  0.08661866188049316
r_  generation:  0.8453662395477295
----------------------check_connections_block total spend ----------------------------- 2.466920852661133
generate_one_block  1.343416690826416
generate_one_block  1.1141612529754639
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

connection checking time:  13.951427221298218
block generation total time  14.218043327331543
average batch blocks generation time:  1.7772554159164429
block dataloader generation time/epoch 247.80147671699524
pseudo mini batch 0 input nodes size: 226962
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.5291748046875 GB
    Memory Allocated: 0.5119686126708984  GigaBytes
Max Memory Allocated: 0.5119686126708984  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.5291748046875 GB
    Memory Allocated: 0.5125236511230469  GigaBytes
Max Memory Allocated: 0.5125236511230469  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.5291748046875 GB
    Memory Allocated: 0.5125236511230469  GigaBytes
Max Memory Allocated: 0.5125236511230469  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7186279296875 GB
    Memory Allocated: 0.6253957748413086  GigaBytes
Max Memory Allocated: 0.6253957748413086  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7186279296875 GB
    Memory Allocated: 0.6253957748413086  GigaBytes
Max Memory Allocated: 0.6253957748413086  GigaBytes

first layer input nodes number: 226962
first layer output nodes number: 225902
edges number: 2220538
----------------------------------------before model layer 0
 Nvidia-smi: 1.7381591796875 GB
    Memory Allocated: 0.6290264129638672  GigaBytes
Max Memory Allocated: 0.637298583984375  GigaBytes

torch.Size([226962, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.7381591796875 GB
    Memory Allocated: 0.6290264129638672  GigaBytes
Max Memory Allocated: 0.637298583984375  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.5057373046875 GB
    Memory Allocated: 1.3684630393981934  GigaBytes
Max Memory Allocated: 1.6604814529418945  GigaBytes

torch.Size([225902, 256])
torch.Size([225902, 256])
----------------------------------------after rst
 Nvidia-smi: 3.7225341796875 GB
    Memory Allocated: 1.583899974822998  GigaBytes
Max Memory Allocated: 1.7993369102478027  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.7225341796875 GB
    Memory Allocated: 1.3684630393981934  GigaBytes
Max Memory Allocated: 1.7993369102478027  GigaBytes

torch.Size([225902, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.7225341796875 GB
    Memory Allocated: 1.583899974822998  GigaBytes
Max Memory Allocated: 1.7993369102478027  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.7225341796875 GB
    Memory Allocated: 1.6377592086791992  GigaBytes
Max Memory Allocated: 1.853196144104004  GigaBytes

input nodes number: 225902
output nodes number: 219224
edges number: 5279850
----------------------------------------before model layer 1
 Nvidia-smi: 3.7225341796875 GB
    Memory Allocated: 1.6410760879516602  GigaBytes
Max Memory Allocated: 1.853196144104004  GigaBytes

torch.Size([225902, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.7225341796875 GB
    Memory Allocated: 1.6410760879516602  GigaBytes
Max Memory Allocated: 1.853196144104004  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.0584716796875 GB
    Memory Allocated: 2.100184440612793  GigaBytes
Max Memory Allocated: 2.100184440612793  GigaBytes

torch.Size([219224, 256])
torch.Size([219224, 256])
----------------------------------------after rst
 Nvidia-smi: 4.4803466796875 GB
    Memory Allocated: 2.3092527389526367  GigaBytes
Max Memory Allocated: 2.5183210372924805  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 4.4803466796875 GB
    Memory Allocated: 2.100184440612793  GigaBytes
Max Memory Allocated: 2.5183210372924805  GigaBytes

torch.Size([219224, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 4.4803466796875 GB
    Memory Allocated: 2.3092527389526367  GigaBytes
Max Memory Allocated: 2.5183210372924805  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 4.5330810546875 GB
    Memory Allocated: 2.3619871139526367  GigaBytes
Max Memory Allocated: 2.5710554122924805  GigaBytes

input nodes number: 219224
output nodes number: 169292
edges number: 4895540
----------------------------------------before model layer 2
 Nvidia-smi: 4.5330810546875 GB
    Memory Allocated: 2.365096092224121  GigaBytes
Max Memory Allocated: 2.5710554122924805  GigaBytes

torch.Size([219224, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 4.5330810546875 GB
    Memory Allocated: 2.365096092224121  GigaBytes
Max Memory Allocated: 2.5710554122924805  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.6971435546875 GB
    Memory Allocated: 2.7263917922973633  GigaBytes
Max Memory Allocated: 2.7263917922973633  GigaBytes

torch.Size([169292, 256])
torch.Size([169292, 256])
----------------------------------------after rst
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 2.8885011672973633  GigaBytes
Max Memory Allocated: 3.0506105422973633  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 2.7270517349243164  GigaBytes
Max Memory Allocated: 3.0506105422973633  GigaBytes

torch.Size([169292, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 2.8891611099243164  GigaBytes
Max Memory Allocated: 3.0506105422973633  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 2.9295167922973633  GigaBytes
Max Memory Allocated: 3.0916261672973633  GigaBytes

----------------input nodes number: 169292
----------------output nodes number: 74484
----------------edges number: 2753391
----------------------------------------before mean aggregator
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 2.931365489959717  GigaBytes
Max Memory Allocated: 3.0916261672973633  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 3.0348453521728516  GigaBytes
Max Memory Allocated: 3.0945019721984863  GigaBytes

torch.Size([74484, 41])
torch.Size([74484, 41])
----------------------------------------after rst
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 3.04622220993042  GigaBytes
Max Memory Allocated: 3.0945019721984863  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 3.0348453521728516  GigaBytes
Max Memory Allocated: 3.0945019721984863  GigaBytes

torch.Size([74484, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 3.04622220993042  GigaBytes
Max Memory Allocated: 3.0945019721984863  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 5.0213623046875 GB
    Memory Allocated: 3.0576000213623047  GigaBytes
Max Memory Allocated: 3.0945019721984863  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 6.2342529296875 GB
    Memory Allocated: 0.8649377822875977  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

pseudo mini batch 1 input nodes size: 228870
----------------------------------------before load block subtensor 
 Nvidia-smi: 6.2342529296875 GB
    Memory Allocated: 0.5261044502258301  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 6.2342529296875 GB
    Memory Allocated: 0.5261044502258301  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 1.03977632522583  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 1.0403647422790527  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 0.5300440788269043  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 0.6388363838195801  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 0.6388363838195801  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

first layer input nodes number: 228870
first layer output nodes number: 227876
edges number: 2229181
----------------------------------------before model layer 0
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 0.6422505378723145  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([228870, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 6.7479248046875 GB
    Memory Allocated: 0.6422505378723145  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.3903522491455078  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([227876, 256])
torch.Size([227876, 256])
----------------------------------------after rst
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.6076717376708984  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.3903522491455078  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([227876, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.6076717376708984  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.662001609802246  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

input nodes number: 227876
output nodes number: 215658
edges number: 5138451
----------------------------------------before model layer 1
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.6654157638549805  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([227876, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 1.6654157638549805  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.1170315742492676  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([215658, 256])
torch.Size([215658, 256])
----------------------------------------after rst
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.3226990699768066  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.1170315742492676  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([215658, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.3226990699768066  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.3741159439086914  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

input nodes number: 215658
output nodes number: 153891
edges number: 4331454
----------------------------------------before model layer 2
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.377775192260742  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([215658, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.377775192260742  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.704718589782715  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([153891, 256])
torch.Size([153891, 256])
----------------------------------------after rst
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.851480484008789  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.704718589782715  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([153891, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.851480484008789  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.8881711959838867  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------input nodes number: 153891
----------------output nodes number: 78947
----------------edges number: 2798129
----------------------------------------before mean aggregator
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.8901801109313965  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.998964786529541  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([78947, 41])
torch.Size([78947, 41])
----------------------------------------after rst
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 3.0110230445861816  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.998964786529541  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

torch.Size([78947, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 2.9996461868286133  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 7.7752685546875 GB
    Memory Allocated: 3.011704921722412  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 7.7791748046875 GB
    Memory Allocated: 0.8588118553161621  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 7.7830810546875 GB
    Memory Allocated: 0.863217830657959  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 7.7830810546875 GB
    Memory Allocated: 0.863217830657959  GigaBytes
Max Memory Allocated: 3.3096375465393066  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.20246493816375732 |0.26399779319763184 |0.46047914028167725 |0.00023043155670166016 |0.0565488338470459 |0.0058705806732177734 |
----------------------------------------------------------pseudo_mini_loss sum 19.293720245361328
Total (block generation + training)time/epoch 249.8040668964386
Training time/epoch 2.00224232673645
Training time without block to device /epoch 1.4742467403411865
Training time without total dataloading part /epoch 1.0403873920440674
load block tensor time/epoch 0.40492987632751465
block to device time/epoch 0.5279955863952637
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1667675
Number of first layer input nodes during this epoch:  455832
Number of first layer output nodes during this epoch:  453778
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=602, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=602, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=41, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=41, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  591360
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 602])
layers.0.fc_neigh.weight, torch.Size([256, 602])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([41, 256])
layers.3.fc_neigh.weight, torch.Size([41, 256])
----------------------------------------
un-trainable parameters
