main start at this time 1657074027.1571994
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  1433
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00323486328125  GigaBytes
Max Memory Allocated: 0.00323486328125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00323486328125  GigaBytes
Max Memory Allocated: 0.00323486328125  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0011217594146728516
global_2_local spend time (sec) 0.00015687942504882812
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0005507469177246094
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 497, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 10: 3, 8: 3, 12: 2, 30: 2, 19: 1, 21: 1, 11: 1})

A = g.adjacency_matrix() spent  0.00037288665771484375
auxiliary_graph
Graph(num_nodes=637, num_edges=436,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0005469322204589844
remove nodes length  497

auxiliary_graph.remove_nodes spent  0.001844644546508789
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=436,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0008378028869628906

the counter of shared neighbor distribution
Counter({1.0: 250, 2.0: 30, 3.0: 14, 4.0: 2})
296
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.001 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0016906261444091797
72
68
total k batches seeds list generation spend  0.009787797927856445
after graph partition
graph partition algorithm spend time 0.03983497619628906
72
68
partition_len_list
[365, 278]
REG selection method  spend 0.04025149345397949
time for parepare:  9.655952453613281e-05
local_output_nid generation:  7.62939453125e-06
local_in_edges_tensor generation:  0.00013780593872070312
mini_batch_src_global generation:  3.790855407714844e-05
r_  generation:  0.00017786026000976562
local_output_nid generation:  7.62939453125e-06
local_in_edges_tensor generation:  0.00013327598571777344
mini_batch_src_global generation:  3.0040740966796875e-05
r_  generation:  0.0001125335693359375
----------------------check_connections_block total spend ----------------------------- 0.0009846687316894531
generate_one_block  0.0027418136596679688
generate_one_block  0.0013239383697509766
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0005793571472167969
gen group dst list time:  6.246566772460938e-05
time for parepare:  0.00017595291137695312
local_output_nid generation:  3.361701965332031e-05
local_in_edges_tensor generation:  0.0002377033233642578
mini_batch_src_global generation:  0.00010609626770019531
r_  generation:  0.0008084774017333984
local_output_nid generation:  2.6464462280273438e-05
local_in_edges_tensor generation:  0.00017213821411132812
mini_batch_src_global generation:  8.869171142578125e-05
r_  generation:  0.0005896091461181641
----------------------check_connections_block total spend ----------------------------- 0.002668142318725586
generate_one_block  0.0020699501037597656
generate_one_block  0.0016472339630126953
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0005762577056884766
gen group dst list time:  5.054473876953125e-05
time for parepare:  0.0001761913299560547
local_output_nid generation:  6.67572021484375e-05
local_in_edges_tensor generation:  0.0003094673156738281
mini_batch_src_global generation:  0.0001583099365234375
r_  generation:  0.0015213489532470703
local_output_nid generation:  5.91278076171875e-05
local_in_edges_tensor generation:  0.0002143383026123047
mini_batch_src_global generation:  0.00014066696166992188
r_  generation:  0.0012345314025878906
----------------------check_connections_block total spend ----------------------------- 0.004576444625854492
generate_one_block  0.0027899742126464844
generate_one_block  0.0025572776794433594
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00323486328125  GigaBytes
Max Memory Allocated: 0.00323486328125  GigaBytes

connection checking time:  0.008229255676269531
block generation total time  0.01313018798828125
average batch blocks generation time:  0.0021883646647135415
block dataloader generation time/epoch 0.06876015663146973
pseudo mini batch 0 input nodes size: 1632
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00323486328125  GigaBytes
Max Memory Allocated: 0.00323486328125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00323486328125  GigaBytes
Max Memory Allocated: 0.00323486328125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.011947154998779297  GigaBytes
Max Memory Allocated: 0.011947154998779297  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.011948108673095703  GigaBytes
Max Memory Allocated: 0.011948108673095703  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.011948108673095703  GigaBytes
Max Memory Allocated: 0.011948108673095703  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.01199960708618164  GigaBytes
Max Memory Allocated: 0.01199960708618164  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.01199960708618164  GigaBytes
Max Memory Allocated: 0.01199960708618164  GigaBytes

first layer input nodes number: 1632
first layer output nodes number: 977
edges number: 4346
----------------------------------------before model layer 0
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.012019634246826172  GigaBytes
Max Memory Allocated: 0.012035846710205078  GigaBytes

torch.Size([1632, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.012019634246826172  GigaBytes
Max Memory Allocated: 0.012035846710205078  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2869873046875 GB
    Memory Allocated: 0.018203258514404297  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([977, 256])
torch.Size([977, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.019134998321533203  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.018203258514404297  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([977, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.019134998321533203  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.01936817169189453  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

input nodes number: 977
output nodes number: 365
edges number: 2067
----------------------------------------before model layer 1
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.019378662109375  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([977, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.019378662109375  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2889404296875 GB
    Memory Allocated: 0.020093917846679688  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([365, 256])
torch.Size([365, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.02044200897216797  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020093917846679688  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([365, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.02044200897216797  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.02052927017211914  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------input nodes number: 365
----------------output nodes number: 72
----------------edges number: 381
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020533084869384766  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020607471466064453  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([72, 7])
torch.Size([72, 7])
----------------------------------------after rst
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020609378814697266  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020607471466064453  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

torch.Size([72, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020609378814697266  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2908935546875 GB
    Memory Allocated: 0.020612239837646484  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.015353202819824219  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

pseudo mini batch 1 input nodes size: 1504
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.015185832977294922  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.015185832977294922  GigaBytes
Max Memory Allocated: 0.022490978240966797  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.02321481704711914  GigaBytes
Max Memory Allocated: 0.02321481704711914  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.023215770721435547  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.014502525329589844  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.0145416259765625  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.0145416259765625  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

first layer input nodes number: 1504
first layer output nodes number: 794
edges number: 3461
----------------------------------------before model layer 0
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.014559268951416016  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([1504, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.014559268951416016  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.019585609436035156  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([794, 256])
torch.Size([794, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.02034282684326172  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.019585609436035156  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([794, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.02034282684326172  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.02053213119506836  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

input nodes number: 794
output nodes number: 278
edges number: 1404
----------------------------------------before model layer 1
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.020540714263916016  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([794, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.020540714263916016  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021084308624267578  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([278, 256])
torch.Size([278, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021349430084228516  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021084308624267578  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([278, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021349430084228516  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.02141571044921875  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------input nodes number: 278
----------------output nodes number: 68
----------------edges number: 249
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021419048309326172  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021488666534423828  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([68, 7])
torch.Size([68, 7])
----------------------------------------after rst
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.02149057388305664  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021488666534423828  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

torch.Size([68, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021488666534423828  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021491050720214844  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.014632701873779297  GigaBytes
Max Memory Allocated: 0.023215770721435547  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021102428436279297  GigaBytes
Max Memory Allocated: 0.025202274322509766  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.2947998046875 GB
    Memory Allocated: 0.021102428436279297  GigaBytes
Max Memory Allocated: 0.025202274322509766  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0073816776275634766 |0.17486655712127686 |0.3906214237213135 |0.0001971721649169922 |0.004353761672973633 |0.0014736652374267578 |
----------------------------------------------------------pseudo_mini_loss sum 1.950443983078003
Total (block generation + training)time/epoch 1.232694149017334
Training time/epoch 1.1635944843292236
Training time without block to device /epoch 0.8138613700866699
Training time without total dataloading part /epoch 0.791818380355835
load block tensor time/epoch 0.014763355255126953
block to device time/epoch 0.3497331142425537
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  5550
Number of first layer input nodes during this epoch:  3136
Number of first layer output nodes during this epoch:  1771
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=1433, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=1433, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=7, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=7, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  868352
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 1433])
layers.0.fc_neigh.weight, torch.Size([256, 1433])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([7, 256])
layers.2.fc_neigh.weight, torch.Size([7, 256])
----------------------------------------
un-trainable parameters
