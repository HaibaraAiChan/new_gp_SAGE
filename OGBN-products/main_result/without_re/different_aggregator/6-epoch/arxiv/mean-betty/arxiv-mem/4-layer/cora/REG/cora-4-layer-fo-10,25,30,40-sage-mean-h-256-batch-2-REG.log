main start at this time 1657101236.3632143
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  1433
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00372314453125  GigaBytes
Max Memory Allocated: 0.00372314453125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00372314453125  GigaBytes
Max Memory Allocated: 0.00372314453125  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.001207590103149414
global_2_local spend time (sec) 0.000152587890625
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0006809234619140625
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 504, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 7: 4, 9: 4, 8: 3, 10: 3, 12: 2, 11: 1, 21: 1, 19: 1, 36: 1, 32: 1})

A = g.adjacency_matrix() spent  0.00041866302490234375
auxiliary_graph
Graph(num_nodes=644, num_edges=438,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0008087158203125
remove nodes length  504

auxiliary_graph.remove_nodes spent  0.0011706352233886719
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=438,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0009965896606445312

the counter of shared neighbor distribution
Counter({1.0: 252, 2.0: 30, 3.0: 14, 4.0: 2})
298
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0017702579498291016
72
68
total k batches seeds list generation spend  0.01192474365234375
after graph partition
graph partition algorithm spend time 0.06551218032836914
72
68
partition_len_list
[361, 286]
REG selection method  spend 0.06604814529418945
time for parepare:  0.00015473365783691406
local_output_nid generation:  1.7642974853515625e-05
local_in_edges_tensor generation:  0.0003535747528076172
mini_batch_src_global generation:  7.224082946777344e-05
r_  generation:  0.0002942085266113281
local_output_nid generation:  1.7642974853515625e-05
local_in_edges_tensor generation:  0.00025582313537597656
mini_batch_src_global generation:  5.888938903808594e-05
r_  generation:  0.00023865699768066406
----------------------check_connections_block total spend ----------------------------- 0.001837015151977539
generate_one_block  0.003679037094116211
generate_one_block  0.002439737319946289
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0010607242584228516
gen group dst list time:  6.794929504394531e-05
time for parepare:  0.0003228187561035156
local_output_nid generation:  5.9604644775390625e-05
local_in_edges_tensor generation:  0.0004076957702636719
mini_batch_src_global generation:  0.00013637542724609375
r_  generation:  0.0015406608581542969
local_output_nid generation:  4.887580871582031e-05
local_in_edges_tensor generation:  0.0003223419189453125
mini_batch_src_global generation:  0.000141143798828125
r_  generation:  0.0010879039764404297
----------------------check_connections_block total spend ----------------------------- 0.004790306091308594
generate_one_block  0.002679109573364258
generate_one_block  0.002248048782348633
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0008130073547363281
gen group dst list time:  6.771087646484375e-05
time for parepare:  0.0002574920654296875
local_output_nid generation:  0.00010752677917480469
local_in_edges_tensor generation:  0.0004119873046875
mini_batch_src_global generation:  0.00019478797912597656
r_  generation:  0.002393007278442383
local_output_nid generation:  5.459785461425781e-05
local_in_edges_tensor generation:  0.00020837783813476562
mini_batch_src_global generation:  0.0001499652862548828
r_  generation:  0.0012197494506835938
----------------------check_connections_block total spend ----------------------------- 0.005841732025146484
generate_one_block  0.003144502639770508
generate_one_block  0.0024566650390625
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0006453990936279297
gen group dst list time:  8.058547973632812e-05
time for parepare:  0.0001881122589111328
local_output_nid generation:  0.00012302398681640625
local_in_edges_tensor generation:  0.0004048347473144531
mini_batch_src_global generation:  0.0001964569091796875
r_  generation:  0.0026280879974365234
local_output_nid generation:  0.00010395050048828125
local_in_edges_tensor generation:  0.000293731689453125
mini_batch_src_global generation:  0.00024056434631347656
r_  generation:  0.0021338462829589844
----------------------check_connections_block total spend ----------------------------- 0.0076029300689697266
generate_one_block  0.003939628601074219
generate_one_block  0.0034477710723876953
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00372314453125  GigaBytes
Max Memory Allocated: 0.00372314453125  GigaBytes

connection checking time:  0.020071983337402344
block generation total time  0.024034500122070312
average batch blocks generation time:  0.003004312515258789
block dataloader generation time/epoch 0.12099719047546387
pseudo mini batch 0 input nodes size: 2271
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00372314453125  GigaBytes
Max Memory Allocated: 0.00372314453125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00372314453125  GigaBytes
Max Memory Allocated: 0.00372314453125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.015846729278564453  GigaBytes
Max Memory Allocated: 0.015846729278564453  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.01584768295288086  GigaBytes
Max Memory Allocated: 0.01584768295288086  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.01584768295288086  GigaBytes
Max Memory Allocated: 0.01584768295288086  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.015960216522216797  GigaBytes
Max Memory Allocated: 0.015960216522216797  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.015960216522216797  GigaBytes
Max Memory Allocated: 0.015960216522216797  GigaBytes

first layer input nodes number: 2271
first layer output nodes number: 1838
edges number: 7411
----------------------------------------before model layer 0
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.0159912109375  GigaBytes
Max Memory Allocated: 0.01601886749267578  GigaBytes

torch.Size([2271, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.0159912109375  GigaBytes
Max Memory Allocated: 0.01601886749267578  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.02777242660522461  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([1838, 256])
torch.Size([1838, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.029525279998779297  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.027618408203125  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([1838, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.029371261596679688  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.02996349334716797  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

input nodes number: 1838
output nodes number: 1078
edges number: 5085
----------------------------------------before model layer 1
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.029985427856445312  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([1838, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.029985427856445312  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.032953739166259766  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([1078, 256])
torch.Size([1078, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.0339818000793457  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.032813072204589844  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([1078, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2967529296875 GB
    Memory Allocated: 0.03384113311767578  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03423881530761719  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

input nodes number: 1078
output nodes number: 361
edges number: 2102
----------------------------------------before model layer 2
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03424978256225586  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([1078, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03424978256225586  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.0349574089050293  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([361, 256])
torch.Size([361, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03530168533325195  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.0349574089050293  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

torch.Size([361, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03530168533325195  GigaBytes
Max Memory Allocated: 0.03568458557128906  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03538799285888672  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

----------------input nodes number: 361
----------------output nodes number: 72
----------------edges number: 359
----------------------------------------before mean aggregator
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.035391807556152344  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03546619415283203  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

torch.Size([72, 7])
torch.Size([72, 7])
----------------------------------------after rst
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.035468101501464844  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03546619415283203  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

torch.Size([72, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.035468101501464844  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.2987060546875 GB
    Memory Allocated: 0.03547096252441406  GigaBytes
Max Memory Allocated: 0.035732269287109375  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.019949913024902344  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

pseudo mini batch 1 input nodes size: 1987
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.019573688507080078  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.019573688507080078  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.030181407928466797  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.030182361602783203  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.018057823181152344  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.018144607543945312  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.018144607543945312  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

first layer input nodes number: 1987
first layer output nodes number: 1417
edges number: 6086
----------------------------------------before model layer 0
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.018170833587646484  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([1987, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.018170833587646484  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.02772808074951172  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([1417, 256])
torch.Size([1417, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.029079437255859375  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.027138233184814453  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([1417, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.02848958969116211  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.029332637786865234  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

input nodes number: 1417
output nodes number: 673
edges number: 3540
----------------------------------------before model layer 1
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.02934885025024414  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([1417, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.02934885025024414  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.030664920806884766  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([673, 256])
torch.Size([673, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.03130674362182617  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.030664920806884766  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([673, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.03130674362182617  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.031467437744140625  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

input nodes number: 673
output nodes number: 286
edges number: 1430
----------------------------------------before model layer 2
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.031475067138671875  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([673, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.031475067138671875  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.032034873962402344  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([286, 256])
torch.Size([286, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03230762481689453  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.032034873962402344  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([286, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03230762481689453  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03237581253051758  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------input nodes number: 286
----------------output nodes number: 68
----------------edges number: 279
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.032379150390625  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03244972229003906  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([68, 7])
torch.Size([68, 7])
----------------------------------------after rst
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.032451629638671875  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03244972229003906  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

torch.Size([68, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03244972229003906  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03245210647583008  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.018346309661865234  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.0263671875  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.0263671875  GigaBytes
Max Memory Allocated: 0.036859989166259766  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.008850932121276855 |0.1720954179763794 |0.4008355140686035 |0.00021374225616455078 |0.005807042121887207 |0.0018122196197509766 |
----------------------------------------------------------pseudo_mini_loss sum 1.9660100936889648
Total (block generation + training)time/epoch 1.3060719966888428
Training time/epoch 1.1847317218780518
Training time without block to device /epoch 0.840540885925293
Training time without total dataloading part /epoch 0.8155248165130615
load block tensor time/epoch 0.01770186424255371
block to device time/epoch 0.3441908359527588
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  9911
Number of first layer input nodes during this epoch:  4258
Number of first layer output nodes during this epoch:  3255
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=1433, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=1433, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=7, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=7, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  999424
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 1433])
layers.0.fc_neigh.weight, torch.Size([256, 1433])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([7, 256])
layers.3.fc_neigh.weight, torch.Size([7, 256])
----------------------------------------
un-trainable parameters
