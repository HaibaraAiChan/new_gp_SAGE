main start at this time 1657105090.2118611
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
60
500
19157
# Nodes: 19717
# Edges: 88648
# Train: 60
# Val: 500
# Test: 19157
# Classes: 3

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  500
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007778167724609375  GigaBytes
Max Memory Allocated: 0.007778167724609375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007778167724609375  GigaBytes
Max Memory Allocated: 0.007778167724609375  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.002529144287109375
global_2_local spend time (sec) 6.127357482910156e-05
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003905296325683594
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 294, 1: 26, 2: 6, 3: 6, 6: 4, 4: 3, 8: 3, 5: 2, 17: 2, 18: 1, 7: 1, 31: 1, 22: 1, 10: 1, 29: 1, 9: 1, 11: 1})

A = g.adjacency_matrix() spent  0.0003437995910644531
auxiliary_graph
Graph(num_nodes=354, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0004107952117919922
remove nodes length  294

auxiliary_graph.remove_nodes spent  0.001634359359741211
after remove non output nodes the auxiliary_graph
Graph(num_nodes=60, num_edges=66,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007555484771728516

the counter of shared neighbor distribution
Counter({1.0: 6})
6
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0014908313751220703
30
30
total k batches seeds list generation spend  0.00887155532836914
after graph partition
graph partition algorithm spend time 0.05055999755859375
30
30
partition_len_list
[181, 173]
REG selection method  spend 0.05076003074645996
time for parepare:  4.863739013671875e-05
local_output_nid generation:  4.5299530029296875e-06
local_in_edges_tensor generation:  0.0001385211944580078
mini_batch_src_global generation:  3.6716461181640625e-05
r_  generation:  9.560585021972656e-05
local_output_nid generation:  4.5299530029296875e-06
local_in_edges_tensor generation:  0.0001385211944580078
mini_batch_src_global generation:  2.6702880859375e-05
r_  generation:  7.605552673339844e-05
----------------------check_connections_block total spend ----------------------------- 0.00074005126953125
generate_one_block  0.0028481483459472656
generate_one_block  0.0012004375457763672
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.0008828639984130859
gen group dst list time:  2.4080276489257812e-05
time for parepare:  0.0002551078796386719
local_output_nid generation:  1.7404556274414062e-05
local_in_edges_tensor generation:  0.00029087066650390625
mini_batch_src_global generation:  6.461143493652344e-05
r_  generation:  0.0006008148193359375
local_output_nid generation:  1.4781951904296875e-05
local_in_edges_tensor generation:  0.0001468658447265625
mini_batch_src_global generation:  7.867813110351562e-05
r_  generation:  0.0006308555603027344
----------------------check_connections_block total spend ----------------------------- 0.0024318695068359375
generate_one_block  0.001928091049194336
generate_one_block  0.0018854141235351562
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0010113716125488281
gen group dst list time:  5.8650970458984375e-05
time for parepare:  0.0006611347198486328
local_output_nid generation:  9.822845458984375e-05
local_in_edges_tensor generation:  0.0003914833068847656
mini_batch_src_global generation:  0.00025773048400878906
r_  generation:  0.0033452510833740234
local_output_nid generation:  9.322166442871094e-05
local_in_edges_tensor generation:  0.0002930164337158203
mini_batch_src_global generation:  0.0004990100860595703
r_  generation:  0.003699779510498047
----------------------check_connections_block total spend ----------------------------- 0.01130533218383789
generate_one_block  0.005585670471191406
generate_one_block  0.005461454391479492
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0020399093627929688
gen group dst list time:  0.00016999244689941406
time for parepare:  0.0013663768768310547
local_output_nid generation:  0.00038242340087890625
local_in_edges_tensor generation:  0.0010306835174560547
mini_batch_src_global generation:  0.0012049674987792969
r_  generation:  0.01235651969909668
local_output_nid generation:  0.00029158592224121094
local_in_edges_tensor generation:  0.0008363723754882812
mini_batch_src_global generation:  0.0012540817260742188
r_  generation:  0.010509014129638672
----------------------check_connections_block total spend ----------------------------- 0.03486061096191406
generate_one_block  0.017585277557373047
generate_one_block  0.015571355819702148
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0016717910766601562
gen group dst list time:  0.0004725456237792969
time for parepare:  0.001516580581665039
local_output_nid generation:  0.0009620189666748047
local_in_edges_tensor generation:  0.0019881725311279297
mini_batch_src_global generation:  0.0015685558319091797
r_  generation:  0.01796269416809082
local_output_nid generation:  0.0007739067077636719
local_in_edges_tensor generation:  0.0012769699096679688
mini_batch_src_global generation:  0.0017008781433105469
r_  generation:  0.015502452850341797
----------------------check_connections_block total spend ----------------------------- 0.05130505561828613
generate_one_block  0.02351665496826172
generate_one_block  0.02077484130859375
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007778167724609375  GigaBytes
Max Memory Allocated: 0.007778167724609375  GigaBytes

connection checking time:  0.10064291954040527
block generation total time  0.09635734558105469
average batch blocks generation time:  0.009635734558105468
block dataloader generation time/epoch 0.26776599884033203
pseudo mini batch 0 input nodes size: 16831
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007778167724609375  GigaBytes
Max Memory Allocated: 0.007778167724609375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0233154296875 GB
    Memory Allocated: 0.007778167724609375  GigaBytes
Max Memory Allocated: 0.007778167724609375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0565185546875 GB
    Memory Allocated: 0.039128780364990234  GigaBytes
Max Memory Allocated: 0.039128780364990234  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0565185546875 GB
    Memory Allocated: 0.03912925720214844  GigaBytes
Max Memory Allocated: 0.03912925720214844  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0565185546875 GB
    Memory Allocated: 0.03912925720214844  GigaBytes
Max Memory Allocated: 0.03912925720214844  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1229248046875 GB
    Memory Allocated: 0.039938926696777344  GigaBytes
Max Memory Allocated: 0.039938926696777344  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1229248046875 GB
    Memory Allocated: 0.039938926696777344  GigaBytes
Max Memory Allocated: 0.039938926696777344  GigaBytes

first layer input nodes number: 16831
first layer output nodes number: 13616
edges number: 53907
----------------------------------------before model layer 0
 Nvidia-smi: 1.1229248046875 GB
    Memory Allocated: 0.04016590118408203  GigaBytes
Max Memory Allocated: 0.04036712646484375  GigaBytes

torch.Size([16831, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1229248046875 GB
    Memory Allocated: 0.04016590118408203  GigaBytes
Max Memory Allocated: 0.04036712646484375  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3885498046875 GB
    Memory Allocated: 0.0919804573059082  GigaBytes
Max Memory Allocated: 0.0919804573059082  GigaBytes

torch.Size([13616, 512])
torch.Size([13616, 512])
----------------------------------------after rst
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.1179509162902832  GigaBytes
Max Memory Allocated: 0.1439213752746582  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.0919804573059082  GigaBytes
Max Memory Allocated: 0.1439213752746582  GigaBytes

torch.Size([13616, 512])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.1179509162902832  GigaBytes
Max Memory Allocated: 0.1439213752746582  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.12444353103637695  GigaBytes
Max Memory Allocated: 0.15041399002075195  GigaBytes

input nodes number: 13616
output nodes number: 5404
edges number: 41487
----------------------------------------before model layer 1
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.12458562850952148  GigaBytes
Max Memory Allocated: 0.15041399002075195  GigaBytes

torch.Size([13616, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.12458562850952148  GigaBytes
Max Memory Allocated: 0.15041399002075195  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4432373046875 GB
    Memory Allocated: 0.14555120468139648  GigaBytes
Max Memory Allocated: 0.15041399002075195  GigaBytes

torch.Size([5404, 512])
torch.Size([5404, 512])
----------------------------------------after rst
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.15585851669311523  GigaBytes
Max Memory Allocated: 0.16616582870483398  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.14555120468139648  GigaBytes
Max Memory Allocated: 0.16616582870483398  GigaBytes

torch.Size([5404, 512])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.15585851669311523  GigaBytes
Max Memory Allocated: 0.16616582870483398  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.15843534469604492  GigaBytes
Max Memory Allocated: 0.16874265670776367  GigaBytes

input nodes number: 5404
output nodes number: 1382
edges number: 10818
----------------------------------------before model layer 2
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.15848636627197266  GigaBytes
Max Memory Allocated: 0.16874265670776367  GigaBytes

torch.Size([5404, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.15848636627197266  GigaBytes
Max Memory Allocated: 0.16874265670776367  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.1638498306274414  GigaBytes
Max Memory Allocated: 0.16874265670776367  GigaBytes

torch.Size([1382, 512])
torch.Size([1382, 512])
----------------------------------------after rst
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16716861724853516  GigaBytes
Max Memory Allocated: 0.16980457305908203  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16453266143798828  GigaBytes
Max Memory Allocated: 0.16980457305908203  GigaBytes

torch.Size([1382, 512])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16716861724853516  GigaBytes
Max Memory Allocated: 0.16980457305908203  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16782760620117188  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

input nodes number: 1382
output nodes number: 181
edges number: 1807
----------------------------------------before model layer 3
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16783952713012695  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

torch.Size([1382, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16783952713012695  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.16854619979858398  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

torch.Size([181, 512])
torch.Size([181, 512])
----------------------------------------after rst
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16889142990112305  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16854619979858398  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

torch.Size([181, 512])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16889142990112305  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.1689777374267578  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

----------------input nodes number: 181
----------------output nodes number: 30
----------------edges number: 153
----------------------------------------before mean aggregator
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16897964477539062  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16904020309448242  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

torch.Size([30, 3])
torch.Size([30, 3])
----------------------------------------after rst
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16904067993164062  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16904020309448242  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

torch.Size([30, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16904067993164062  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.4569091796875 GB
    Memory Allocated: 0.16904211044311523  GigaBytes
Max Memory Allocated: 0.17046356201171875  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.5291748046875 GB
    Memory Allocated: 0.04952526092529297  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

pseudo mini batch 1 input nodes size: 14692
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.5291748046875 GB
    Memory Allocated: 0.04690885543823242  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.5291748046875 GB
    Memory Allocated: 0.04690885543823242  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.07427501678466797  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.07427549362182617  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.04292440414428711  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.043653011322021484  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.043653011322021484  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

first layer input nodes number: 14692
first layer output nodes number: 10827
edges number: 46675
----------------------------------------before model layer 0
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.043843746185302734  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([14692, 500])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.043843746185302734  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.08505010604858398  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([10827, 512])
torch.Size([10827, 512])
----------------------------------------after rst
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.10570096969604492  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.08505010604858398  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([10827, 512])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.10570096969604492  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.11092472076416016  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

input nodes number: 10827
output nodes number: 4070
edges number: 36082
----------------------------------------before model layer 1
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.11103630065917969  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([10827, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.11103630065917969  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.126861572265625  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([4070, 512])
torch.Size([4070, 512])
----------------------------------------after rst
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.13462448120117188  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.126861572265625  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([4070, 512])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.13462448120117188  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.13672637939453125  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

input nodes number: 4070
output nodes number: 1278
edges number: 12589
----------------------------------------before model layer 2
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.1367664337158203  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([4070, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.1367664337158203  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14174556732177734  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([1278, 512])
torch.Size([1278, 512])
----------------------------------------after rst
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14418315887451172  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14174556732177734  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([1278, 512])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14418315887451172  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.1447925567626953  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

input nodes number: 1278
output nodes number: 173
edges number: 1997
----------------------------------------before model layer 3
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14480352401733398  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([1278, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14480352401733398  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14548063278198242  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([173, 512])
torch.Size([173, 512])
----------------------------------------after rst
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14581060409545898  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14548063278198242  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([173, 512])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14581060409545898  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14589309692382812  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------input nodes number: 173
----------------output nodes number: 30
----------------edges number: 144
----------------------------------------before mean aggregator
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14589500427246094  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14595556259155273  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([30, 3])
torch.Size([30, 3])
----------------------------------------after rst
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14595603942871094  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14595556259155273  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

torch.Size([30, 3])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14595556259155273  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.5584716796875 GB
    Memory Allocated: 0.14595651626586914  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.5604248046875 GB
    Memory Allocated: 0.04524087905883789  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.5780029296875 GB
    Memory Allocated: 0.06079721450805664  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.5780029296875 GB
    Memory Allocated: 0.06079721450805664  GigaBytes
Max Memory Allocated: 0.18338298797607422  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.013140320777893066 |0.17664682865142822 |0.40357983112335205 |0.00021207332611083984 |0.007807731628417969 |0.0034461021423339844 |
----------------------------------------------------------pseudo_mini_loss sum 1.1166231632232666
Total (block generation + training)time/epoch 1.4817273616790771
Training time/epoch 1.213609218597412
Training time without block to device /epoch 0.8603155612945557
Training time without total dataloading part /epoch 0.8266453742980957
load block tensor time/epoch 0.026280641555786133
block to device time/epoch 0.35329365730285645
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 2.384185791015625e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  68454
Number of first layer input nodes during this epoch:  31523
Number of first layer output nodes during this epoch:  24443
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=500, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=500, out_features=512, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=512, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=512, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=512, bias=False)
    )
    (4): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=3, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=3, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  2087936
trainable parameters
layers.0.fc_self.weight, torch.Size([512, 500])
layers.0.fc_neigh.weight, torch.Size([512, 500])
layers.1.fc_self.weight, torch.Size([512, 512])
layers.1.fc_neigh.weight, torch.Size([512, 512])
layers.2.fc_self.weight, torch.Size([512, 512])
layers.2.fc_neigh.weight, torch.Size([512, 512])
layers.3.fc_self.weight, torch.Size([512, 512])
layers.3.fc_neigh.weight, torch.Size([512, 512])
layers.4.fc_self.weight, torch.Size([3, 512])
layers.4.fc_neigh.weight, torch.Size([3, 512])
----------------------------------------
un-trainable parameters
