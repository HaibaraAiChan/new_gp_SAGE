main start at this time 1657072187.3626788
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
153431
23831
55703
# Nodes: 232965
# Edges: 114615892
# Train: 153431
# Val: 23831
# Test: 55703
# Classes: 41

#nodes: 232965
#edges: 114615892
#classes: 41
----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  602
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

The real block id is  2
get_global_graph_edges_ids_block function  spend 0.6203608512878418
global_2_local spend time (sec) 0.060594797134399414
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.017384767532348633
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({30: 132904, 0: 71192, 1: 1391, 2: 1221, 3: 1053, 4: 986, 5: 920, 6: 875, 7: 814, 8: 799, 11: 702, 9: 695, 13: 691, 10: 690, 12: 684, 14: 652, 15: 643, 16: 607, 19: 606, 17: 598, 18: 563, 21: 562, 22: 556, 23: 543, 20: 538, 28: 532, 27: 528, 25: 525, 26: 521, 24: 521, 29: 511})

A = g.adjacency_matrix() spent  0.06485462188720703
auxiliary_graph
Graph(num_nodes=224623, num_edges=205357019,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.12215948104858398
remove nodes length  71192

auxiliary_graph.remove_nodes spent  12.882683515548706
after remove non output nodes the auxiliary_graph
Graph(num_nodes=153431, num_edges=205357019,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  8.831721067428589

the counter of shared neighbor distribution
Counter({1.0: 188777130, 2.0: 13023222, 3.0: 2028012, 4.0: 618458, 5.0: 280804, 6.0: 151834, 7.0: 91670, 8.0: 58900, 9.0: 41228, 10.0: 29572, 11.0: 21504, 12.0: 16186, 13.0: 12610, 14.0: 9636, 15.0: 7654, 16.0: 6272, 17.0: 4990, 18.0: 4596, 19.0: 3764, 20.0: 3034, 21.0: 2596, 22.0: 2018, 23.0: 1648, 25.0: 1556, 24.0: 1394, 26.0: 1266, 27.0: 1144, 28.0: 688, 29.0: 200, 30.0: 2})
205203588
Convert a graph into a bidirected graph: 14.634 seconds
Metis partitioning: 48.396 seconds
Split the graph: 22.382 seconds
Construct subgraphs: 0.056 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  85.550945520401
78883
74548
total k batches seeds list generation spend  136.00063490867615
after graph partition
graph partition algorithm spend time 136.63397693634033
78883
74548
partition_len_list
[148436, 146947]
REG selection method  spend 136.7782530784607
time for parepare:  0.028994321823120117
local_output_nid generation:  0.009312868118286133
local_in_edges_tensor generation:  0.03104686737060547
mini_batch_src_global generation:  0.07577681541442871
r_  generation:  0.6866919994354248
local_output_nid generation:  0.011921882629394531
local_in_edges_tensor generation:  0.05440878868103027
mini_batch_src_global generation:  0.08495783805847168
r_  generation:  0.6776716709136963
----------------------check_connections_block total spend ----------------------------- 1.9562714099884033
generate_one_block  1.0121979713439941
generate_one_block  1.0521032810211182
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.5728251934051514
gen group dst list time:  0.009020328521728516
time for parepare:  0.029103755950927734
local_output_nid generation:  0.02131175994873047
local_in_edges_tensor generation:  0.0756692886352539
mini_batch_src_global generation:  0.10852980613708496
r_  generation:  1.0858557224273682
local_output_nid generation:  0.025743722915649414
local_in_edges_tensor generation:  0.0833747386932373
mini_batch_src_global generation:  0.1353895664215088
r_  generation:  1.1519672870635986
----------------------check_connections_block total spend ----------------------------- 3.1717758178710938
generate_one_block  1.7680158615112305
generate_one_block  1.5206670761108398
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.2809758186340332
gen group dst list time:  0.025359630584716797
time for parepare:  0.03188753128051758
local_output_nid generation:  0.057257652282714844
local_in_edges_tensor generation:  0.07027101516723633
mini_batch_src_global generation:  0.06376361846923828
r_  generation:  0.7723040580749512
local_output_nid generation:  0.05672860145568848
local_in_edges_tensor generation:  0.061728715896606445
mini_batch_src_global generation:  0.07996249198913574
r_  generation:  0.8344814777374268
----------------------check_connections_block total spend ----------------------------- 2.381995916366577
generate_one_block  1.2792515754699707
generate_one_block  0.9747531414031982
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

connection checking time:  7.510043144226074
block generation total time  7.606988906860352
average batch blocks generation time:  1.2678314844767253
block dataloader generation time/epoch 154.1092071533203
pseudo mini batch 0 input nodes size: 222997
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0017147064208984375  GigaBytes
Max Memory Allocated: 0.0017147064208984375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.5194091796875 GB
    Memory Allocated: 0.5018134117126465  GigaBytes
Max Memory Allocated: 0.5018134117126465  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.5213623046875 GB
    Memory Allocated: 0.5024013519287109  GigaBytes
Max Memory Allocated: 0.5024013519287109  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.5213623046875 GB
    Memory Allocated: 0.5024013519287109  GigaBytes
Max Memory Allocated: 0.5024013519287109  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.6522216796875 GB
    Memory Allocated: 0.560856819152832  GigaBytes
Max Memory Allocated: 0.560856819152832  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.6522216796875 GB
    Memory Allocated: 0.560856819152832  GigaBytes
Max Memory Allocated: 0.560856819152832  GigaBytes

first layer input nodes number: 222997
first layer output nodes number: 209591
edges number: 2051372
----------------------------------------before model layer 0
 Nvidia-smi: 1.6717529296875 GB
    Memory Allocated: 0.5642728805541992  GigaBytes
Max Memory Allocated: 0.5719151496887207  GigaBytes

torch.Size([222997, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.6717529296875 GB
    Memory Allocated: 0.5642728805541992  GigaBytes
Max Memory Allocated: 0.5719151496887207  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.3221435546875 GB
    Memory Allocated: 1.2509231567382812  GigaBytes
Max Memory Allocated: 1.5225257873535156  GigaBytes

torch.Size([209591, 256])
torch.Size([209591, 256])
----------------------------------------after rst
 Nvidia-smi: 3.5233154296875 GB
    Memory Allocated: 1.4508047103881836  GigaBytes
Max Memory Allocated: 1.650686264038086  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.5233154296875 GB
    Memory Allocated: 1.2509231567382812  GigaBytes
Max Memory Allocated: 1.650686264038086  GigaBytes

torch.Size([209591, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.5233154296875 GB
    Memory Allocated: 1.4508047103881836  GigaBytes
Max Memory Allocated: 1.650686264038086  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.5233154296875 GB
    Memory Allocated: 1.5007753372192383  GigaBytes
Max Memory Allocated: 1.7006568908691406  GigaBytes

input nodes number: 209591
output nodes number: 148436
edges number: 3493638
----------------------------------------before model layer 1
 Nvidia-smi: 3.5233154296875 GB
    Memory Allocated: 1.5042080879211426  GigaBytes
Max Memory Allocated: 1.7006568908691406  GigaBytes

torch.Size([209591, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.5233154296875 GB
    Memory Allocated: 1.5042080879211426  GigaBytes
Max Memory Allocated: 1.7006568908691406  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.6658935546875 GB
    Memory Allocated: 1.8144640922546387  GigaBytes
Max Memory Allocated: 1.8144640922546387  GigaBytes

torch.Size([148436, 256])
torch.Size([148436, 256])
----------------------------------------after rst
 Nvidia-smi: 3.9510498046875 GB
    Memory Allocated: 1.9560236930847168  GigaBytes
Max Memory Allocated: 2.097583293914795  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 3.9510498046875 GB
    Memory Allocated: 1.8144640922546387  GigaBytes
Max Memory Allocated: 2.097583293914795  GigaBytes

torch.Size([148436, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 3.9510498046875 GB
    Memory Allocated: 1.9560236930847168  GigaBytes
Max Memory Allocated: 2.097583293914795  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 3.9510498046875 GB
    Memory Allocated: 1.9914135932922363  GigaBytes
Max Memory Allocated: 2.1329731941223145  GigaBytes

----------------input nodes number: 148436
----------------output nodes number: 78883
----------------edges number: 2124180
----------------------------------------before mean aggregator
 Nvidia-smi: 3.9510498046875 GB
    Memory Allocated: 1.993107795715332  GigaBytes
Max Memory Allocated: 2.1329731941223145  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.0272216796875 GB
    Memory Allocated: 2.097813129425049  GigaBytes
Max Memory Allocated: 2.1609930992126465  GigaBytes

torch.Size([78883, 41])
torch.Size([78883, 41])
----------------------------------------after rst
 Nvidia-smi: 4.0272216796875 GB
    Memory Allocated: 2.1098618507385254  GigaBytes
Max Memory Allocated: 2.1609930992126465  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 4.0272216796875 GB
    Memory Allocated: 2.097813129425049  GigaBytes
Max Memory Allocated: 2.1609930992126465  GigaBytes

torch.Size([78883, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.0272216796875 GB
    Memory Allocated: 2.1098618507385254  GigaBytes
Max Memory Allocated: 2.1609930992126465  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 4.0272216796875 GB
    Memory Allocated: 2.1219115257263184  GigaBytes
Max Memory Allocated: 2.1609930992126465  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 4.8006591796875 GB
    Memory Allocated: 0.6851959228515625  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

pseudo mini batch 1 input nodes size: 221373
----------------------------------------before load block subtensor 
 Nvidia-smi: 4.8006591796875 GB
    Memory Allocated: 0.5161657333374023  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 4.8006591796875 GB
    Memory Allocated: 0.5161657333374023  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 1.012622356414795  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 1.0131778717041016  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 0.5124912261962891  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 0.5705537796020508  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 0.5705537796020508  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

first layer input nodes number: 221373
first layer output nodes number: 211915
edges number: 2096871
----------------------------------------before model layer 0
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 0.5744643211364746  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([221373, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 5.2987060546875 GB
    Memory Allocated: 0.5744643211364746  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.2682209014892578  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([211915, 256])
torch.Size([211915, 256])
----------------------------------------after rst
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.4703187942504883  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.2682209014892578  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([211915, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.4703187942504883  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.520843505859375  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

input nodes number: 211915
output nodes number: 146947
edges number: 3571381
----------------------------------------before model layer 1
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.5244803428649902  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([211915, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.5244803428649902  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.8324646949768066  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([146947, 256])
torch.Size([146947, 256])
----------------------------------------after rst
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.9726042747497559  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.8324646949768066  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([146947, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 1.9726042747497559  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.0076394081115723  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------input nodes number: 146947
----------------output nodes number: 74548
----------------edges number: 2124612
----------------------------------------before mean aggregator
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.0092902183532715  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.108546257019043  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([74548, 41])
torch.Size([74548, 41])
----------------------------------------after rst
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.1199326515197754  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.108546257019043  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

torch.Size([74548, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.107883930206299  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 5.7811279296875 GB
    Memory Allocated: 2.1192708015441895  GigaBytes
Max Memory Allocated: 2.320925712585449  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 5.7830810546875 GB
    Memory Allocated: 0.6831603050231934  GigaBytes
Max Memory Allocated: 2.3213934898376465  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 5.7869873046875 GB
    Memory Allocated: 0.6865897178649902  GigaBytes
Max Memory Allocated: 2.3213934898376465  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 5.7869873046875 GB
    Memory Allocated: 0.6865897178649902  GigaBytes
Max Memory Allocated: 2.3213934898376465  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.18705785274505615 |0.21701478958129883 |0.4439516067504883 |0.0002442598342895508 |0.028424620628356934 |0.006101131439208984 |
----------------------------------------------------------pseudo_mini_loss sum 10.740013122558594
Total (block generation + training)time/epoch 155.89344096183777
Training time/epoch 1.783921241760254
Training time without block to device /epoch 1.3498916625976562
Training time without total dataloading part /epoch 0.9513421058654785
load block tensor time/epoch 0.3741157054901123
block to device time/epoch 0.43402957916259766
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1161259
Number of first layer input nodes during this epoch:  444370
Number of first layer output nodes during this epoch:  421506
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=602, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=602, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=41, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=41, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  460288
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 602])
layers.0.fc_neigh.weight, torch.Size([256, 602])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([41, 256])
layers.2.fc_neigh.weight, torch.Size([41, 256])
----------------------------------------
un-trainable parameters
