main start at this time 1657104963.536171
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  1433
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.0113525390625  GigaBytes
Max Memory Allocated: 0.0113525390625  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.0113525390625  GigaBytes
Max Memory Allocated: 0.0113525390625  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.0009827613830566406
global_2_local spend time (sec) 0.00011420249938964844
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0003898143768310547
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 504, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 10: 3, 8: 3, 12: 2, 21: 1, 11: 1, 36: 1, 19: 1, 32: 1})

A = g.adjacency_matrix() spent  0.00032329559326171875
auxiliary_graph
Graph(num_nodes=644, num_edges=438,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.00046133995056152344
remove nodes length  504

auxiliary_graph.remove_nodes spent  0.0009114742279052734
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=438,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0007855892181396484

the counter of shared neighbor distribution
Counter({1.0: 252, 2.0: 30, 3.0: 14, 4.0: 2})
298
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0018088817596435547
72
68
total k batches seeds list generation spend  0.008153200149536133
after graph partition
graph partition algorithm spend time 0.0561680793762207
72
68
partition_len_list
[369, 279]
REG selection method  spend 0.05655837059020996
time for parepare:  0.00011849403381347656
local_output_nid generation:  1.2159347534179688e-05
local_in_edges_tensor generation:  0.0002167224884033203
mini_batch_src_global generation:  7.367134094238281e-05
r_  generation:  0.0003135204315185547
local_output_nid generation:  1.3589859008789062e-05
local_in_edges_tensor generation:  0.0002067089080810547
mini_batch_src_global generation:  4.649162292480469e-05
r_  generation:  0.00018525123596191406
----------------------check_connections_block total spend ----------------------------- 0.0015358924865722656
generate_one_block  0.0035457611083984375
generate_one_block  0.0013589859008789062
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.0006549358367919922
gen group dst list time:  6.842613220214844e-05
time for parepare:  0.0002052783966064453
local_output_nid generation:  3.5762786865234375e-05
local_in_edges_tensor generation:  0.00024318695068359375
mini_batch_src_global generation:  0.00011467933654785156
r_  generation:  0.0008637905120849609
local_output_nid generation:  2.8133392333984375e-05
local_in_edges_tensor generation:  0.00017881393432617188
mini_batch_src_global generation:  8.702278137207031e-05
r_  generation:  0.0005931854248046875
----------------------check_connections_block total spend ----------------------------- 0.002804994583129883
generate_one_block  0.0022284984588623047
generate_one_block  0.0017006397247314453
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0006542205810546875
gen group dst list time:  5.078315734863281e-05
time for parepare:  0.00017881393432617188
local_output_nid generation:  7.748603820800781e-05
local_in_edges_tensor generation:  0.0003268718719482422
mini_batch_src_global generation:  0.00020074844360351562
r_  generation:  0.0018229484558105469
local_output_nid generation:  4.76837158203125e-05
local_in_edges_tensor generation:  0.00020694732666015625
mini_batch_src_global generation:  0.00015020370483398438
r_  generation:  0.0011663436889648438
----------------------check_connections_block total spend ----------------------------- 0.0049266815185546875
generate_one_block  0.003153562545776367
generate_one_block  0.0023272037506103516
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006954669952392578
gen group dst list time:  8.535385131835938e-05
time for parepare:  0.0001957416534423828
local_output_nid generation:  0.00012540817260742188
local_in_edges_tensor generation:  0.0004379749298095703
mini_batch_src_global generation:  0.0002167224884033203
r_  generation:  0.002839326858520508
local_output_nid generation:  9.72747802734375e-05
local_in_edges_tensor generation:  0.0002884864807128906
mini_batch_src_global generation:  0.0002429485321044922
r_  generation:  0.0021114349365234375
----------------------check_connections_block total spend ----------------------------- 0.007946014404296875
generate_one_block  0.0040781497955322266
generate_one_block  0.0033698081970214844
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0008251667022705078
gen group dst list time:  0.00010085105895996094
time for parepare:  0.00018906593322753906
local_output_nid generation:  0.0001506805419921875
local_in_edges_tensor generation:  0.0004475116729736328
mini_batch_src_global generation:  0.0001995563507080078
r_  generation:  0.0030677318572998047
local_output_nid generation:  0.000141143798828125
local_in_edges_tensor generation:  0.0003483295440673828
mini_batch_src_global generation:  0.0002636909484863281
r_  generation:  0.002767801284790039
----------------------check_connections_block total spend ----------------------------- 0.009133338928222656
generate_one_block  0.00429081916809082
generate_one_block  0.003918886184692383
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.0113525390625  GigaBytes
Max Memory Allocated: 0.0113525390625  GigaBytes

connection checking time:  0.026346921920776367
block generation total time  0.029972314834594727
average batch blocks generation time:  0.0029972314834594725
block dataloader generation time/epoch 0.12429380416870117
pseudo mini batch 0 input nodes size: 2431
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.0113525390625  GigaBytes
Max Memory Allocated: 0.0113525390625  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.0113525390625  GigaBytes
Max Memory Allocated: 0.0113525390625  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.02433013916015625  GigaBytes
Max Memory Allocated: 0.02433013916015625  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.024331092834472656  GigaBytes
Max Memory Allocated: 0.024331092834472656  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0428466796875 GB
    Memory Allocated: 0.024331092834472656  GigaBytes
Max Memory Allocated: 0.024331092834472656  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024519920349121094  GigaBytes
Max Memory Allocated: 0.024519920349121094  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024519920349121094  GigaBytes
Max Memory Allocated: 0.024519920349121094  GigaBytes

first layer input nodes number: 2431
first layer output nodes number: 2306
edges number: 8741
----------------------------------------before model layer 0
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024555683135986328  GigaBytes
Max Memory Allocated: 0.024588584899902344  GigaBytes

torch.Size([2431, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1072998046875 GB
    Memory Allocated: 0.024555683135986328  GigaBytes
Max Memory Allocated: 0.024588584899902344  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.04133939743041992  GigaBytes
Max Memory Allocated: 0.049260616302490234  GigaBytes

torch.Size([2306, 512])
torch.Size([2306, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.04621458053588867  GigaBytes
Max Memory Allocated: 0.0506129264831543  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.04181623458862305  GigaBytes
Max Memory Allocated: 0.0506129264831543  GigaBytes

torch.Size([2306, 512])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.04621458053588867  GigaBytes
Max Memory Allocated: 0.0506129264831543  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.047575950622558594  GigaBytes
Max Memory Allocated: 0.05197429656982422  GigaBytes

input nodes number: 2306
output nodes number: 1915
edges number: 8249
----------------------------------------before model layer 1
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.0476078987121582  GigaBytes
Max Memory Allocated: 0.05197429656982422  GigaBytes

torch.Size([2306, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3084716796875 GB
    Memory Allocated: 0.0476078987121582  GigaBytes
Max Memory Allocated: 0.05197429656982422  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.055735111236572266  GigaBytes
Max Memory Allocated: 0.055735111236572266  GigaBytes

torch.Size([1915, 512])
torch.Size([1915, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.0593876838684082  GigaBytes
Max Memory Allocated: 0.06304025650024414  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.05498933792114258  GigaBytes
Max Memory Allocated: 0.06304025650024414  GigaBytes

torch.Size([1915, 512])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.058641910552978516  GigaBytes
Max Memory Allocated: 0.06304025650024414  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.06030082702636719  GigaBytes
Max Memory Allocated: 0.06395339965820312  GigaBytes

input nodes number: 1915
output nodes number: 1137
edges number: 5504
----------------------------------------before model layer 2
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.06032371520996094  GigaBytes
Max Memory Allocated: 0.06395339965820312  GigaBytes

torch.Size([1915, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.06032371520996094  GigaBytes
Max Memory Allocated: 0.06395339965820312  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.06471061706542969  GigaBytes
Max Memory Allocated: 0.06471061706542969  GigaBytes

torch.Size([1137, 512])
torch.Size([1137, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.0668792724609375  GigaBytes
Max Memory Allocated: 0.06904792785644531  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.06471061706542969  GigaBytes
Max Memory Allocated: 0.06904792785644531  GigaBytes

torch.Size([1137, 512])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3280029296875 GB
    Memory Allocated: 0.0668792724609375  GigaBytes
Max Memory Allocated: 0.06904792785644531  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.06742143630981445  GigaBytes
Max Memory Allocated: 0.06959009170532227  GigaBytes

input nodes number: 1137
output nodes number: 369
edges number: 2229
----------------------------------------before model layer 3
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.06743288040161133  GigaBytes
Max Memory Allocated: 0.06959009170532227  GigaBytes

torch.Size([1137, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.06743288040161133  GigaBytes
Max Memory Allocated: 0.06959009170532227  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3299560546875 GB
    Memory Allocated: 0.06886053085327148  GigaBytes
Max Memory Allocated: 0.06959009170532227  GigaBytes

torch.Size([369, 512])
torch.Size([369, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.0695643424987793  GigaBytes
Max Memory Allocated: 0.07026815414428711  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06886053085327148  GigaBytes
Max Memory Allocated: 0.07026815414428711  GigaBytes

torch.Size([369, 512])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.0695643424987793  GigaBytes
Max Memory Allocated: 0.07026815414428711  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06974029541015625  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

----------------input nodes number: 369
----------------output nodes number: 72
----------------edges number: 367
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06974411010742188  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06988716125488281  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

torch.Size([72, 7])
torch.Size([72, 7])
----------------------------------------after rst
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06988906860351562  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06988716125488281  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

torch.Size([72, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06988906860351562  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3319091796875 GB
    Memory Allocated: 0.06989192962646484  GigaBytes
Max Memory Allocated: 0.07044410705566406  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.03633737564086914  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

pseudo mini batch 1 input nodes size: 2307
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.035686492919921875  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.035686492919921875  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.04800224304199219  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.048003196716308594  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.03502464294433594  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.035170555114746094  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.035170555114746094  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

first layer input nodes number: 2307
first layer output nodes number: 2010
edges number: 7962
----------------------------------------before model layer 0
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.03520345687866211  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([2307, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.03520345687866211  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.049835205078125  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([2010, 512])
torch.Size([2010, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.053668975830078125  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.049835205078125  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([2010, 512])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.053668975830078125  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.054627418518066406  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

input nodes number: 2010
output nodes number: 1357
edges number: 6350
----------------------------------------before model layer 1
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.054653167724609375  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([2010, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.054653167724609375  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.05988788604736328  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([1357, 512])
torch.Size([1357, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.062476158142089844  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.05988788604736328  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([1357, 512])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.062476158142089844  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06312322616577148  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

input nodes number: 1357
output nodes number: 645
edges number: 3312
----------------------------------------before model layer 2
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06313896179199219  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([1357, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06313896179199219  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06577110290527344  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([645, 512])
torch.Size([645, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.0670013427734375  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06575584411621094  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([645, 512])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.0670013427734375  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06820535659790039  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

input nodes number: 645
output nodes number: 279
edges number: 1391
----------------------------------------before model layer 3
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06821298599243164  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([645, 512])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.06821298599243164  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3612060546875 GB
    Memory Allocated: 0.0692906379699707  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([279, 512])
torch.Size([279, 512])
----------------------------------------after rst
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.06982278823852539  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.0692906379699707  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([279, 512])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.06982278823852539  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.06995582580566406  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------input nodes number: 279
----------------output nodes number: 68
----------------edges number: 271
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.06995916366577148  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.07009458541870117  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([68, 7])
torch.Size([68, 7])
----------------------------------------after rst
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.07009649276733398  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.07009458541870117  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

torch.Size([68, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.07009458541870117  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3631591796875 GB
    Memory Allocated: 0.07009696960449219  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3651123046875 GB
    Memory Allocated: 0.0355224609375  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.3768310546875 GB
    Memory Allocated: 0.05882453918457031  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.3768310546875 GB
    Memory Allocated: 0.05882453918457031  GigaBytes
Max Memory Allocated: 0.07380437850952148  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.015006303787231445 |0.17230939865112305 |0.40552210807800293 |0.0002142190933227539 |0.006818175315856934 |0.0035278797149658203 |
----------------------------------------------------------pseudo_mini_loss sum 1.9548144340515137
Total (block generation + training)time/epoch 1.3354721069335938
Training time/epoch 1.2108805179595947
Training time without block to device /epoch 0.8662617206573486
Training time without total dataloading part /epoch 0.828636884689331
load block tensor time/epoch 0.03001260757446289
block to device time/epoch 0.3446187973022461
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 2.384185791015625e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  14756
Number of first layer input nodes during this epoch:  4738
Number of first layer output nodes during this epoch:  4316
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=1433, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=1433, out_features=512, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=512, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=512, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=512, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=512, bias=False)
    )
    (4): SAGEConv(
      (fc_self): Linear(in_features=512, out_features=7, bias=False)
      (fc_neigh): Linear(in_features=512, out_features=7, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  3047424
trainable parameters
layers.0.fc_self.weight, torch.Size([512, 1433])
layers.0.fc_neigh.weight, torch.Size([512, 1433])
layers.1.fc_self.weight, torch.Size([512, 512])
layers.1.fc_neigh.weight, torch.Size([512, 512])
layers.2.fc_self.weight, torch.Size([512, 512])
layers.2.fc_neigh.weight, torch.Size([512, 512])
layers.3.fc_self.weight, torch.Size([512, 512])
layers.3.fc_neigh.weight, torch.Size([512, 512])
layers.4.fc_self.weight, torch.Size([7, 512])
layers.4.fc_neigh.weight, torch.Size([7, 512])
----------------------------------------
un-trainable parameters
