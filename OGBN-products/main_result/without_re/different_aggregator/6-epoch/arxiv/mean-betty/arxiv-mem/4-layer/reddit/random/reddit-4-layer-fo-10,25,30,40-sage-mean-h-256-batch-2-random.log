main start at this time 1657099878.9628077
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

success----------------------------------------
153431
23831
55703
# Nodes: 232965
# Edges: 114615892
# Train: 153431
# Val: 23831
# Test: 55703
# Classes: 41

#nodes: 232965
#edges: 114615892
#classes: 41
----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  602
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

The real block id is  3
get_global_graph_edges_ids_block function  spend 0.4485201835632324
number of batches is  2
batch size is  76716
random selection method spend 0.012453079223632812
time for parepare:  0.02859807014465332
local_output_nid generation:  0.0319209098815918
local_in_edges_tensor generation:  0.07042598724365234
mini_batch_src_global generation:  0.0807044506072998
r_  generation:  0.889815092086792
local_output_nid generation:  0.03709840774536133
local_in_edges_tensor generation:  0.06663084030151367
mini_batch_src_global generation:  0.10527253150939941
r_  generation:  0.9248607158660889
----------------------check_connections_block total spend ----------------------------- 2.591381549835205
generate_one_block  1.1087281703948975
generate_one_block  1.109114646911621
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.5237298011779785
gen group dst list time:  0.012650728225708008
time for parepare:  0.028688430786132812
local_output_nid generation:  0.04384422302246094
local_in_edges_tensor generation:  0.16036438941955566
mini_batch_src_global generation:  0.18876886367797852
r_  generation:  1.879831075668335
local_output_nid generation:  0.053206682205200195
local_in_edges_tensor generation:  0.15870141983032227
mini_batch_src_global generation:  0.2427961826324463
r_  generation:  1.902667760848999
----------------------check_connections_block total spend ----------------------------- 5.480977773666382
generate_one_block  2.54848313331604
generate_one_block  2.5883119106292725
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.5989482402801514
gen group dst list time:  0.016721010208129883
time for parepare:  0.027801036834716797
local_output_nid generation:  0.04765653610229492
local_in_edges_tensor generation:  0.15839290618896484
mini_batch_src_global generation:  0.1680605411529541
r_  generation:  1.6719200611114502
local_output_nid generation:  0.053594350814819336
local_in_edges_tensor generation:  0.1386570930480957
mini_batch_src_global generation:  0.20595145225524902
r_  generation:  1.7081959247589111
----------------------check_connections_block total spend ----------------------------- 4.912126541137695
generate_one_block  2.3667566776275635
generate_one_block  2.156970977783203
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.37101054191589355
gen group dst list time:  0.02169346809387207
time for parepare:  0.03269791603088379
local_output_nid generation:  0.04892134666442871
local_in_edges_tensor generation:  0.09150075912475586
mini_batch_src_global generation:  0.06354904174804688
r_  generation:  0.8020954132080078
local_output_nid generation:  0.05645751953125
local_in_edges_tensor generation:  0.07979464530944824
mini_batch_src_global generation:  0.0808718204498291
r_  generation:  0.8040058612823486
----------------------check_connections_block total spend ----------------------------- 2.421370029449463
generate_one_block  0.9650540351867676
generate_one_block  0.9540281295776367
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

connection checking time:  12.81447434425354
block generation total time  11.579604864120483
average batch blocks generation time:  5.789802432060242
block dataloader generation time/epoch 32.58884954452515
pseudo mini batch 0 input nodes size: 228876
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0194091796875 GB
    Memory Allocated: 0.0022029876708984375  GigaBytes
Max Memory Allocated: 0.0022029876708984375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.5330810546875 GB
    Memory Allocated: 0.5158748626708984  GigaBytes
Max Memory Allocated: 0.5158748626708984  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.5330810546875 GB
    Memory Allocated: 0.516446590423584  GigaBytes
Max Memory Allocated: 0.516446590423584  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.5330810546875 GB
    Memory Allocated: 0.516446590423584  GigaBytes
Max Memory Allocated: 0.516446590423584  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.7303466796875 GB
    Memory Allocated: 0.6407904624938965  GigaBytes
Max Memory Allocated: 0.6407904624938965  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.7303466796875 GB
    Memory Allocated: 0.6407904624938965  GigaBytes
Max Memory Allocated: 0.6407904624938965  GigaBytes

first layer input nodes number: 228876
first layer output nodes number: 228485
edges number: 2236393
----------------------------------------before model layer 0
 Nvidia-smi: 1.7498779296875 GB
    Memory Allocated: 0.6441988945007324  GigaBytes
Max Memory Allocated: 0.6525301933288574  GigaBytes

torch.Size([228876, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.7498779296875 GB
    Memory Allocated: 0.6441988945007324  GigaBytes
Max Memory Allocated: 0.6525301933288574  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 3.5350341796875 GB
    Memory Allocated: 1.3920197486877441  GigaBytes
Max Memory Allocated: 1.6873774528503418  GigaBytes

torch.Size([228485, 256])
torch.Size([228485, 256])
----------------------------------------after rst
 Nvidia-smi: 3.7537841796875 GB
    Memory Allocated: 1.6107697486877441  GigaBytes
Max Memory Allocated: 1.8286700248718262  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 3.7537841796875 GB
    Memory Allocated: 1.392869472503662  GigaBytes
Max Memory Allocated: 1.8286700248718262  GigaBytes

torch.Size([228485, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 3.7537841796875 GB
    Memory Allocated: 1.6107697486877441  GigaBytes
Max Memory Allocated: 1.8286700248718262  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 3.7537841796875 GB
    Memory Allocated: 1.6652450561523438  GigaBytes
Max Memory Allocated: 1.8831453323364258  GigaBytes

input nodes number: 228485
output nodes number: 226622
edges number: 5388497
----------------------------------------before model layer 1
 Nvidia-smi: 3.7537841796875 GB
    Memory Allocated: 1.6686363220214844  GigaBytes
Max Memory Allocated: 1.8831453323364258  GigaBytes

torch.Size([228485, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 3.7537841796875 GB
    Memory Allocated: 1.6686363220214844  GigaBytes
Max Memory Allocated: 1.8831453323364258  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.0955810546875 GB
    Memory Allocated: 2.1433935165405273  GigaBytes
Max Memory Allocated: 2.1433935165405273  GigaBytes

torch.Size([226622, 256])
torch.Size([226622, 256])
----------------------------------------after rst
 Nvidia-smi: 4.5291748046875 GB
    Memory Allocated: 2.3601903915405273  GigaBytes
Max Memory Allocated: 2.5769872665405273  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 4.5291748046875 GB
    Memory Allocated: 2.14406681060791  GigaBytes
Max Memory Allocated: 2.5769872665405273  GigaBytes

torch.Size([226622, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 4.5291748046875 GB
    Memory Allocated: 2.36086368560791  GigaBytes
Max Memory Allocated: 2.5769872665405273  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 4.5838623046875 GB
    Memory Allocated: 2.4148778915405273  GigaBytes
Max Memory Allocated: 2.6316747665405273  GigaBytes

input nodes number: 226622
output nodes number: 215926
edges number: 6173208
----------------------------------------before model layer 2
 Nvidia-smi: 4.5838623046875 GB
    Memory Allocated: 2.4182634353637695  GigaBytes
Max Memory Allocated: 2.6316747665405273  GigaBytes

torch.Size([226622, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 4.5838623046875 GB
    Memory Allocated: 2.4182634353637695  GigaBytes
Max Memory Allocated: 2.6316747665405273  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 4.9100341796875 GB
    Memory Allocated: 2.877713203430176  GigaBytes
Max Memory Allocated: 2.877713203430176  GigaBytes

torch.Size([215926, 256])
torch.Size([215926, 256])
----------------------------------------after rst
 Nvidia-smi: 5.3240966796875 GB
    Memory Allocated: 3.0836362838745117  GigaBytes
Max Memory Allocated: 3.2895593643188477  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 5.3240966796875 GB
    Memory Allocated: 2.877713203430176  GigaBytes
Max Memory Allocated: 3.2895593643188477  GigaBytes

torch.Size([215926, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 5.3240966796875 GB
    Memory Allocated: 3.0836362838745117  GigaBytes
Max Memory Allocated: 3.2895593643188477  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.1351170539855957  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

----------------input nodes number: 215926
----------------output nodes number: 76716
----------------edges number: 2772677
----------------------------------------before mean aggregator
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.137402057647705  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.2440571784973145  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

torch.Size([76716, 41])
torch.Size([76716, 41])
----------------------------------------after rst
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.255774974822998  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.2440571784973145  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

torch.Size([76716, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.255774974822998  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 5.3768310546875 GB
    Memory Allocated: 3.267493724822998  GigaBytes
Max Memory Allocated: 3.3410401344299316  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.9037189483642578  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

pseudo mini batch 1 input nodes size: 228824
----------------------------------------before load block subtensor 
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.5303683280944824  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.5303683280944824  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.0440402030944824  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.044611930847168  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.5303683280944824  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.6547408103942871  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.6547408103942871  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

first layer input nodes number: 228824
first layer output nodes number: 228383
edges number: 2235803
----------------------------------------before model layer 0
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.6581478118896484  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([228824, 602])
----------------------------------------before mean aggregator
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 0.6581478118896484  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.4074349403381348  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([228383, 256])
torch.Size([228383, 256])
----------------------------------------after rst
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.6261849403381348  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.4074349403381348  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([228383, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.6261849403381348  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.6808724403381348  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

input nodes number: 228383
output nodes number: 226481
edges number: 5386651
----------------------------------------before model layer 1
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.6842617988586426  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([228383, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 1.6842617988586426  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.1596779823303223  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([226481, 256])
torch.Size([226481, 256])
----------------------------------------after rst
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.3764748573303223  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.1596779823303223  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([226481, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.3764748573303223  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.4304723739624023  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

input nodes number: 226481
output nodes number: 215652
edges number: 6166519
----------------------------------------before model layer 2
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.4338440895080566  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([226481, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 6.7069091796875 GB
    Memory Allocated: 2.4338440895080566  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 2.893184185028076  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([215652, 256])
torch.Size([215652, 256])
----------------------------------------after rst
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.098845958709717  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 2.893184185028076  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([215652, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.098845958709717  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.150261402130127  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------input nodes number: 215652
----------------output nodes number: 76715
----------------edges number: 2778843
----------------------------------------before mean aggregator
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.153304100036621  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.261091709136963  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([76715, 41])
torch.Size([76715, 41])
----------------------------------------after rst
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.2728090286254883  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.261091709136963  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

torch.Size([76715, 41])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.2610912322998047  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 3.2728095054626465  GigaBytes
Max Memory Allocated: 3.603997230529785  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 6.7088623046875 GB
    Memory Allocated: 0.9064068794250488  GigaBytes
Max Memory Allocated: 3.6087584495544434  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 6.7147216796875 GB
    Memory Allocated: 0.9108128547668457  GigaBytes
Max Memory Allocated: 3.6087584495544434  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 6.7147216796875 GB
    Memory Allocated: 0.9108128547668457  GigaBytes
Max Memory Allocated: 3.6087584495544434  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.21928763389587402 |0.25674939155578613 |0.45248520374298096 |0.00019729137420654297 |0.03995692729949951 |0.0052051544189453125 |
----------------------------------------------------------pseudo_mini_loss sum 19.319820404052734
Total (block generation + training)time/epoch 34.61775207519531
Training time/epoch 2.028588056564331
Training time without block to device /epoch 1.5150892734527588
Training time without total dataloading part /epoch 0.9904839992523193
load block tensor time/epoch 0.43857526779174805
block to device time/epoch 0.5134987831115723
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  1799249
Number of first layer input nodes during this epoch:  457700
Number of first layer output nodes during this epoch:  456868
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=602, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=602, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=41, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=41, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  591360
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 602])
layers.0.fc_neigh.weight, torch.Size([256, 602])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([41, 256])
layers.3.fc_neigh.weight, torch.Size([41, 256])
----------------------------------------
un-trainable parameters
