main start at this time 1657102906.902252
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

  NumNodes: 2708
  NumEdges: 10556
  NumFeats: 1433
  NumClasses: 7
  NumTrainingSamples: 140
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
success----------------------------------------
140
500
2068
# Nodes: 2708
# Edges: 10556
# Train: 140
# Val: 500
# Test: 2068
# Classes: 7

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  1433
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00421142578125  GigaBytes
Max Memory Allocated: 0.00421142578125  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00421142578125  GigaBytes
Max Memory Allocated: 0.00421142578125  GigaBytes

The real block id is  4
get_global_graph_edges_ids_block function  spend 0.0016050338745117188
global_2_local spend time (sec) 0.00010538101196289062
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0005757808685302734
the counter of in-degree current block !!!!!!!!!!!!!!_______________!!!!!!!!!!
Counter({0: 504, 3: 26, 2: 25, 4: 22, 1: 20, 5: 15, 6: 11, 9: 4, 7: 4, 10: 3, 8: 3, 12: 2, 21: 1, 11: 1, 36: 1, 19: 1, 32: 1})

A = g.adjacency_matrix() spent  0.0003845691680908203
auxiliary_graph
Graph(num_nodes=644, num_edges=438,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.0006644725799560547
remove nodes length  504

auxiliary_graph.remove_nodes spent  0.00164794921875
after remove non output nodes the auxiliary_graph
Graph(num_nodes=140, num_edges=438,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  0.0008819103240966797

the counter of shared neighbor distribution
Counter({1.0: 252, 2.0: 30, 3.0: 14, 4.0: 2})
298
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.001 seconds
Construct subgraphs: 0.000 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  0.0017397403717041016
72
68
total k batches seeds list generation spend  0.011431455612182617
after graph partition
graph partition algorithm spend time 0.03745007514953613
72
68
partition_len_list
[369, 279]
REG selection method  spend 0.0377349853515625
time for parepare:  6.031990051269531e-05
local_output_nid generation:  6.9141387939453125e-06
local_in_edges_tensor generation:  0.00012230873107910156
mini_batch_src_global generation:  3.266334533691406e-05
r_  generation:  0.00014162063598632812
local_output_nid generation:  7.3909759521484375e-06
local_in_edges_tensor generation:  0.00011920928955078125
mini_batch_src_global generation:  2.7179718017578125e-05
r_  generation:  0.00011157989501953125
----------------------check_connections_block total spend ----------------------------- 0.0007956027984619141
generate_one_block  0.002791881561279297
generate_one_block  0.0012054443359375
The real block id is  3
get_global_graph_edges_ids_block function  spend 0.0005135536193847656
gen group dst list time:  3.528594970703125e-05
time for parepare:  0.00017309188842773438
local_output_nid generation:  3.0040740966796875e-05
local_in_edges_tensor generation:  0.0002315044403076172
mini_batch_src_global generation:  9.393692016601562e-05
r_  generation:  0.0007460117340087891
local_output_nid generation:  2.2172927856445312e-05
local_in_edges_tensor generation:  0.0001556873321533203
mini_batch_src_global generation:  7.605552673339844e-05
r_  generation:  0.0005109310150146484
----------------------check_connections_block total spend ----------------------------- 0.0024366378784179688
generate_one_block  0.0019598007202148438
generate_one_block  0.0016672611236572266
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0005962848663330078
gen group dst list time:  5.078315734863281e-05
time for parepare:  0.0001747608184814453
local_output_nid generation:  7.653236389160156e-05
local_in_edges_tensor generation:  0.00032401084899902344
mini_batch_src_global generation:  0.00016999244689941406
r_  generation:  0.0018513202667236328
local_output_nid generation:  4.863739013671875e-05
local_in_edges_tensor generation:  0.00020241737365722656
mini_batch_src_global generation:  0.000141143798828125
r_  generation:  0.0011425018310546875
----------------------check_connections_block total spend ----------------------------- 0.004854917526245117
generate_one_block  0.0031719207763671875
generate_one_block  0.0023522377014160156
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006597042083740234
gen group dst list time:  7.843971252441406e-05
time for parepare:  0.00019931793212890625
local_output_nid generation:  0.00012993812561035156
local_in_edges_tensor generation:  0.0004172325134277344
mini_batch_src_global generation:  0.00021982192993164062
r_  generation:  0.002836465835571289
local_output_nid generation:  9.775161743164062e-05
local_in_edges_tensor generation:  0.0002799034118652344
mini_batch_src_global generation:  0.0002052783966064453
r_  generation:  0.0021529197692871094
----------------------check_connections_block total spend ----------------------------- 0.007798671722412109
generate_one_block  0.004132270812988281
generate_one_block  0.0034782886505126953
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0007770061492919922
gen group dst list time:  0.000102996826171875
time for parepare:  0.00019621849060058594
local_output_nid generation:  0.00015354156494140625
local_in_edges_tensor generation:  0.0004696846008300781
mini_batch_src_global generation:  0.0002067089080810547
r_  generation:  0.003120899200439453
local_output_nid generation:  0.00014328956604003906
local_in_edges_tensor generation:  0.000347137451171875
mini_batch_src_global generation:  0.0002665519714355469
r_  generation:  0.0028138160705566406
----------------------check_connections_block total spend ----------------------------- 0.009209871292114258
generate_one_block  0.004370689392089844
generate_one_block  0.0038421154022216797
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  2
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00421142578125  GigaBytes
Max Memory Allocated: 0.00421142578125  GigaBytes

connection checking time:  0.025095701217651367
block generation total time  0.02897191047668457
average batch blocks generation time:  0.002897191047668457
block dataloader generation time/epoch 0.10357165336608887
pseudo mini batch 0 input nodes size: 2431
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00421142578125  GigaBytes
Max Memory Allocated: 0.00421142578125  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.00421142578125  GigaBytes
Max Memory Allocated: 0.00421142578125  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.01718902587890625  GigaBytes
Max Memory Allocated: 0.01718902587890625  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.017189979553222656  GigaBytes
Max Memory Allocated: 0.017189979553222656  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.0369873046875 GB
    Memory Allocated: 0.017189979553222656  GigaBytes
Max Memory Allocated: 0.017189979553222656  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.017378807067871094  GigaBytes
Max Memory Allocated: 0.017378807067871094  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.017378807067871094  GigaBytes
Max Memory Allocated: 0.017378807067871094  GigaBytes

first layer input nodes number: 2431
first layer output nodes number: 2306
edges number: 8741
----------------------------------------before model layer 0
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.017414569854736328  GigaBytes
Max Memory Allocated: 0.017447471618652344  GigaBytes

torch.Size([2431, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.1014404296875 GB
    Memory Allocated: 0.017414569854736328  GigaBytes
Max Memory Allocated: 0.017447471618652344  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.03199911117553711  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

torch.Size([2306, 256])
torch.Size([2306, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.03419828414916992  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.03199911117553711  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

torch.Size([2306, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3026123046875 GB
    Memory Allocated: 0.03419828414916992  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.034748077392578125  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

input nodes number: 2306
output nodes number: 1915
edges number: 8249
----------------------------------------before model layer 1
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.034780025482177734  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

torch.Size([2306, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.034780025482177734  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.038881778717041016  GigaBytes
Max Memory Allocated: 0.042119503021240234  GigaBytes

torch.Size([1915, 256])
torch.Size([1915, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.040708065032958984  GigaBytes
Max Memory Allocated: 0.04253435134887695  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.03850889205932617  GigaBytes
Max Memory Allocated: 0.04253435134887695  GigaBytes

torch.Size([1915, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.04033517837524414  GigaBytes
Max Memory Allocated: 0.04253435134887695  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.04116487503051758  GigaBytes
Max Memory Allocated: 0.04299116134643555  GigaBytes

input nodes number: 1915
output nodes number: 1137
edges number: 5504
----------------------------------------before model layer 2
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.04118776321411133  GigaBytes
Max Memory Allocated: 0.04299116134643555  GigaBytes

torch.Size([1915, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.04118776321411133  GigaBytes
Max Memory Allocated: 0.04299116134643555  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.044219970703125  GigaBytes
Max Memory Allocated: 0.044219970703125  GigaBytes

torch.Size([1137, 256])
torch.Size([1137, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.045304298400878906  GigaBytes
Max Memory Allocated: 0.047130584716796875  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.043942928314208984  GigaBytes
Max Memory Allocated: 0.047130584716796875  GigaBytes

torch.Size([1137, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.045304298400878906  GigaBytes
Max Memory Allocated: 0.047130584716796875  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.04604053497314453  GigaBytes
Max Memory Allocated: 0.04740190505981445  GigaBytes

input nodes number: 1137
output nodes number: 369
edges number: 2229
----------------------------------------before model layer 3
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.046051979064941406  GigaBytes
Max Memory Allocated: 0.04740190505981445  GigaBytes

torch.Size([1137, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3045654296875 GB
    Memory Allocated: 0.046051979064941406  GigaBytes
Max Memory Allocated: 0.04740190505981445  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04677581787109375  GigaBytes
Max Memory Allocated: 0.04740190505981445  GigaBytes

torch.Size([369, 256])
torch.Size([369, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.047127723693847656  GigaBytes
Max Memory Allocated: 0.04747962951660156  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04677581787109375  GigaBytes
Max Memory Allocated: 0.04747962951660156  GigaBytes

torch.Size([369, 256])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.047127723693847656  GigaBytes
Max Memory Allocated: 0.04747962951660156  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.047215938568115234  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

----------------input nodes number: 369
----------------output nodes number: 72
----------------edges number: 367
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04721975326538086  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04729413986206055  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

torch.Size([72, 7])
torch.Size([72, 7])
----------------------------------------after rst
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04729604721069336  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04729413986206055  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

torch.Size([72, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04729604721069336  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3065185546875 GB
    Memory Allocated: 0.04729890823364258  GigaBytes
Max Memory Allocated: 0.04756784439086914  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.02230978012084961  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

pseudo mini batch 1 input nodes size: 2307
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.021658897399902344  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.021658897399902344  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.033974647521972656  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after  batch labels to device
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.03397560119628906  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.020997047424316406  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.021142959594726562  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.021142959594726562  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

first layer input nodes number: 2307
first layer output nodes number: 2010
edges number: 7962
----------------------------------------before model layer 0
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.021175861358642578  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([2307, 1433])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.021175861358642578  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.033890724182128906  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([2010, 256])
torch.Size([2010, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.03580760955810547  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.033890724182128906  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([2010, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.03580760955810547  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.036899566650390625  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

input nodes number: 2010
output nodes number: 1357
edges number: 6350
----------------------------------------before model layer 1
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.036925315856933594  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([2010, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.036925315856933594  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.040256500244140625  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([1357, 256])
torch.Size([1357, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.041550636291503906  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.04019451141357422  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([1357, 256])
----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.0414886474609375  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.04187440872192383  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

input nodes number: 1357
output nodes number: 645
edges number: 3312
----------------------------------------before model layer 2
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.04189014434814453  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([1357, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3104248046875 GB
    Memory Allocated: 0.04189014434814453  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043150901794433594  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([645, 256])
torch.Size([645, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043766021728515625  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 2 x = layer(block, x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043150901794433594  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([645, 256])
----------------------------------------after model layer 2 x = self.activation(x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043766021728515625  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 2 x = self.dropout(x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043920040130615234  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

input nodes number: 645
output nodes number: 279
edges number: 1391
----------------------------------------before model layer 3
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043927669525146484  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([645, 256])
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.043927669525146484  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.04447317123413086  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([279, 256])
torch.Size([279, 256])
----------------------------------------after rst
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.0447392463684082  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 3 x = layer(block, x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.04447317123413086  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([279, 256])
----------------------------------------after model layer 3 x = self.activation(x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.0447392463684082  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after model layer 3 x = self.dropout(x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.04480600357055664  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------input nodes number: 279
----------------output nodes number: 68
----------------edges number: 271
----------------------------------------before mean aggregator
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.04480934143066406  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------after mean aggregator-------
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.044879913330078125  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([68, 7])
torch.Size([68, 7])
----------------------------------------after rst
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.04488182067871094  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.044879913330078125  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

torch.Size([68, 7])
----------------------------------------- after batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.044879913330078125  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 1.3123779296875 GB
    Memory Allocated: 0.04488229751586914  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 1.3143310546875 GB
    Memory Allocated: 0.02149486541748047  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 1.3143310546875 GB
    Memory Allocated: 0.02991771697998047  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 1.3143310546875 GB
    Memory Allocated: 0.02991771697998047  GigaBytes
Max Memory Allocated: 0.04905366897583008  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.008742451667785645 |0.1759873628616333 |0.400409460067749 |0.00024271011352539062 |0.006680846214294434 |0.0021681785583496094 |
----------------------------------------------------------pseudo_mini_loss sum 1.9388537406921387
Total (block generation + training)time/epoch 1.298954963684082
Training time/epoch 1.1949107646942139
Training time without block to device /epoch 0.8429360389709473
Training time without total dataloading part /epoch 0.8168342113494873
load block tensor time/epoch 0.01748490333557129
block to device time/epoch 0.3519747257232666
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 2.384185791015625e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  14756
Number of first layer input nodes during this epoch:  4738
Number of first layer output nodes during this epoch:  4316
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=1433, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=1433, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (2): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (3): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=256, bias=False)
    )
    (4): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=7, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=7, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  1130496
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 1433])
layers.0.fc_neigh.weight, torch.Size([256, 1433])
layers.1.fc_self.weight, torch.Size([256, 256])
layers.1.fc_neigh.weight, torch.Size([256, 256])
layers.2.fc_self.weight, torch.Size([256, 256])
layers.2.fc_neigh.weight, torch.Size([256, 256])
layers.3.fc_self.weight, torch.Size([256, 256])
layers.3.fc_neigh.weight, torch.Size([256, 256])
layers.4.fc_self.weight, torch.Size([7, 256])
layers.4.fc_neigh.weight, torch.Size([7, 256])
----------------------------------------
un-trainable parameters
