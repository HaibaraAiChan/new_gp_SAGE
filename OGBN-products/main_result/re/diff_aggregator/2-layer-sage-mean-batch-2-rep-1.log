main start at this time 1655961741.087215
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------before model to device 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

----------------------------------------after model to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0002803802490234375  GigaBytes
Max Memory Allocated: 0.0002803802490234375  GigaBytes

----------------------------------------before generate dataloader block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0002803802490234375  GigaBytes
Max Memory Allocated: 0.0002803802490234375  GigaBytes

The real block id is  1
get_global_graph_edges_ids_block function  spend 0.22506070137023926
global_2_local spend time (sec) 0.3918015956878662
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.05071234703063965
A = g.adjacency_matrix() spent  0.07543420791625977
auxiliary_graph
Graph(num_nodes=1205586, num_edges=51744463,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
get remove nodes spent  0.5840508937835693
remove nodes length
1009015
auxiliary_graph.remove_nodes spent  2.6903600692749023
after remove non output nodes the auxiliary_graph
Graph(num_nodes=196571, num_edges=51744463,
      ndata_schemes={}
      edata_schemes={'w': Scheme(shape=(), dtype=torch.float32)})
auxiliary_graph_no_diag generation spent  2.0803675651550293

the counter of shared neighbor distribution
Counter({1.0: 42565268, 2.0: 5784668, 3.0: 1687528, 4.0: 688038, 5.0: 337564, 6.0: 180988, 7.0: 106156, 8.0: 62284, 9.0: 39504, 10.0: 24936, 11.0: 16152, 12.0: 10442, 13.0: 7436, 14.0: 6488, 15.0: 6116, 18.0: 3980, 16.0: 3882, 17.0: 2908, 20.0: 2870, 19.0: 2726, 22.0: 1912, 23.0: 1838, 21.0: 1636, 24.0: 1624, 25.0: 948})
51547892
--------------------------------------- new test ---------------------
--------------------------------------- new test ---------------------

before step function auxiliary_graph_no_diag.edata[w]

tensor([       0,        1,        2,  ..., 51547889, 51547890, 51547891])
drop no edges

after step function v.2.0 all zero auxiliary_graph_no_diag.edata[w]
the counter of shared neigbor distribution
Counter({1.0: 42565268, 2.0: 5784668, 3.0: 1687528, 4.0: 688038, 5.0: 337564, 6.0: 180988, 7.0: 106156, 8.0: 62284, 9.0: 39504, 10.0: 24936, 11.0: 16152, 12.0: 10442, 13.0: 7436, 14.0: 6488, 15.0: 6116, 18.0: 3980, 16.0: 3882, 17.0: 2908, 20.0: 2870, 19.0: 2726, 22.0: 1912, 23.0: 1838, 21.0: 1636, 24.0: 1624, 25.0: 948})
Convert a graph into a bidirected graph: 2.916 seconds
Metis partitioning: 11.460 seconds
Split the graph: 5.903 seconds
Construct subgraphs: 0.050 seconds
auxiliary_graph_no_diag dgl.metis_partition spent  20.351134777069092
99885
96686
total k batches seeds list generation spend  41.54252576828003
after graph partition
graph partition algorithm spend time 42.39179992675781
99885
96686
partition_len_list
[677235, 607702]
shared_neighbor_graph_partition_s0 selection method  spend 43.04345512390137
time for parepare:  0.24511313438415527
local_output_nid generation:  0.013198614120483398
local_in_edges_tensor generation:  0.035207271575927734
mini_batch_src_global generation:  0.07795071601867676
r_  generation:  1.0872080326080322
local_output_nid generation:  0.014471292495727539
local_in_edges_tensor generation:  0.04659581184387207
mini_batch_src_global generation:  0.1049196720123291
r_  generation:  1.1578845977783203
----------------------check_connections_block total spend ----------------------------- 3.2148964405059814
generate_one_block  2.8665571212768555
generate_one_block  1.3004326820373535
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.6647932529449463
gen group dst list time:  0.039177656173706055
time for parepare:  0.4092061519622803
local_output_nid generation:  0.10991764068603516
local_in_edges_tensor generation:  0.2713150978088379
mini_batch_src_global generation:  0.20750951766967773
r_  generation:  3.367457628250122
local_output_nid generation:  0.11107659339904785
local_in_edges_tensor generation:  0.16315722465515137
mini_batch_src_global generation:  0.24749469757080078
r_  generation:  3.0238285064697266
----------------------check_connections_block total spend ----------------------------- 9.01486349105835
generate_one_block  4.5530736446380615
generate_one_block  3.889925479888916
----------===============-------------===============-------------the number of batches *****---- 2

original number of batches:  1
re graph partition time:  0

-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0002803802490234375  GigaBytes
Max Memory Allocated: 0.0002803802490234375  GigaBytes

connection checking time:  12.229759931564331
block generation total time  12.609988927841187
average batch blocks generation time:  3.1524972319602966
block dataloader generation time/epoch 69.99980664253235
pseudo mini batch 0 input nodes size: 1170185
----------------------------------------before load block subtensor 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0002803802490234375  GigaBytes
Max Memory Allocated: 0.0002803802490234375  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0002803802490234375  GigaBytes
Max Memory Allocated: 0.0002803802490234375  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.43620872497558594  GigaBytes
Max Memory Allocated: 0.43620872497558594  GigaBytes

<class 'torch.Tensor'>
----------------------------------------after  batch labels to device
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.436953067779541  GigaBytes
Max Memory Allocated: 0.436953067779541  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 1.4549560546875 GB
    Memory Allocated: 0.436953067779541  GigaBytes
Max Memory Allocated: 0.436953067779541  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 1.5897216796875 GB
    Memory Allocated: 0.5057854652404785  GigaBytes
Max Memory Allocated: 0.5057854652404785  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.5897216796875 GB
    Memory Allocated: 0.5057854652404785  GigaBytes
Max Memory Allocated: 0.5057854652404785  GigaBytes

first layer input nodes number: 1170185
first layer output nodes number: 677235
edges number: 6641936
----------------------------------------before model layer 0
 Nvidia-smi: 1.6346435546875 GB
    Memory Allocated: 0.5195503234863281  GigaBytes
Max Memory Allocated: 0.5449409484863281  GigaBytes

torch.Size([1170185, 100])
----------------------------------------after rst
 Nvidia-smi: 4.7244873046875 GB
    Memory Allocated: 2.1181130409240723  GigaBytes
Max Memory Allocated: 2.7645974159240723  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 4.7244873046875 GB
    Memory Allocated: 1.4716286659240723  GigaBytes
Max Memory Allocated: 2.7645974159240723  GigaBytes

torch.Size([677235, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 4.7244873046875 GB
    Memory Allocated: 2.1181130409240723  GigaBytes
Max Memory Allocated: 2.7645974159240723  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 4.7244873046875 GB
    Memory Allocated: 2.279578685760498  GigaBytes
Max Memory Allocated: 2.926063060760498  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 4.7264404296875 GB
    Memory Allocated: 2.428610324859619  GigaBytes
Max Memory Allocated: 2.926063060760498  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 4.7264404296875 GB
    Memory Allocated: 2.411121368408203  GigaBytes
Max Memory Allocated: 2.926063060760498  GigaBytes

torch.Size([99885, 47])
input nodes number: 677235
output nodes number: 99885
edges number: 2422706
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 4.7264404296875 GB
    Memory Allocated: 2.4344005584716797  GigaBytes
Max Memory Allocated: 2.926063060760498  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 4.7264404296875 GB
    Memory Allocated: 2.434401512145996  GigaBytes
Max Memory Allocated: 2.926063060760498  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.6361331939697266  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

pseudo mini batch 1 input nodes size: 1095760
----------------------------------------before load block subtensor 
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.4547233581542969  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------before batch input features to device
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.4547233581542969  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------after batch input features to device
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.8629260063171387  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

<class 'torch.Tensor'>
----------------------------------------after  batch labels to device
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.8636465072631836  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------after load block subtensor  
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.426973819732666  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------after blocks to device 
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.488008975982666  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.488008975982666  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

first layer input nodes number: 1095760
first layer output nodes number: 607702
edges number: 5850717
----------------------------------------before model layer 0
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 0.5013041496276855  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

torch.Size([1095760, 100])
----------------------------------------after rst
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 1.9329357147216797  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 1.3533859252929688  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

torch.Size([607702, 256])
----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 1.9329357147216797  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 2.0778231620788574  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 2.222566604614258  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 6.0467529296875 GB
    Memory Allocated: 2.2051234245300293  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

torch.Size([96686, 47])
input nodes number: 607702
output nodes number: 96686
edges number: 2341173
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 6.0487060546875 GB
    Memory Allocated: 2.2103261947631836  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

-----------------------------------------after loss calculation
 Nvidia-smi: 6.0487060546875 GB
    Memory Allocated: 2.210326671600342  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

-----------------------------------------after loss backward
 Nvidia-smi: 6.6287841796875 GB
    Memory Allocated: 0.5901637077331543  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

-----------------------------------------after optimizer step
 Nvidia-smi: 6.6287841796875 GB
    Memory Allocated: 0.5907244682312012  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

-----------------------------------------after optimizer zero grad
 Nvidia-smi: 6.6287841796875 GB
    Memory Allocated: 0.5907244682312012  GigaBytes
Max Memory Allocated: 3.6356353759765625  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.17994987964630127 |0.23139548301696777 |0.4131273031234741 |0.00025177001953125 |0.012022972106933594 |0.003026247024536133 |
----------------------------------------------------------pseudo_mini_loss sum 6.269518852233887
Total (block generation + training)time/epoch 71.71248292922974
* Pure training time/epoch 1.6765210628509521
Training time/epoch 1.712376594543457
Training time without block to device /epoch 1.2495856285095215
Training time without total dataloading part /epoch 0.8538303375244141
load block tensor time/epoch 0.35989975929260254
block to device time/epoch 0.46279096603393555
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  3550882
Number of first layer input nodes during this epoch:  2265945
Number of first layer output nodes during this epoch:  1284937
GraphSAGE(
  (layers): ModuleList(
    (0): SAGEConv(
      (fc_self): Linear(in_features=100, out_features=256, bias=False)
      (fc_neigh): Linear(in_features=100, out_features=256, bias=False)
    )
    (1): SAGEConv(
      (fc_self): Linear(in_features=256, out_features=47, bias=False)
      (fc_neigh): Linear(in_features=256, out_features=47, bias=False)
    )
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
total model parameters size  75264
trainable parameters
layers.0.fc_self.weight, torch.Size([256, 100])
layers.0.fc_neigh.weight, torch.Size([256, 100])
layers.1.fc_self.weight, torch.Size([47, 256])
layers.1.fc_neigh.weight, torch.Size([47, 256])
----------------------------------------
un-trainable parameters
