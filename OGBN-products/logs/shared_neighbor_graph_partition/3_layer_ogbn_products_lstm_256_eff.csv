"products sage fan-out 25,35,40 hidden 256","full batch 25,35,40","pseudo 2 batches25,35,40","pseudo 4 batches25,35,40","pseudo 8 batches25,35,40","pseudo 16 batches25,35,40","pseudo 32 batches25,35,40","pseudo 64 batches25,35,40","pseudo 128 batches25,35,40","pseudo 256 batches25,35,40","pseudo 512 batches25,35,40","pseudo 1024 batches25,35,40","pseudo 2048 batches25,35,40"
final layer output nodes/pure train time,,,,,,,,,,,320.9150547813645,187.56429123784207
all layers input nodes//pure train time,,,,,,,,,,,575516.2103005118,450778.00980392867
average train time per epoch,,,,,,,,,,,612.532809138298,1048.0193148851395
average number of nodes for computation,,,,,,,,,,,352522561.0,472424061.0
average first layer num of input nodes,,,,,,,,,,,298090877.0,409291744.0
redundancy rate I (First Layer Input),1.0,,,,,,,,,,131.37248876292335,180.38014306421496
redundancy rate O (First Layer Output),1.0,,,,,,,,,,23.15427671891504,28.95698645679558
average load block input feature time per epoch,,,,,,,,,,,48.78033649921417,59.81739032268524
average block to device time per epoch,,,,,,,,,,,15.970784306526184,25.470399022102356
average dataloading time per epoch,,,,,,,,,,,64.75112080574036,85.2877893447876
average first layer num of output nodes,,,,,,,,,,,49249609.666666664,61592089.333333336
CUDA max memory consumption,,,,,,,,,,,19.488155364990234,11.669703006744385
