main start at this time 1669674798.0779655
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([130185, 134544, 131319, 134356, 134512, 130186, 130174, 134543, 130354,
        131534], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 82910, 130045,  47925, 174275, 176347,  64092,   2998,  14770,  80948,
        147379], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.3663330078125 GB
    Memory Allocated: 0.32146787643432617  GigaBytes
Max Memory Allocated: 0.3221855163574219  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([142928, 165022,  70663,  82506,  33441,  50729,  71803, 175954, 106779,
        146894], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.0987548828125 GB
    Memory Allocated: 5.9539713859558105  GigaBytes
Max Memory Allocated: 6.9369659423828125  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3510)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.1085205078125 GB
    Memory Allocated: 0.37380313873291016  GigaBytes
Max Memory Allocated: 6.9369659423828125  GigaBytes

v3.py : output nodes local nid:  tensor([34099, 34100, 34101, 34102, 34103, 34105, 34106, 34107, 34108, 34070],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([161844,  48159,  59259, 121751,  33708,  87118, 137067, 191415, 187241,
        155495], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.1085205078125 GB
    Memory Allocated: 0.37380313873291016  GigaBytes
Max Memory Allocated: 6.9369659423828125  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([176520,  84678,  92585, 153585,  53623, 127617,  75656, 176570,  91389,
        140489], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 5.971820831298828  GigaBytes
Max Memory Allocated: 6.989232540130615  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3566)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 0.37380313873291016  GigaBytes
Max Memory Allocated: 6.989232540130615  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.7076)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 0.3744783401489258  GigaBytes
Max Memory Allocated: 6.989232540130615  GigaBytes


 Run 0| Epoch 0 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([131453, 130605, 130638, 130639, 131452, 130600, 130211, 131497, 130597,
        130575], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 85594,  64796,  43905, 174846,  44027,  94274,   6635, 123804, 191519,
         99342], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 0.37457704544067383  GigaBytes
Max Memory Allocated: 6.989232540130615  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([ 38125,  64477, 116569, 165766, 100350,  87624, 187402, 142538,  93040,
         87818], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.972662925720215  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3431)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37457704544067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34032, 34033, 34034, 34035, 34036, 34037, 34038, 34039, 34077, 34041],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([  5806,  36684, 188188, 142191, 131552, 119588, 189893, 154760, 127826,
        178062], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37457704544067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([ 9803, 58644, 40232, 52049, 63566, 44927, 76964, 73841,  4551, 72875],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.972594738006592  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3464)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37457704544067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6894)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37457704544067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 1 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([130698, 130428, 130429, 130697, 130700, 130699, 130701, 130427, 130409,
        130677], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 58830,  78083,  33872,  54223,  41565, 149776,  26583,  47478, 132306,
        141691], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3741927146911621  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([185562, 178226, 133156,  52180,  94009, 181947, 158023,  14313,  32828,
        168770], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.972278594970703  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3343)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3741927146911621  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34081, 34082, 34083, 34084, 34085, 34086, 34087, 34052, 34041, 34042],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([165555,  78274, 177418, 109244,  28756,  51495, 116157, 185014,  12555,
        166600], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3741927146911621  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([   223,  37819, 188965,  45272, 101544,  68278,  71127, 195148,  34245,
        183792], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.97221040725708  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3370)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3741927146911621  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6713)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3741927146911621  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 2 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([130503, 130465, 130403, 130523, 130516, 130467, 131481, 131547, 131503,
        130517], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([164711,  89544,   3882, 101283, 119163, 163754, 123521,  77382, 181476,
        185964], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37438344955444336  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([132943, 147509,  30629,   6151,  28732, 101524, 179002, 109180, 117450,
        151594], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972469329833984  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3286)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37438344955444336  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34097, 34098, 34099, 34100, 34065, 34054, 34055, 34056, 34057, 34058],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([189246, 106580,  23415,  43431, 153060,    302,  75469, 101113, 157930,
         66327], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37438344955444336  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([168448,  23795,   6306, 172750,  47948, 185788, 181936, 126381,  14902,
         20262], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972401142120361  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3247)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37438344955444336  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6532)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37438344955444336  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 3 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([130182, 131407, 130199, 131408, 131665, 130307, 131640, 131624, 131623,
        130320], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([183840,  14224, 178868, 182117, 108296,   9554, 132128, 131441,  32212,
        133940], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3741621971130371  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([136708, 167585,  80378,  14694, 135792, 193887,  87514, 107903,   4410,
         91084], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972248077392578  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3159)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3746180534362793  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34032, 34033, 34034, 34035, 34036, 34038, 34039, 34040, 34077, 34042],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 47577,  48857, 106092,   9706,  97231, 148554, 151487, 113099,  18660,
         13400], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3746180534362793  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([ 72365,   2135,  55660,  29272, 151789, 192431, 147793, 114071, 102056,
         57988], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972635746002197  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3193)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3741621971130371  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6353)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3741621971130371  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 4 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([131375, 131534, 131428, 131693, 131376, 131427, 131384, 131414, 131535,
        131413], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 74719,  53417,  76261,  60432, 147978,  65580, 183923,  87835,  55561,
          9022], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37408876419067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([169792, 170500,  94941, 148501, 149790,  47238, 135800, 117415,  24497,
        150330], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972174644470215  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3063)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37408876419067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34009, 34011, 34012, 34014, 34015, 34016, 34017, 34055, 34019, 34020],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 52567,  76498,  54843, 150220, 139168,  75525, 192732,  18606,  46699,
         21507], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37408876419067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([ 91052, 178646,  39383,  86395, 171804, 183766, 134111, 158399, 152156,
        162478], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972106456756592  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3111)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37408876419067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6174)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.37408876419067383  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 5 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([131852, 130651, 124716, 132314, 131847, 124631, 130570, 125015, 131903,
        130569], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([192459,   3209, 166394, 159980, 157265, 178441,  21658,  11744, 157259,
         99169], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3740377426147461  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([ 51802, 103403, 142529,  62736, 193509,  38861,  72809,  94198, 122978,
        193765], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972123622894287  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3046)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3744935989379883  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34084, 34085, 34086, 34087, 34088, 34089, 34090, 34078, 34092, 34093],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 83551, 118211, 185241,  82276,  66181,  19531,  23760,  87623, 173264,
        176504], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3744935989379883  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([ 21993, 150099,  46111,  36356,  88695,  23798,  90096,  93568, 155667,
        172200], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972511291503906  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2948)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3740377426147461  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5994)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3740377426147461  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 6 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([132022, 132038, 132027, 125003, 132026, 132025, 132024, 132023, 132035,
        131975], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([125129, 193044,  32931,  95032,  10202, 134120,  82082,  32255, 120242,
         94564], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.373685359954834  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([ 58092, 105281,  21091, 101410,  18010,  23599,  67383,  80535, 150840,
         19171], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.971771240234375  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2931)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.373685359954834  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34006, 34007, 34008, 34009, 34010, 34072, 34061, 34062, 34063, 34064],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 92709,  24639,  39906,  90610, 179195,  70153,  91986, 124662, 126714,
         82981], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.373685359954834  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([181009,  25785,  99646,  16968,  81243, 191977, 119881,  80631,  82636,
         84821], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.971703052520752  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2886)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.373685359954834  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5817)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.373685359954834  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 7 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([131724, 131758, 131847, 131759, 131915, 131740, 131908, 131830, 131910,
        131805], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([150283,  95513,  97646, 111619, 104810,  91187,  82020, 118824, 171295,
        128798], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3741641044616699  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([ 41397, 113839, 168800, 153860,   7679, 109485,  71059, 125115, 112870,
         15472], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972249984741211  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2749)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3746199607849121  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([33843, 33844, 33845, 33846, 33847, 33848, 34104, 34093, 34094, 34095],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([119502,  46680, 195524, 152769, 161987,   4609,   1189, 126487,  97682,
        194763], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3746199607849121  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([158434, 148188,  18065,  42972,  53116, 186588,  44931, 174573, 143922,
         24770], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.97263765335083  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2891)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3741641044616699  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5640)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3741641044616699  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 8 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([131459, 131449, 131458, 131460, 131167, 134335, 131445, 131444, 131443,
        134334], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([157639,  41825,  11962, 133176, 108292,  71690, 137059,  51115,  78111,
        144168], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3742504119873047  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96305
core.py : output nodes global nid:  tensor([170531, 121455, 120101,  90778, 120409,  99087, 190662, 192401,  68941,
          7949], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972336292266846  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2721)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3742504119873047  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

v3.py : output nodes local nid:  tensor([34102, 34103, 34104, 34105, 34094, 34108, 34109, 34110, 34111, 34112],
       device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([ 17286,  75780, 161695,  36724,  68331,  71496, 177881,  72096,  31394,
         21909], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3742504119873047  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

the length of bkt_idx in core.py _bucketing 96304
core.py : output nodes global nid:  tensor([111619, 106416,  59887, 180907, 159397,  45187, 108559, 187154,   7688,
        119750], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 5.972268104553223  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2740)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3742504119873047  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5462)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8292236328125 GB
    Memory Allocated: 0.3742504119873047  GigaBytes
Max Memory Allocated: 6.99007511138916  GigaBytes


 Run 0| Epoch 9 |
