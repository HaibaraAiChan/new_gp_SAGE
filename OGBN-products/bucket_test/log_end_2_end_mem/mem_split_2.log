main start at this time 1671171182.1563122
-----------------------------------------before load data 
 Nvidia-smi: 2.3907470703125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 2.3907470703125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 3.1094970703125 GB
    Memory Allocated: 0.0003376007080078125  GigaBytes
Max Memory Allocated: 0.0003376007080078125  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 3.4454345703125 GB
    Memory Allocated: 0.3182086944580078  GigaBytes
Max Memory Allocated: 0.3182086944580078  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 3.4454345703125 GB
    Memory Allocated: 0.3182086944580078  GigaBytes
Max Memory Allocated: 0.3182086944580078  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 3.5020751953125 GB
    Memory Allocated: 0.3182086944580078  GigaBytes
Max Memory Allocated: 0.3182086944580078  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 3.5020751953125 GB
    Memory Allocated: 0.3182086944580078  GigaBytes
Max Memory Allocated: 0.3182086944580078  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 3.5509033203125 GB
    Memory Allocated: 0.3196907043457031  GigaBytes
Max Memory Allocated: 0.3197035789489746  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.5645751953125 GB
    Memory Allocated: 0.5944876670837402  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0948)
------------------------------------- after loss backward 
 Nvidia-smi: 4.5743408203125 GB
    Memory Allocated: 0.35516977310180664  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 4.5743408203125 GB
    Memory Allocated: 0.3200111389160156  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 4.5743408203125 GB
    Memory Allocated: 0.3210878372192383  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98315, 98316, 98317], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.3712158203125 GB
    Memory Allocated: 5.953591346740723  GigaBytes
Max Memory Allocated: 6.936585903167725  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3509)
------------------------------------ after loss backward 
 Nvidia-smi: 10.3712158203125 GB
    Memory Allocated: 0.37308549880981445  GigaBytes
Max Memory Allocated: 6.936585903167725  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.3712158203125 GB
    Memory Allocated: 0.37308549880981445  GigaBytes
Max Memory Allocated: 6.936585903167725  GigaBytes

core.py bucket local nid tensor([ 98318,  98320,  98321,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 5.971103191375732  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3455)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.37308549880981445  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.3200111389160156  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.7912)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes


 Run 0| Epoch 0 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.6382002830505371  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.6382002830505371  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7618408203125 GB
    Memory Allocated: 0.6382002830505371  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.3188643455505371  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.3203463554382324  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7305908203125 GB
    Memory Allocated: 0.5953783988952637  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0937)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3554878234863281  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3203291893005371  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32140588760375977  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98292, 98293, 98294], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.953909397125244  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3180)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.37340354919433594  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.37340354919433594  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

core.py bucket local nid tensor([ 98295,  98296,  98297,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971421241760254  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3156)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.37340354919433594  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3203291893005371  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.7273)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3203291893005371  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes


 Run 0| Epoch 1 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3203291893005371  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6382002830505371  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6382002830505371  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6382002830505371  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31922149658203125  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32070350646972656  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5955004692077637  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0926)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35584497451782227  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3217630386352539  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98306, 98307, 98308], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.954266548156738  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2861)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.988832950592041  GigaBytes

core.py bucket local nid tensor([ 98309,  98310,  98311,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971778869628906  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2843)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.6630)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 2 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6380066871643066  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6380066871643066  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6380066871643066  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31867074966430664  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32015275955200195  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5951848030090332  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0915)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35529422760009766  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32013559341430664  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3212122917175293  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98303, 98304, 98305], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.953715801239014  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2518)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.37320995330810547  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.37320995330810547  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98306,  98307,  98308,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971227645874023  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2562)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.37320995330810547  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32013559341430664  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.5995)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32013559341430664  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 3 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32013559341430664  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6380066871643066  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6380066871643066  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6380066871643066  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31922149658203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32070350646972656  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5955004692077637  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0904)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35584497451782227  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3217630386352539  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98293, 98294, 98295], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.954266548156738  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2241)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98296,  98297,  98298,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971778869628906  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2207)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.5352)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 4 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6381678581237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6381678581237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6381678581237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3188319206237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3203139305114746  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5953459739685059  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0893)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3554553985595703  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3202967643737793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32137346267700195  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98292, 98293, 98294], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.953876972198486  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1934)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3733711242675781  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3733711242675781  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98295,  98296,  98297,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971388816833496  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1878)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3733711242675781  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3202967643737793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.4706)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3202967643737793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 5 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3202967643737793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6381678581237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6381678581237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6381678581237793  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31922149658203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32070350646972656  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5955004692077637  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0882)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35584497451782227  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3217630386352539  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98232, 98233, 98234], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.954266548156738  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1550)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98235,  98236,  98238,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971778869628906  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1618)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.4050)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 6 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6377644538879395  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6377644538879395  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6377644538879395  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31842851638793945  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31991052627563477  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.594942569732666  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0871)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35505199432373047  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31989336013793945  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3209700584411621  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98255, 98256, 98257], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.9534735679626465  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1241)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3729677200317383  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3729677200317383  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98258,  98259,  98260,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.970985412597656  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1268)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3729677200317383  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31989336013793945  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.3380)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31989336013793945  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 7 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31989336013793945  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6377644538879395  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6377644538879395  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6377644538879395  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31922149658203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32070350646972656  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5955004692077637  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0859)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35584497451782227  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3217630386352539  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98362, 98363, 98364], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.954266548156738  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.0998)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98365,  98366,  98367,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971778869628906  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.0844)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3737607002258301  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.2701)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 8 |
----------------------------------------- after full batch dataloader loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32068634033203125  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block subtensor loading 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6383295059204102  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after schedule preparing 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.6383295059204102  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after block to device loading 
 Nvidia-smi: 10.7637939453125 GB
    Memory Allocated: 0.6383295059204102  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- before degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.31899356842041016  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------ before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32047557830810547  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.5955076217651367  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0848)
------------------------------------- after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.35561704635620117  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree grouping 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32045841217041016  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.3215351104736328  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98231, 98232, 98233], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.954038619995117  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.0593)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.373532772064209  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.373532772064209  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

core.py bucket local nid tensor([ 98234,  98235,  98236,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
------------------------------------after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 5.971550464630127  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.0559)
------------------------------------ after loss backward 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.373532772064209  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

----------------------------------------- after degree split 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32045841217041016  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes

-------------------------------------------------------------------------------loss_sum  :  tensor(4.1999)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 10.7325439453125 GB
    Memory Allocated: 0.32045841217041016  GigaBytes
Max Memory Allocated: 6.989190578460693  GigaBytes


 Run 0| Epoch 9 |
