main start at this time 1670389449.1006224
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.3663330078125 GB
    Memory Allocated: 0.3196439743041992  GigaBytes
Max Memory Allocated: 0.3218116760253906  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 13.9522705078125 GB
    Memory Allocated: 11.456117630004883  GigaBytes
Max Memory Allocated: 12.836132526397705  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.6964)
----------------------------------------- after loss backward 
 Nvidia-smi: 13.9600830078125 GB
    Memory Allocated: 0.3895587921142578  GigaBytes
Max Memory Allocated: 12.836132526397705  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6964)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 13.9600830078125 GB
    Memory Allocated: 0.39023399353027344  GigaBytes
Max Memory Allocated: 12.836132526397705  GigaBytes


 Run 0| Epoch 0 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 13.9600830078125 GB
    Memory Allocated: 0.3898768424987793  GigaBytes
Max Memory Allocated: 12.836132526397705  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.49193286895752  GigaBytes
Max Memory Allocated: 12.905852317810059  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.6336)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39057064056396484  GigaBytes
Max Memory Allocated: 12.905852317810059  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6336)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39057064056396484  GigaBytes
Max Memory Allocated: 12.905852317810059  GigaBytes


 Run 0| Epoch 1 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.390927791595459  GigaBytes
Max Memory Allocated: 12.905852317810059  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.4929838180542  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.5703)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.390927791595459  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5703)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.390927791595459  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 2 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3903770446777344  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.492433071136475  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.5078)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.38968324661254883  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5078)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.38968324661254883  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 3 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39023399353027344  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.492790699005127  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.4446)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39023399353027344  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4446)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39023399353027344  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 4 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3898444175720215  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.491900444030762  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.3810)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3898444175720215  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3810)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3898444175720215  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 5 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39023399353027344  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.492713451385498  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.3164)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39026355743408203  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3164)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.39026355743408203  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 6 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3899235725402832  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.491979598999023  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.2505)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3898940086364746  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.2505)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3898940086364746  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 7 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3899197578430176  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.492369651794434  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.1837)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.38994932174682617  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1837)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.38994932174682617  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 8 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3904590606689453  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 11.492515087127686  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.1145)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3904294967651367  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1145)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6788330078125 GB
    Memory Allocated: 0.3904294967651367  GigaBytes
Max Memory Allocated: 12.907416343688965  GigaBytes


 Run 0| Epoch 9 |
