main start at this time 1670382679.985132
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.3663330078125 GB
    Memory Allocated: 0.31928539276123047  GigaBytes
Max Memory Allocated: 0.32073545455932617  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98315, 98316, 98317], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.0968017578125 GB
    Memory Allocated: 5.951788902282715  GigaBytes
Max Memory Allocated: 6.936248302459717  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3509)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.1065673828125 GB
    Memory Allocated: 0.37162065505981445  GigaBytes
Max Memory Allocated: 6.936248302459717  GigaBytes

v3.py : output nodes local nid:  tensor([98318, 98320, 98321, 98322, 98323, 98324, 98325, 98326, 98327, 98328],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.1065673828125 GB
    Memory Allocated: 0.37162065505981445  GigaBytes
Max Memory Allocated: 6.936248302459717  GigaBytes

core.py bucket local nid tensor([ 98318,  98320,  98321,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.4659423828125 GB
    Memory Allocated: 5.969638347625732  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3455)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 0.37162065505981445  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6964)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 0.3722958564758301  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes


 Run 0| Epoch 0 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.4678955078125 GB
    Memory Allocated: 0.37193870544433594  GigaBytes
Max Memory Allocated: 6.9885149002075195  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98292, 98293, 98294], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.970024585723877  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3180)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37193870544433594  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes

v3.py : output nodes local nid:  tensor([98295, 98296, 98297, 98298, 98299, 98300, 98301, 98302, 98303, 98304],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37193870544433594  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes

core.py bucket local nid tensor([ 98295,  98296,  98297,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969956398010254  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3156)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37193870544433594  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6336)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37193870544433594  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes


 Run 0| Epoch 1 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3720102310180664  GigaBytes
Max Memory Allocated: 6.988901615142822  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98306, 98307, 98308], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.970096111297607  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2861)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3720102310180664  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98309, 98310, 98311, 98312, 98313, 98314, 98315, 98316, 98317, 98318],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3720102310180664  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98309,  98310,  98311,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.970027923583984  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2842)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3720102310180664  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5703)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3720102310180664  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 2 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37174510955810547  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98303, 98304, 98305], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.9698309898376465  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2517)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37174510955810547  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98306, 98307, 98308, 98309, 98310, 98311, 98312, 98313, 98314, 98315],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37174510955810547  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98306,  98307,  98308,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969762802124023  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2561)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37174510955810547  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5078)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.37174510955810547  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 3 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719797134399414  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98293, 98294, 98295], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.970065593719482  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2240)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719797134399414  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98296, 98297, 98298, 98299, 98300, 98301, 98302, 98303, 98304, 98305],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719797134399414  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98296,  98297,  98298,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969997406005859  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2206)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719797134399414  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4446)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719797134399414  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 4 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719062805175781  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98292, 98293, 98294], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969992160797119  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1933)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719062805175781  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98295, 98296, 98297, 98298, 98299, 98300, 98301, 98302, 98303, 98305],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719062805175781  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98295,  98296,  98297,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969923973083496  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1877)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719062805175781  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3810)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719062805175781  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 5 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3718552589416504  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98232, 98233, 98234], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969941139221191  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1548)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3718552589416504  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98235, 98236, 98238, 98239, 98240, 98241, 98242, 98243, 98244, 98245],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3718552589416504  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98235,  98236,  98238,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969872951507568  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1616)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3718552589416504  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3164)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3718552589416504  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 6 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3715028762817383  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98255, 98256, 98257], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969588756561279  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1239)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3715028762817383  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98258, 98259, 98260, 98261, 98262, 98263, 98264, 98265, 98266, 98267],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3715028762817383  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98258,  98259,  98260,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969520568847656  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1266)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3715028762817383  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.2505)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3715028762817383  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 7 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719816207885742  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98362, 98363, 98364], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.970067501068115  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.0995)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719816207885742  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

v3.py : output nodes local nid:  tensor([98365, 98366, 98367, 98368, 98369, 98370, 98371, 98372, 98373, 98374],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719816207885742  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([ 98365,  98366,  98367,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.969999313354492  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.0842)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719816207885742  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1837)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.3719816207885742  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes


 Run 0| Epoch 8 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.372067928314209  GigaBytes
Max Memory Allocated: 6.988973140716553  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98231, 98232, 98233], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.97015380859375  GigaBytes
Max Memory Allocated: 6.989030838012695  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.0590)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.372067928314209  GigaBytes
Max Memory Allocated: 6.989030838012695  GigaBytes

v3.py : output nodes local nid:  tensor([98234, 98235, 98236, 98237, 98238, 98239, 98240, 98241, 98242, 98243],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.372067928314209  GigaBytes
Max Memory Allocated: 6.989030838012695  GigaBytes

core.py bucket local nid tensor([ 98234,  98235,  98236,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 5.970085620880127  GigaBytes
Max Memory Allocated: 6.989030838012695  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.0555)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.372067928314209  GigaBytes
Max Memory Allocated: 6.989030838012695  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1145)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.8272705078125 GB
    Memory Allocated: 0.372067928314209  GigaBytes
Max Memory Allocated: 6.989030838012695  GigaBytes


 Run 0| Epoch 9 |
