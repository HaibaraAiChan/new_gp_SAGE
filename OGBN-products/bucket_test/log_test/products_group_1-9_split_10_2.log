main start at this time 1670390306.8492677
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.4132080078125 GB
    Memory Allocated: 0.3182258605957031  GigaBytes
Max Memory Allocated: 0.3182387351989746  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 2.4268798828125 GB
    Memory Allocated: 0.5930228233337402  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0948)
----------------------------------------- after loss backward 
 Nvidia-smi: 2.4366455078125 GB
    Memory Allocated: 0.35370492935180664  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 2.4366455078125 GB
    Memory Allocated: 0.3547816276550293  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98315, 98316, 98317], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.2706298828125 GB
    Memory Allocated: 5.95286750793457  GigaBytes
Max Memory Allocated: 6.971744537353516  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3509)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.2706298828125 GB
    Memory Allocated: 0.37163782119750977  GigaBytes
Max Memory Allocated: 6.971744537353516  GigaBytes

v3.py : output nodes local nid:  tensor([98318, 98320, 98321, 98322, 98323, 98324, 98325, 98326, 98327, 98328],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.2706298828125 GB
    Memory Allocated: 0.37163782119750977  GigaBytes
Max Memory Allocated: 6.971744537353516  GigaBytes

core.py bucket local nid tensor([ 98318,  98320,  98321,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6300048828125 GB
    Memory Allocated: 5.969655513763428  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3455)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6300048828125 GB
    Memory Allocated: 0.37163782119750977  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.7912)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6300048828125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes


 Run 0| Epoch 0 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6300048828125 GB
    Memory Allocated: 0.37195587158203125  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.612335205078125  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0937)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3550996780395508  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3550996780395508  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98292, 98293, 98294], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953185558319092  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.3180)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37195587158203125  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

v3.py : output nodes local nid:  tensor([98295, 98296, 98297, 98298, 98299, 98300, 98301, 98302, 98303, 98304],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37195587158203125  GigaBytes
Max Memory Allocated: 6.988532066345215  GigaBytes

core.py bucket local nid tensor([ 98295,  98296,  98297,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.969973564147949  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.3156)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37195587158203125  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.7273)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37195587158203125  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes


 Run 0| Epoch 1 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3720273971557617  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6124067306518555  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0926)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35517120361328125  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35517120361328125  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98306, 98307, 98308], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953257083892822  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2861)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3720273971557617  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

v3.py : output nodes local nid:  tensor([98309, 98310, 98311, 98312, 98313, 98314, 98315, 98316, 98317, 98318],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3720273971557617  GigaBytes
Max Memory Allocated: 6.988850116729736  GigaBytes

core.py bucket local nid tensor([ 98309,  98310,  98311,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.97004508972168  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2843)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3720273971557617  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6630)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3720273971557617  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes


 Run 0| Epoch 2 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6126923561096191  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0915)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3554568290710449  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3554568290710449  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98303, 98304, 98305], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953542709350586  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2518)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

v3.py : output nodes local nid:  tensor([98306, 98307, 98308, 98309, 98310, 98311, 98312, 98313, 98314, 98315],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.988921642303467  GigaBytes

core.py bucket local nid tensor([ 98306,  98307,  98308,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.970330715179443  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2562)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5995)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 3 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3719968795776367  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6123762130737305  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0904)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35514068603515625  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35514068603515625  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98293, 98294, 98295], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953226566314697  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.2241)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3719968795776367  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([98296, 98297, 98298, 98299, 98300, 98301, 98302, 98303, 98304, 98305],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3719968795776367  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([ 98296,  98297,  98298,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.970014572143555  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.2207)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3719968795776367  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5352)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3719968795776367  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 4 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37192344665527344  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6123027801513672  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0893)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35506725311279297  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35506725311279297  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98292, 98293, 98294], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953153133392334  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1934)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37192344665527344  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([98295, 98296, 98297, 98298, 98299, 98300, 98301, 98302, 98303, 98305],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37192344665527344  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([ 98295,  98296,  98297,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.969941139221191  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1878)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37192344665527344  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4706)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37192344665527344  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 5 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6126923561096191  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0882)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3554568290710449  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3554568290710449  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98232, 98233, 98234], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953542709350586  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1550)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([98235, 98236, 98238, 98239, 98240, 98241, 98242, 98243, 98244, 98245],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([ 98235,  98236,  98238,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.970330715179443  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1618)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4050)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 6 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3715200424194336  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6118993759155273  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0871)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3546638488769531  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3546638488769531  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98255, 98256, 98257], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.952749729156494  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.1241)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3715200424194336  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([98258, 98259, 98260, 98261, 98262, 98263, 98264, 98265, 98266, 98267],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3715200424194336  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([ 98258,  98259,  98260,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.969537734985352  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.1268)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3715200424194336  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3380)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3715200424194336  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 7 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37199878692626953  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6123781204223633  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0859)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35514259338378906  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.35514259338378906  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98362, 98363, 98364], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.95322847366333  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.0998)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37199878692626953  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([98365, 98366, 98367, 98368, 98369, 98370, 98371, 98372, 98373, 98374],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37199878692626953  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([ 98365,  98366,  98367,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.9700164794921875  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.0844)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37199878692626953  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.2701)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.37199878692626953  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 8 |
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.6126923561096191  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0848)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3554568290710449  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3554568290710449  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([    0,     1,     2,  ..., 98231, 98232, 98233], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96305
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.953542709350586  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96305 ratio: 0.48992476001037794 bucket_loss : tensor(2.0593)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

v3.py : output nodes local nid:  tensor([98234, 98235, 98236, 98237, 98238, 98239, 98240, 98241, 98242, 98243],
       device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

core.py bucket local nid tensor([ 98234,  98235,  98236,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 96304
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 5.970330715179443  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

degree: tensor(10) # of output: 96304 ratio: 0.4899196727899843 bucket_loss : tensor(2.0559)
----------------------------------------- after loss backward 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1999)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 8.6319580078125 GB
    Memory Allocated: 0.3723130226135254  GigaBytes
Max Memory Allocated: 6.9892072677612305  GigaBytes


 Run 0| Epoch 9 |
