main start at this time 1670376110.717918
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

karate data
{}
{}
Graph(num_nodes=7, num_edges=14,
      ndata_schemes={'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(4,), dtype=torch.float32)}
      edata_schemes={})
#nodes: 7
#edges: 14
#classes: 2
success----------------------------------------
4
2
1
# Nodes: 7
# Edges: 14
# Train: 4
# Val: 2
# Test: 1
# Classes: 2

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  4
{1: 1, 2: 3}
blocks[-1].dstdata[_ID] tensor([2, 0, 1, 3], device='cuda:0')
blocks[-1].dstdata[_ID] torch.return_types.sort(
values=tensor([0, 1, 2, 3], device='cuda:0'),
indices=tensor([1, 2, 0, 3], device='cuda:0'))
v3.py : output nodes local nid:  tensor([0, 2, 3], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([2, 1, 3], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 0.9971923828125 GB
    Memory Allocated: 5.7220458984375e-06  GigaBytes
Max Memory Allocated: 6.67572021484375e-06  GigaBytes

core.py bucket local nid tensor([0, 2, 3], device='cuda:0')
the length of bkt_idx in core.py _bucketing 3
core.py : node_bkt local nid:  tensor([0, 2, 3], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0538330078125 GB
    Memory Allocated: 1.430511474609375e-05  GigaBytes
Max Memory Allocated: 1.7642974853515625e-05  GigaBytes

degree: tensor(2) # of output: 3 ratio: 0.75 bucket_loss : tensor(1.0148)
----------------------------------------- after loss backward 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.049041748046875e-05  GigaBytes
Max Memory Allocated: 2.002716064453125e-05  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(1.0148)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.002716064453125e-05  GigaBytes


 Run 0| Epoch 0 |
{1: 1, 2: 3}
blocks[-1].dstdata[_ID] tensor([1, 3, 2, 0], device='cuda:0')
blocks[-1].dstdata[_ID] torch.return_types.sort(
values=tensor([0, 1, 2, 3], device='cuda:0'),
indices=tensor([3, 0, 2, 1], device='cuda:0'))
v3.py : output nodes local nid:  tensor([0, 1, 2], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([1, 3, 2], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.002716064453125e-05  GigaBytes

core.py bucket local nid tensor([0, 1, 2], device='cuda:0')
the length of bkt_idx in core.py _bucketing 3
core.py : node_bkt local nid:  tensor([0, 1, 2], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 2.4318695068359375e-05  GigaBytes
Max Memory Allocated: 2.8133392333984375e-05  GigaBytes

degree: tensor(2) # of output: 3 ratio: 0.75 bucket_loss : tensor(1.0091)
----------------------------------------- after loss backward 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(1.0091)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes


 Run 0| Epoch 1 |
{1: 1, 2: 3}
blocks[-1].dstdata[_ID] tensor([1, 2, 3, 0], device='cuda:0')
blocks[-1].dstdata[_ID] torch.return_types.sort(
values=tensor([0, 1, 2, 3], device='cuda:0'),
indices=tensor([3, 0, 1, 2], device='cuda:0'))
v3.py : output nodes local nid:  tensor([0, 1, 2], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([1, 2, 3], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

core.py bucket local nid tensor([0, 1, 2], device='cuda:0')
the length of bkt_idx in core.py _bucketing 3
core.py : node_bkt local nid:  tensor([0, 1, 2], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 2.4318695068359375e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

degree: tensor(2) # of output: 3 ratio: 0.75 bucket_loss : tensor(1.0065)
----------------------------------------- after loss backward 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(1.0065)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes


 Run 0| Epoch 2 |
{1: 1, 2: 3}
blocks[-1].dstdata[_ID] tensor([0, 3, 2, 1], device='cuda:0')
blocks[-1].dstdata[_ID] torch.return_types.sort(
values=tensor([0, 1, 2, 3], device='cuda:0'),
indices=tensor([0, 3, 2, 1], device='cuda:0'))
v3.py : output nodes local nid:  tensor([1, 2, 3], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([3, 2, 1], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

core.py bucket local nid tensor([1, 2, 3], device='cuda:0')
the length of bkt_idx in core.py _bucketing 3
core.py : node_bkt local nid:  tensor([1, 2, 3], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 2.4318695068359375e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

degree: tensor(2) # of output: 3 ratio: 0.75 bucket_loss : tensor(0.9998)
----------------------------------------- after loss backward 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(0.9998)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes


 Run 0| Epoch 3 |
{1: 1, 2: 3}
blocks[-1].dstdata[_ID] tensor([3, 0, 2, 1], device='cuda:0')
blocks[-1].dstdata[_ID] torch.return_types.sort(
values=tensor([0, 1, 2, 3], device='cuda:0'),
indices=tensor([1, 3, 2, 0], device='cuda:0'))
v3.py : output nodes local nid:  tensor([0, 2, 3], device='cuda:0', dtype=torch.int32)
v3.py : output nodes global nid:  tensor([3, 2, 1], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

core.py bucket local nid tensor([0, 2, 3], device='cuda:0')
the length of bkt_idx in core.py _bucketing 3
core.py : node_bkt local nid:  tensor([0, 2, 3], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 2.4318695068359375e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

degree: tensor(2) # of output: 3 ratio: 0.75 bucket_loss : tensor(0.9991)
----------------------------------------- after loss backward 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(0.9991)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 1.0616455078125 GB
    Memory Allocated: 1.621246337890625e-05  GigaBytes
Max Memory Allocated: 2.86102294921875e-05  GigaBytes


 Run 0| Epoch 4 |
