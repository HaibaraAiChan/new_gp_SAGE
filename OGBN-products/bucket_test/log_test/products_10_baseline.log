main start at this time 1669667351.8850517
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([130185, 134544, 131319, 134356, 134512, 130186, 130174, 134543, 130354,
        131534], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([ 82910, 130045,  47925, 174275, 176347,  64092,   2998,  14770,  80948,
        147379], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.4210205078125 GB
    Memory Allocated: 0.3203616142272949  GigaBytes
Max Memory Allocated: 0.3203616142272949  GigaBytes

core.py : output nodes global nid:  tensor([142928, 165022,  70663,  82506,  33441,  50729,  71803, 175954, 106779,
        146894], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 13.9600830078125 GB
    Memory Allocated: 11.456776142120361  GigaBytes
Max Memory Allocated: 12.836880207061768  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.6964)
----------------------------------------- after loss backward 
 Nvidia-smi: 13.9678955078125 GB
    Memory Allocated: 0.3917412757873535  GigaBytes
Max Memory Allocated: 12.836880207061768  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6964)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 13.9678955078125 GB
    Memory Allocated: 0.39241647720336914  GigaBytes
Max Memory Allocated: 12.836880207061768  GigaBytes


 Run 0| Epoch 0 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([131453, 130605, 130638, 130639, 131452, 130600, 130211, 131497, 130597,
        130575], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([ 85594,  64796,  43905, 174846,  44027,  94274,   6635, 123804, 191519,
         99342], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 13.9678955078125 GB
    Memory Allocated: 0.390594482421875  GigaBytes
Max Memory Allocated: 12.836880207061768  GigaBytes

core.py : output nodes global nid:  tensor([ 38125,  64477, 116569, 165766, 100350,  87624, 187402, 142538,  93040,
         87818], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.492591381072998  GigaBytes
Max Memory Allocated: 12.906599998474121  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.6336)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39275312423706055  GigaBytes
Max Memory Allocated: 12.906599998474121  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6336)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39275312423706055  GigaBytes
Max Memory Allocated: 12.906599998474121  GigaBytes


 Run 0| Epoch 1 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([130698, 130428, 130429, 130697, 130700, 130699, 130701, 130427, 130409,
        130677], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([ 58830,  78083,  33872,  54223,  41565, 149776,  26583,  47478, 132306,
        141691], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3916454315185547  GigaBytes
Max Memory Allocated: 12.906599998474121  GigaBytes

core.py : output nodes global nid:  tensor([185562, 178226, 133156,  52180,  94009, 181947, 158023,  14313,  32828,
        168770], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.493642330169678  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.5703)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3931102752685547  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5703)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3931102752685547  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 2 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([130503, 130465, 130403, 130523, 130516, 130467, 131481, 131547, 131503,
        130517], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([164711,  89544,   3882, 101283, 119163, 163754, 123521,  77382, 181476,
        185964], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3910946846008301  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([132943, 147509,  30629,   6151,  28732, 101524, 179002, 109180, 117450,
        151594], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.493091583251953  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.5078)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39186573028564453  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5078)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39186573028564453  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 3 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([130182, 131407, 130199, 131408, 131665, 130307, 131640, 131624, 131623,
        130320], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([183840,  14224, 178868, 182117, 108296,   9554, 132128, 131441,  32212,
        133940], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39095163345336914  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([136708, 167585,  80378,  14694, 135792, 193887,  87514, 107903,   4410,
         91084], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.492948532104492  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.4446)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39241647720336914  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4446)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39241647720336914  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 4 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([131375, 131534, 131428, 131693, 131376, 131427, 131384, 131414, 131535,
        131413], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([ 74719,  53417,  76261,  60432, 147978,  65580, 183923,  87835,  55561,
          9022], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3905620574951172  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([169792, 170500,  94941, 148501, 149790,  47238, 135800, 117415,  24497,
        150330], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.49255895614624  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.3810)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3920269012451172  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3810)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3920269012451172  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 5 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([131852, 130651, 124716, 132314, 131847, 124631, 130570, 125015, 131903,
        130569], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([192459,   3209, 166394, 159980, 157265, 178441,  21658,  11744, 157259,
         99169], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39095163345336914  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([ 51802, 103403, 142529,  62736, 193509,  38861,  72809,  94198, 122978,
        193765], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.492948532104492  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.3164)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39241647720336914  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3164)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.39241647720336914  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 6 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([132022, 132038, 132027, 125003, 132026, 132025, 132024, 132023, 132035,
        131975], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([125129, 193044,  32931,  95032,  10202, 134120,  82082,  32255, 120242,
         94564], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3906412124633789  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([ 58092, 105281,  21091, 101410,  18010,  23599,  67383,  80535, 150840,
         19171], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.492638111114502  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.2505)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3921060562133789  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.2505)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3921060562133789  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 7 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([131724, 131758, 131847, 131759, 131915, 131740, 131908, 131830, 131910,
        131805], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([150283,  95513,  97646, 111619, 104810,  91187,  82020, 118824, 171295,
        128798], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3906373977661133  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([ 41397, 113839, 168800, 153860,   7679, 109485,  71059, 125115, 112870,
         15472], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.492634296417236  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.1837)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3921022415161133  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1837)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3921022415161133  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 8 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
main.py output local:  tensor([131459, 131449, 131458, 131460, 131167, 134335, 131445, 131444, 131443,
        134334], device='cuda:0', dtype=torch.int32)
main.py bucket_outputs_global:  tensor([157639,  41825,  11962, 133176, 108292,  71690, 137059,  51115,  78111,
        144168], device='cuda:0')
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3912062644958496  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

core.py : output nodes global nid:  tensor([170531, 121455, 120101,  90778, 120409,  99087, 190662, 192401,  68941,
          7949], device='cuda:0', dtype=torch.int32)
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 11.493203163146973  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

degree: 10 # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.1145)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3926711082458496  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1145)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.6885986328125 GB
    Memory Allocated: 0.3926711082458496  GigaBytes
Max Memory Allocated: 12.908164024353027  GigaBytes


 Run 0| Epoch 9 |
