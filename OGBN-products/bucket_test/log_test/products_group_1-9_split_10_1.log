main start at this time 1670390023.7171192
-----------------------------------------before load data 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

#nodes: 2449029
#edges: 123718024
#classes: 47
success----------------------------------------
196571
39255
2164782
# Nodes: 2400608
# Edges: 123718024
# Train: 196571
# Val: 39255
# Test: 2164782
# Classes: 47

----------------------------------------start of run function 
 Nvidia-smi: 0.2530517578125 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

in feats:  100
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 1.4132080078125 GB
    Memory Allocated: 0.3182258605957031  GigaBytes
Max Memory Allocated: 0.3182387351989746  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 2.4268798828125 GB
    Memory Allocated: 0.5930228233337402  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0948)
----------------------------------------- after loss backward 
 Nvidia-smi: 2.4366455078125 GB
    Memory Allocated: 0.35370492935180664  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 2.4366455078125 GB
    Memory Allocated: 0.35514020919799805  GigaBytes
Max Memory Allocated: 1.3277521133422852  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.1495361328125 GB
    Memory Allocated: 11.456683158874512  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.6964)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.1495361328125 GB
    Memory Allocated: 0.3895759582519531  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.7912)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.1495361328125 GB
    Memory Allocated: 0.39025115966796875  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes


 Run 0| Epoch 0 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.1495361328125 GB
    Memory Allocated: 0.3904242515563965  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.1514892578125 GB
    Memory Allocated: 0.6308035850524902  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0937)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.1534423828125 GB
    Memory Allocated: 0.3559885025024414  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.1534423828125 GB
    Memory Allocated: 0.3559885025024414  GigaBytes
Max Memory Allocated: 12.871115684509277  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.457531452178955  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.6336)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3904242515563965  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.7273)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3904242515563965  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes


 Run 0| Epoch 1 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39025115966796875  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6306304931640625  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0926)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.35581541061401367  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.35581541061401367  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.457358360290527  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.5704)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39025115966796875  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.6630)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39025115966796875  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes


 Run 0| Epoch 2 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.38970041275024414  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6302852630615234  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0915)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.35526466369628906  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.35526466369628906  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.45732069015503  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.5080)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.38970041275024414  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5995)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.38970041275024414  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes


 Run 0| Epoch 3 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3899350166320801  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6303143501281738  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0904)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.355499267578125  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.355499267578125  GigaBytes
Max Memory Allocated: 12.871450901031494  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.457555294036865  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.4448)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3906288146972656  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.5352)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3906288146972656  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes


 Run 0| Epoch 4 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39055538177490234  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6311402320861816  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0893)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3554258346557617  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3554258346557617  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.456909656524658  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.3813)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3898615837097168  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4706)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3898615837097168  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes


 Run 0| Epoch 5 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.38981056213378906  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6303954124450684  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0882)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.355374813079834  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.355374813079834  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.456917762756348  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.3168)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.38981056213378906  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.4050)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.38981056213378906  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes


 Run 0| Epoch 6 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3898615837097168  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6304464340209961  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0871)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3554258346557617  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3554258346557617  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.456939220428467  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.2510)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39055538177490234  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.3380)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39055538177490234  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes


 Run 0| Epoch 7 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39063072204589844  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6312155723571777  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0859)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3555011749267578  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3555011749267578  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.457044124603271  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.1842)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3899369239807129  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.2701)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3899369239807129  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes


 Run 0| Epoch 8 |
{1: 173, 2: 221, 3: 374, 4: 456, 5: 445, 6: 550, 7: 655, 8: 512, 9: 576, 10: 192609}
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.39025115966796875  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.6306304931640625  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32) # of output: 3962 ratio: 0.02015556719963779 bucket_loss : tensor(0.0848)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.35581541061401367  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

v3.py : output nodes local nid:  tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0', dtype=torch.int32)
----------------------------------------- before batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.35581541061401367  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

core.py bucket local nid tensor([     0,      1,      2,  ..., 196568, 196569, 196570], device='cuda:0')
the length of bkt_idx in core.py _bucketing 192609
----------------------------------------- after batch_pred = model(blocks, batch_inputs, deg.to(device)) 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 11.45785903930664  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

degree: tensor(10) # of output: 192609 ratio: 0.9798444328003623 bucket_loss : tensor(4.1151)
----------------------------------------- after loss backward 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3909449577331543  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes

-------------------------------------------------------loss_sum  :  tensor(4.1999)
----------------------------------------- after optimizer.zero_grad() 
 Nvidia-smi: 14.8721923828125 GB
    Memory Allocated: 0.3909449577331543  GigaBytes
Max Memory Allocated: 12.871474742889404  GigaBytes


 Run 0| Epoch 9 |
