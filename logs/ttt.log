main start at this time 1649895194.4457521
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

karate data
{}
{}
#nodes: 6
#edges: 13
#classes: 2
success----------------------------------------
4
1
1
# Nodes: 6
# Edges: 13
# Train: 4
# Val: 1
# Test: 1
# Classes: 2

in feats:  4
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0005083084106445312  GigaBytes
Max Memory Allocated: 0.0005083084106445312  GigaBytes

tensor(indices=tensor([[0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 1, 5],
                       [1, 0, 2, 3, 4, 1, 3, 4, 2, 4, 3, 5, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=13, layout=torch.sparse_coo)
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=6, num_dst_nodes=6, num_edges=10), Block(num_src_nodes=6, num_dst_nodes=6, num_edges=13), Block(num_src_nodes=6, num_dst_nodes=4, num_edges=9)]
global src and dst nids
tensor([2, 3, 0, 1, 4, 5])
tensor([2, 3, 0, 1, 4, 5])
global src and dst nids
tensor([2, 3, 0, 1, 4, 5])
tensor([2, 3, 0, 1, 4, 5])
global src and dst nids
tensor([2, 3, 0, 1, 4, 5])
tensor([2, 3, 0, 1])
full batch blocks first block 
(tensor([3, 1, 3, 4, 3, 2, 5, 3, 1, 3]), tensor([0, 0, 1, 1, 2, 3, 3, 4, 4, 5]))
full batch blocks last block 
(tensor([3, 1, 3, 0, 4, 3, 2, 0, 5]), tensor([0, 0, 1, 1, 1, 2, 3, 3, 3]))
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.018185853958129883
src global
[2, 3, 0, 1, 4, 5]
dst local
[0, 1, 2, 3]
global_2_local spend time (sec) 2.956390380859375e-05
----------------------------  graph partition start---------------------
remove
[4, 5]
  (1, 0)	1
  (2, 0)	1
  (0, 1)	1
  (2, 1)	1
  (3, 1)	1
  (0, 2)	1
  (1, 2)	1
  (1, 3)	1
   source  target  weight  capacity
0       1       0       1         1
1       2       0       1         1
2       0       1       1         1
3       2       1       1         1
4       3       1       1         1
5       0       2       1         1
6       1       2       1         1
7       1       3       1         1

1
({0, 1, 2}, {3})
after graph partition
graph partition algorithm spend time 0.07568120956420898
-----------------------------------------------global batched output nodes id----------------------------
[0, 2, 3]
[1]
partition_len_list
[5, 4]
shared_neighbor_graph_partition selection method range initialization spend 0.0759434700012207
time for parepare:  7.3909759521484375e-06
local_output_nid generation:  1.9073486328125e-06
local_in_edges_tensor generation:  0.00014781951904296875
mini_batch_src_global generation:  4.6253204345703125e-05
r_  generation:  0.0012462139129638672
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.00015234947204589844
mini_batch_src_global generation:  2.47955322265625e-05
r_  generation:  1.71661376953125e-05
----------------------check_connections_block total spend ----------------------------- 0.0018389225006103516
generate_one_block  0.003289461135864258
generate_one_block  0.0014865398406982422
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0005693435668945312
gen group dst list time:  2.5272369384765625e-05
time for parepare:  5.0067901611328125e-06
local_output_nid generation:  2.384185791015625e-06
local_in_edges_tensor generation:  0.04779362678527832
mini_batch_src_global generation:  2.7894973754882812e-05
r_  generation:  3.0040740966796875e-05
local_output_nid generation:  1.9073486328125e-06
local_in_edges_tensor generation:  0.0001480579376220703
mini_batch_src_global generation:  1.811981201171875e-05
r_  generation:  1.7642974853515625e-05
----------------------check_connections_block total spend ----------------------------- 0.04819846153259277
generate_one_block  0.0014636516571044922
generate_one_block  0.0013086795806884766
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0004942417144775391
gen group dst list time:  2.1696090698242188e-05
time for parepare:  4.291534423828125e-06
local_output_nid generation:  2.1457672119140625e-06
local_in_edges_tensor generation:  0.03201746940612793
mini_batch_src_global generation:  4.744529724121094e-05
r_  generation:  4.38690185546875e-05
local_output_nid generation:  3.814697265625e-06
local_in_edges_tensor generation:  0.00025010108947753906
mini_batch_src_global generation:  3.409385681152344e-05
r_  generation:  3.409385681152344e-05
----------------------check_connections_block total spend ----------------------------- 0.03264260292053223
generate_one_block  0.002376079559326172
generate_one_block  0.0023491382598876953
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0005083084106445312  GigaBytes
Max Memory Allocated: 0.0005083084106445312  GigaBytes

connection checking time:  0.080841064453125
block generation total time  0.007497549057006836
average batch blocks generation time:  0.003748774528503418
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.0819091796875 GB
    Memory Allocated: 0.0005121231079101562  GigaBytes
Max Memory Allocated: 0.0005121231079101562  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.0819091796875 GB
    Memory Allocated: 0.0005121231079101562  GigaBytes
Max Memory Allocated: 0.0005121231079101562  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005254745483398438  GigaBytes
Max Memory Allocated: 0.0005311965942382812  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005197525024414062  GigaBytes
Max Memory Allocated: 0.0005311965942382812  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 10
input nodes : tensor([2, 3, 0, 1, 4], device='cuda:0')
output nodes : tensor([2, 3, 0], device='cuda:0')
edges number: (tensor([3, 1, 3, 0, 4, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1, 1, 1, 2], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005292892456054688  GigaBytes
Max Memory Allocated: 0.0005311965942382812  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005350112915039062  GigaBytes
Max Memory Allocated: 0.0005350112915039062  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005364418029785156  GigaBytes
Max Memory Allocated: 0.0005421638488769531  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005364418029785156  GigaBytes
Max Memory Allocated: 0.0005421638488769531  GigaBytes

torch.Size([6, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005526542663574219  GigaBytes
Max Memory Allocated: 0.0005574226379394531  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005478858947753906  GigaBytes
Max Memory Allocated: 0.0005574226379394531  GigaBytes

torch.Size([5, 256])
input nodes number: 6
output nodes number: 5
edges number: 12
input nodes : tensor([2, 3, 0, 1, 4], device='cuda:0')
output nodes : tensor([2, 3, 0], device='cuda:0')
edges number: (tensor([3, 1, 3, 0, 4, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1, 1, 1, 2], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005555152893066406  GigaBytes
Max Memory Allocated: 0.0005574226379394531  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005602836608886719  GigaBytes
Max Memory Allocated: 0.0005602836608886719  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005617141723632812  GigaBytes
Max Memory Allocated: 0.0005664825439453125  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005674362182617188  GigaBytes
Max Memory Allocated: 0.0005693435668945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005669593811035156  GigaBytes
Max Memory Allocated: 0.0005693435668945312  GigaBytes

torch.Size([3, 2])
input nodes number: 5
output nodes number: 3
edges number: 6
input nodes : tensor([2, 3, 0, 1, 4], device='cuda:0')
output nodes : tensor([2, 3, 0], device='cuda:0')
edges number: (tensor([3, 1, 3, 0, 4, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1, 1, 1, 2], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005674362182617188  GigaBytes
Max Memory Allocated: 0.0005693435668945312  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010170936584472656  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010170936584472656  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010285377502441406  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010237693786621094  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

torch.Size([5, 256])
input nodes number: 6
output nodes number: 5
edges number: 8
input nodes : tensor([1, 0, 2, 5], device='cuda:0')
output nodes : tensor([1], device='cuda:0')
edges number: (tensor([1, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010323524475097656  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010371208190917969  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010385513305664062  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010385513305664062  GigaBytes
Max Memory Allocated: 0.0010509490966796875  GigaBytes

torch.Size([5, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010519027709960938  GigaBytes
Max Memory Allocated: 0.0010557174682617188  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010480880737304688  GigaBytes
Max Memory Allocated: 0.0010557174682617188  GigaBytes

torch.Size([4, 256])
input nodes number: 5
output nodes number: 4
edges number: 7
input nodes : tensor([1, 0, 2, 5], device='cuda:0')
output nodes : tensor([1], device='cuda:0')
edges number: (tensor([1, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010547637939453125  GigaBytes
Max Memory Allocated: 0.0010557174682617188  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010585784912109375  GigaBytes
Max Memory Allocated: 0.0010585784912109375  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010595321655273438  GigaBytes
Max Memory Allocated: 0.0010633468627929688  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010633468627929688  GigaBytes
Max Memory Allocated: 0.0010638236999511719  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010628700256347656  GigaBytes
Max Memory Allocated: 0.0010638236999511719  GigaBytes

torch.Size([1, 2])
input nodes number: 4
output nodes number: 1
edges number: 3
input nodes : tensor([1, 0, 2, 5], device='cuda:0')
output nodes : tensor([1], device='cuda:0')
edges number: (tensor([1, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010628700256347656  GigaBytes
Max Memory Allocated: 0.0010638236999511719  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0002770423889160156 |0.18146133422851562 |0.3927640914916992 |0.0001500844955444336 |0.004598259925842285 |0.0023088455200195312 |
----------------------------------------------------------pseudo_mini_loss sum 1.2110977172851562
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  32
Number of first layer input nodes during this epoch:  12
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002033710479736328  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

tensor(indices=tensor([[0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 1, 5],
                       [1, 0, 2, 3, 4, 1, 3, 4, 2, 4, 3, 5, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=13, layout=torch.sparse_coo)
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=6, num_dst_nodes=6, num_edges=10), Block(num_src_nodes=6, num_dst_nodes=6, num_edges=13), Block(num_src_nodes=6, num_dst_nodes=4, num_edges=9)]
global src and dst nids
tensor([1, 3, 0, 2, 5, 4])
tensor([1, 3, 0, 2, 5, 4])
global src and dst nids
tensor([1, 3, 0, 2, 5, 4])
tensor([1, 3, 0, 2, 5, 4])
global src and dst nids
tensor([1, 3, 0, 2, 5, 4])
tensor([1, 3, 0, 2])
full batch blocks first block 
(tensor([2, 4, 5, 0, 0, 0, 1, 0, 0, 1]), tensor([0, 0, 1, 1, 2, 3, 3, 4, 5, 5]))
full batch blocks last block 
(tensor([2, 3, 4, 0, 3, 5, 0, 0, 1]), tensor([0, 0, 0, 1, 1, 1, 2, 3, 3]))
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0020482540130615234
src global
[1, 3, 0, 2, 5, 4]
dst local
[0, 1, 2, 3]
global_2_local spend time (sec) 3.552436828613281e-05
----------------------------  graph partition start---------------------
remove
[4, 5]
  (1, 0)	1
  (0, 1)	1
  (2, 1)	1
  (3, 1)	1
  (1, 2)	1
  (3, 2)	1
  (1, 3)	1
  (2, 3)	1
   source  target  weight  capacity
0       1       0       1         1
1       0       1       1         1
2       2       1       1         1
3       3       1       1         1
4       1       2       1         1
5       3       2       1         1
6       1       3       1         1
7       2       3       1         1

1
({0}, {1, 2, 3})
after graph partition
graph partition algorithm spend time 0.04757237434387207
-----------------------------------------------global batched output nodes id----------------------------
[1]
[0, 2, 3]
partition_len_list
[4, 5]
shared_neighbor_graph_partition selection method range initialization spend 0.04783892631530762
time for parepare:  7.152557373046875e-06
local_output_nid generation:  1.430511474609375e-06
local_in_edges_tensor generation:  0.00014519691467285156
mini_batch_src_global generation:  4.553794860839844e-05
r_  generation:  4.458427429199219e-05
local_output_nid generation:  1.9073486328125e-06
local_in_edges_tensor generation:  0.00013756752014160156
mini_batch_src_global generation:  2.0265579223632812e-05
r_  generation:  2.384185791015625e-05
----------------------check_connections_block total spend ----------------------------- 0.0005853176116943359
generate_one_block  0.003069639205932617
generate_one_block  0.0014977455139160156
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0006840229034423828
gen group dst list time:  3.0994415283203125e-05
time for parepare:  6.198883056640625e-06
local_output_nid generation:  2.86102294921875e-06
local_in_edges_tensor generation:  0.0314180850982666
mini_batch_src_global generation:  2.2649765014648438e-05
r_  generation:  2.09808349609375e-05
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.00011658668518066406
mini_batch_src_global generation:  1.5497207641601562e-05
r_  generation:  1.7881393432617188e-05
----------------------check_connections_block total spend ----------------------------- 0.03173351287841797
generate_one_block  0.0011298656463623047
generate_one_block  0.0011293888092041016
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0004220008850097656
gen group dst list time:  2.09808349609375e-05
time for parepare:  3.337860107421875e-06
local_output_nid generation:  3.5762786865234375e-06
local_in_edges_tensor generation:  0.030410289764404297
mini_batch_src_global generation:  2.5987625122070312e-05
r_  generation:  2.2649765014648438e-05
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.0001232624053955078
mini_batch_src_global generation:  1.5497207641601562e-05
r_  generation:  1.6689300537109375e-05
----------------------check_connections_block total spend ----------------------------- 0.030736207962036133
generate_one_block  0.001310110092163086
generate_one_block  0.00112152099609375
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002033710479736328  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

connection checking time:  0.0624697208404541
block generation total time  0.004690885543823242
average batch blocks generation time:  0.002345442771911621
block dataloader generation time/epoch 0.8637120723724365
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020232200622558594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020232200622558594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020346641540527344  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002029895782470703  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([5, 256])
input nodes number: 6
output nodes number: 5
edges number: 8
input nodes : tensor([1, 0, 2, 5], device='cuda:0')
output nodes : tensor([1], device='cuda:0')
edges number: (tensor([1, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020384788513183594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020432472229003906  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002044677734375  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002044677734375  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([5, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020580291748046875  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020542144775390625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([4, 256])
input nodes number: 5
output nodes number: 4
edges number: 7
input nodes : tensor([1, 0, 2, 5], device='cuda:0')
output nodes : tensor([1], device='cuda:0')
edges number: (tensor([1, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020608901977539062  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020647048950195312  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020656585693359375  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020694732666015625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020689964294433594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([1, 2])
input nodes number: 4
output nodes number: 1
edges number: 3
input nodes : tensor([1, 0, 2, 5], device='cuda:0')
output nodes : tensor([1], device='cuda:0')
edges number: (tensor([1, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020689964294433594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020241737365722656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020241737365722656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002037525177001953  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020318031311035156  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 10
input nodes : tensor([3, 0, 2, 1, 4], device='cuda:0')
output nodes : tensor([3, 0, 2], device='cuda:0')
edges number: (tensor([3, 2, 4, 3, 3, 0], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 2, 2], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002041339874267578  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020470619201660156  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002048492431640625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002048492431640625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020647048950195312  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020599365234375  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([5, 256])
input nodes number: 6
output nodes number: 5
edges number: 12
input nodes : tensor([3, 0, 2, 1, 4], device='cuda:0')
output nodes : tensor([3, 0, 2], device='cuda:0')
edges number: (tensor([3, 2, 4, 3, 3, 0], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 2, 2], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.00206756591796875  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020723342895507812  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020737648010253906  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002079486846923828  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002079010009765625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([3, 2])
input nodes number: 5
output nodes number: 3
edges number: 6
input nodes : tensor([3, 0, 2, 1, 4], device='cuda:0')
output nodes : tensor([3, 0, 2], device='cuda:0')
edges number: (tensor([3, 2, 4, 3, 3, 0], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 2, 2], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002079010009765625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00013387203216552734 |0.0003902912139892578 |0.011438131332397461 |9.036064147949219e-05 |0.0027960538864135742 |0.002697467803955078 |
----------------------------------------------------------pseudo_mini_loss sum 0.017363930121064186
Total (block generation + training)time/epoch 0.8985910415649414
Training time/epoch 0.03469061851501465
Training time without block to device /epoch 0.03391003608703613
Training time without total dataloading part /epoch 0.03134655952453613
load block tensor time/epoch 0.0002677440643310547
block to device time/epoch 0.0007805824279785156
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  32
Number of first layer input nodes during this epoch:  12
