main start at this time 1649981573.092082
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

karate data
{}
{}
#nodes: 6
#edges: 13
#classes: 2
success----------------------------------------
4
1
1
# Nodes: 6
# Edges: 13
# Train: 4
# Val: 1
# Test: 1
# Classes: 2

in feats:  4
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0005083084106445312  GigaBytes
Max Memory Allocated: 0.0005083084106445312  GigaBytes

tensor(indices=tensor([[0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 1, 5],
                       [1, 0, 2, 3, 4, 1, 3, 4, 2, 4, 3, 5, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=13, layout=torch.sparse_coo)
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=6, num_dst_nodes=6, num_edges=10), Block(num_src_nodes=6, num_dst_nodes=6, num_edges=13), Block(num_src_nodes=6, num_dst_nodes=4, num_edges=9)]
global src and dst nids
tensor([2, 3, 0, 1, 4, 5])
tensor([2, 3, 0, 1, 4, 5])
global src and dst nids
tensor([2, 3, 0, 1, 4, 5])
tensor([2, 3, 0, 1, 4, 5])
global src and dst nids
tensor([2, 3, 0, 1, 4, 5])
tensor([2, 3, 0, 1])
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.0024852752685546875
src global
[2, 3, 0, 1, 4, 5]
dst local
[0, 1, 2, 3]
global_2_local spend time (sec) 3.981590270996094e-05
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0007948875427246094
A = g.adjacency_matrix() spent  0.00030350685119628906
tensor(indices=tensor([[3, 1, 3, 0, 4, 3, 2, 0, 5],
                       [0, 0, 1, 1, 1, 2, 3, 3, 3]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=9, layout=torch.sparse_coo)
tensor(indices=tensor([[0, 0, 1, 1, 1, 2, 3, 3, 3],
                       [3, 1, 3, 0, 4, 3, 2, 0, 5]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=9, layout=torch.sparse_coo)
[[0, 0, 1, 1, 1, 2, 3, 3, 3], [3, 1, 3, 0, 4, 3, 2, 0, 5]]
[[3, 1, 3, 0, 4, 3, 2, 0, 5], [0, 0, 1, 1, 1, 2, 3, 3, 3]]
get remove nodes spent  0.00021195411682128906
remove nodes length
2
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.001 seconds
self.weighted_graph_bipart() spend  0.05450940132141113
after graph partition
graph partition algorithm spend time 0.09637451171875
[1, 3]
[1, 3]
partition_len_list
[6, 6]
shared_neighbor_graph_partition selection method range initialization spend 0.09661364555358887
time for parepare:  4.291534423828125e-06
local_output_nid generation:  1.1920928955078125e-06
local_in_edges_tensor generation:  0.000102996826171875
mini_batch_src_global generation:  2.2172927856445312e-05
r_  generation:  0.002199888229370117
local_output_nid generation:  1.430511474609375e-06
local_in_edges_tensor generation:  0.00012993812561035156
mini_batch_src_global generation:  2.2172927856445312e-05
r_  generation:  1.9550323486328125e-05
----------------------check_connections_block total spend ----------------------------- 0.002629518508911133
generate_one_block  0.001983642578125
generate_one_block  0.0011682510375976562
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.00042438507080078125
gen group dst list time:  1.8596649169921875e-05
time for parepare:  3.337860107421875e-06
local_output_nid generation:  1.430511474609375e-06
local_in_edges_tensor generation:  0.013744354248046875
mini_batch_src_global generation:  2.0742416381835938e-05
r_  generation:  2.3126602172851562e-05
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.00010919570922851562
mini_batch_src_global generation:  1.5020370483398438e-05
r_  generation:  1.8596649169921875e-05
----------------------check_connections_block total spend ----------------------------- 0.014039039611816406
generate_one_block  0.0037686824798583984
generate_one_block  0.0011093616485595703
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0004096031188964844
gen group dst list time:  1.8596649169921875e-05
time for parepare:  3.337860107421875e-06
local_output_nid generation:  1.430511474609375e-06
local_in_edges_tensor generation:  0.11016583442687988
mini_batch_src_global generation:  6.842613220214844e-05
r_  generation:  5.435943603515625e-05
local_output_nid generation:  3.0994415283203125e-06
local_in_edges_tensor generation:  0.00022983551025390625
mini_batch_src_global generation:  2.2649765014648438e-05
r_  generation:  2.3365020751953125e-05
----------------------check_connections_block total spend ----------------------------- 0.11073732376098633
generate_one_block  0.001920938491821289
generate_one_block  0.0014352798461914062
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 0.0005083084106445312  GigaBytes
Max Memory Allocated: 0.0005083084106445312  GigaBytes

connection checking time:  0.12477636337280273
block generation total time  0.008234262466430664
average batch blocks generation time:  0.004117131233215332
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.0819091796875 GB
    Memory Allocated: 0.0005121231079101562  GigaBytes
Max Memory Allocated: 0.0005121231079101562  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.0819091796875 GB
    Memory Allocated: 0.0005121231079101562  GigaBytes
Max Memory Allocated: 0.0005121231079101562  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005254745483398438  GigaBytes
Max Memory Allocated: 0.0005311965942382812  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005197525024414062  GigaBytes
Max Memory Allocated: 0.0005311965942382812  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 10
input nodes : tensor([3, 1, 2, 4, 0, 5], device='cuda:0')
output nodes : tensor([3, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4, 2, 5], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005292892456054688  GigaBytes
Max Memory Allocated: 0.0005311965942382812  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005350112915039062  GigaBytes
Max Memory Allocated: 0.0005350112915039062  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005364418029785156  GigaBytes
Max Memory Allocated: 0.0005421638488769531  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005364418029785156  GigaBytes
Max Memory Allocated: 0.0005421638488769531  GigaBytes

torch.Size([6, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005555152893066406  GigaBytes
Max Memory Allocated: 0.0005612373352050781  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005497932434082031  GigaBytes
Max Memory Allocated: 0.0005612373352050781  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 13
input nodes : tensor([3, 1, 2, 4, 0, 5], device='cuda:0')
output nodes : tensor([3, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4, 2, 5], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005583763122558594  GigaBytes
Max Memory Allocated: 0.0005612373352050781  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005640983581542969  GigaBytes
Max Memory Allocated: 0.0005640983581542969  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005655288696289062  GigaBytes
Max Memory Allocated: 0.0005712509155273438  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005702972412109375  GigaBytes
Max Memory Allocated: 0.0005712509155273438  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005698204040527344  GigaBytes
Max Memory Allocated: 0.0005712509155273438  GigaBytes

torch.Size([2, 2])
input nodes number: 6
output nodes number: 2
edges number: 6
input nodes : tensor([3, 1, 2, 4, 0, 5], device='cuda:0')
output nodes : tensor([3, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4, 2, 5], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0005702972412109375  GigaBytes
Max Memory Allocated: 0.0005712509155273438  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010170936584472656  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010170936584472656  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010304450988769531  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010247230529785156  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 10
input nodes : tensor([3, 1, 2, 4, 0, 5], device='cuda:0')
output nodes : tensor([3, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4, 2, 5], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010342597961425781  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010399818420410156  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.001041412353515625  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.001041412353515625  GigaBytes
Max Memory Allocated: 0.0010547637939453125  GigaBytes

torch.Size([6, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.00106048583984375  GigaBytes
Max Memory Allocated: 0.0010662078857421875  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010547637939453125  GigaBytes
Max Memory Allocated: 0.0010662078857421875  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 13
input nodes : tensor([3, 1, 2, 4, 0, 5], device='cuda:0')
output nodes : tensor([3, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4, 2, 5], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010633468627929688  GigaBytes
Max Memory Allocated: 0.0010662078857421875  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010690689086914062  GigaBytes
Max Memory Allocated: 0.0010690689086914062  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010704994201660156  GigaBytes
Max Memory Allocated: 0.0010762214660644531  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010752677917480469  GigaBytes
Max Memory Allocated: 0.0010762214660644531  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010747909545898438  GigaBytes
Max Memory Allocated: 0.0010762214660644531  GigaBytes

torch.Size([2, 2])
input nodes number: 6
output nodes number: 2
edges number: 6
input nodes : tensor([3, 1, 2, 4, 0, 5], device='cuda:0')
output nodes : tensor([3, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4, 2, 5], device='cuda:0', dtype=torch.int32), tensor([0, 0, 0, 1, 1, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 0.0010747909545898438  GigaBytes
Max Memory Allocated: 0.0010762214660644531  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.0002589225769042969 |0.1806623935699463 |0.39704978466033936 |0.00015032291412353516 |0.0041656494140625 |0.004288196563720703 |
----------------------------------------------------------pseudo_mini_loss sum 0.22813162207603455
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  36
Number of first layer input nodes during this epoch:  12
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002033710479736328  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

tensor(indices=tensor([[0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 1, 5],
                       [1, 0, 2, 3, 4, 1, 3, 4, 2, 4, 3, 5, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=13, layout=torch.sparse_coo)
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=6, num_dst_nodes=6, num_edges=10), Block(num_src_nodes=6, num_dst_nodes=6, num_edges=13), Block(num_src_nodes=6, num_dst_nodes=4, num_edges=9)]
global src and dst nids
tensor([1, 3, 0, 2, 5, 4])
tensor([1, 3, 0, 2, 5, 4])
global src and dst nids
tensor([1, 3, 0, 2, 5, 4])
tensor([1, 3, 0, 2, 5, 4])
global src and dst nids
tensor([1, 3, 0, 2, 5, 4])
tensor([1, 3, 0, 2])
The real block id is  2
get_global_graph_edges_ids_block function  spend 0.002824068069458008
src global
[1, 3, 0, 2, 5, 4]
dst local
[0, 1, 2, 3]
global_2_local spend time (sec) 4.1484832763671875e-05
----------------------------  graph partition start---------------------
g = dgl.graph((u,v))  spent  0.0007250308990478516
A = g.adjacency_matrix() spent  0.0003044605255126953
tensor(indices=tensor([[2, 3, 4, 0, 3, 5, 0, 0, 1],
                       [0, 0, 0, 1, 1, 1, 2, 3, 3]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=9, layout=torch.sparse_coo)
tensor(indices=tensor([[0, 0, 0, 1, 1, 1, 2, 3, 3],
                       [2, 3, 4, 0, 3, 5, 0, 0, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=9, layout=torch.sparse_coo)
[[0, 0, 0, 1, 1, 1, 2, 3, 3], [2, 3, 4, 0, 3, 5, 0, 0, 1]]
[[2, 3, 4, 0, 3, 5, 0, 0, 1], [0, 0, 0, 1, 1, 1, 2, 3, 3]]
get remove nodes spent  9.179115295410156e-05
remove nodes length
2
Convert a graph into a bidirected graph: 0.000 seconds
Metis partitioning: 0.000 seconds
Split the graph: 0.000 seconds
Construct subgraphs: 0.000 seconds
self.weighted_graph_bipart() spend  0.061303138732910156
after graph partition
graph partition algorithm spend time 0.17870306968688965
[0, 2]
[0, 2]
partition_len_list
[4, 4]
shared_neighbor_graph_partition selection method range initialization spend 0.17895030975341797
time for parepare:  6.198883056640625e-06
local_output_nid generation:  1.9073486328125e-06
local_in_edges_tensor generation:  0.00012612342834472656
mini_batch_src_global generation:  2.384185791015625e-05
r_  generation:  0.00013518333435058594
local_output_nid generation:  4.291534423828125e-06
local_in_edges_tensor generation:  0.0002944469451904297
mini_batch_src_global generation:  4.9591064453125e-05
r_  generation:  3.0279159545898438e-05
----------------------check_connections_block total spend ----------------------------- 0.0009145736694335938
generate_one_block  0.003723621368408203
generate_one_block  0.0022954940795898438
The real block id is  1
get_global_graph_edges_ids_block function  spend 0.0009062290191650391
gen group dst list time:  3.337860107421875e-05
time for parepare:  7.3909759521484375e-06
local_output_nid generation:  3.814697265625e-06
local_in_edges_tensor generation:  0.0472261905670166
mini_batch_src_global generation:  4.839897155761719e-05
r_  generation:  6.413459777832031e-05
local_output_nid generation:  4.5299530029296875e-06
local_in_edges_tensor generation:  0.00025963783264160156
mini_batch_src_global generation:  3.3855438232421875e-05
r_  generation:  3.62396240234375e-05
----------------------check_connections_block total spend ----------------------------- 0.04790973663330078
generate_one_block  0.0020072460174560547
generate_one_block  0.00157928466796875
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0006330013275146484
gen group dst list time:  2.7418136596679688e-05
time for parepare:  5.245208740234375e-06
local_output_nid generation:  2.384185791015625e-06
local_in_edges_tensor generation:  0.03851938247680664
mini_batch_src_global generation:  2.47955322265625e-05
r_  generation:  2.4557113647460938e-05
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.00011920928955078125
mini_batch_src_global generation:  1.5735626220703125e-05
r_  generation:  1.6689300537109375e-05
----------------------check_connections_block total spend ----------------------------- 0.03884434700012207
generate_one_block  0.0011272430419921875
generate_one_block  0.0013761520385742188
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002033710479736328  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

connection checking time:  0.08675408363342285
block generation total time  0.006089925765991211
average batch blocks generation time:  0.0030449628829956055
block dataloader generation time/epoch 1.1088013648986816
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020232200622558594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020232200622558594  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002036571502685547  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020308494567871094  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 10
input nodes : tensor([0, 2, 1, 3], device='cuda:0')
output nodes : tensor([0, 2], device='cuda:0')
edges number: (tensor([2, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002040386199951172  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020461082458496094  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020475387573242188  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020475387573242188  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020608901977539062  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020570755004882812  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([4, 256])
input nodes number: 6
output nodes number: 4
edges number: 9
input nodes : tensor([0, 2, 1, 3], device='cuda:0')
output nodes : tensor([0, 2], device='cuda:0')
edges number: (tensor([2, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002063751220703125  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.00206756591796875  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020685195922851562  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020732879638671875  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020728111267089844  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([2, 2])
input nodes number: 4
output nodes number: 2
edges number: 3
input nodes : tensor([0, 2, 1, 3], device='cuda:0')
output nodes : tensor([0, 2], device='cuda:0')
edges number: (tensor([2, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 1, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020728111267089844  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020241737365722656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 0
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020241737365722656  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 4])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002037525177001953  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020318031311035156  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 256])
input nodes number: 6
output nodes number: 6
edges number: 10
input nodes : tensor([0, 2, 1, 3], device='cuda:0')
output nodes : tensor([0, 2], device='cuda:0')
edges number: (tensor([2, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 0 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002041339874267578  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020470619201660156  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 0 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002048492431640625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------before model layer 1
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.002048492431640625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([6, 256])
----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020618438720703125  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = layer(block, x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020580291748046875  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([4, 256])
input nodes number: 6
output nodes number: 4
edges number: 9
input nodes : tensor([0, 2, 1, 3], device='cuda:0')
output nodes : tensor([0, 2], device='cuda:0')
edges number: (tensor([2, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 1, 1], device='cuda:0', dtype=torch.int32))
----------------------------------------after model layer 1 x = self.bns[i](x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020647048950195312  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.activation(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020685195922851562  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after model layer 1 x = self.dropout(x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020694732666015625  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020742416381835938  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020737648010253906  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

torch.Size([2, 2])
input nodes number: 4
output nodes number: 2
edges number: 3
input nodes : tensor([0, 2, 1, 3], device='cuda:0')
output nodes : tensor([0, 2], device='cuda:0')
edges number: (tensor([2, 2, 3], device='cuda:0', dtype=torch.int32), tensor([0, 1, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2440185546875 GB
    Memory Allocated: 0.0020737648010253906  GigaBytes
Max Memory Allocated: 0.0027666091918945312  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00018012523651123047 |0.0005018711090087891 |0.012824654579162598 |0.00012683868408203125 |0.0029965639114379883 |0.0013997554779052734 |
----------------------------------------------------------pseudo_mini_loss sum 5.636101722717285
Total (block generation + training)time/epoch 1.146418571472168
Training time/epoch 0.03740429878234863
Training time without block to device /epoch 0.036400556564331055
Training time without total dataloading part /epoch 0.03329586982727051
load block tensor time/epoch 0.00036025047302246094
block to device time/epoch 0.0010037422180175781
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  32
Number of first layer input nodes during this epoch:  12
