main start at this time 1649908720.7855117
-----------------------------------------before load data 
 Nvidia-smi: 0.1717529296875 GB
    Memory Allocated: 0.0  GigaBytes
Max Memory Allocated: 0.0  GigaBytes

karate data
{}
{}
#nodes: 6
#edges: 13
#classes: 2
success----------------------------------------
4
1
1
# Nodes: 6
# Edges: 13
# Train: 4
# Val: 1
# Test: 1
# Classes: 2

in feats:  4
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 9.5367431640625e-07  GigaBytes
Max Memory Allocated: 9.5367431640625e-07  GigaBytes

tensor(indices=tensor([[0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 1, 5],
                       [1, 0, 2, 3, 4, 1, 3, 4, 2, 4, 3, 5, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=13, layout=torch.sparse_coo)
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=6, num_dst_nodes=4, num_edges=7)]
global src and dst nids
tensor([3, 1, 2, 0, 4, 5])
tensor([3, 1, 2, 0])
full batch blocks first block 
(tensor([1, 4, 3, 5, 1, 0, 1]), tensor([0, 0, 1, 1, 2, 2, 3]))
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.002000093460083008
src global
[3, 1, 2, 0, 4, 5]
dst local
[0, 1, 2, 3]
global_2_local spend time (sec) 4.839897155761719e-05
----------------------------  graph partition start---------------------
remove
[4, 5]
  (2, 0)	1
  (3, 0)	1
  (0, 2)	1
  (3, 2)	1
  (0, 3)	1
  (2, 3)	1
   source  target  weight  capacity
0       2       0       1         1
1       3       0       1         1
2       0       2       1         1
3       3       2       1         1
4       0       3       1         1
5       2       3       1         1

2
({0, 2}, {3})
after graph partition
graph partition algorithm spend time 0.05007314682006836
-----------------------------------------------global batched output nodes id----------------------------
[2, 3]
[0, 1]
partition_len_list
[4, 3]
shared_neighbor_graph_partition selection method range initialization spend 0.050362586975097656
time for parepare:  6.67572021484375e-06
local_output_nid generation:  2.1457672119140625e-06
local_in_edges_tensor generation:  0.00018262863159179688
mini_batch_src_global generation:  3.933906555175781e-05
r_  generation:  0.001094818115234375
local_output_nid generation:  1.9073486328125e-06
local_in_edges_tensor generation:  0.00020813941955566406
mini_batch_src_global generation:  3.075599670410156e-05
r_  generation:  2.3126602172851562e-05
----------------------check_connections_block total spend ----------------------------- 0.0018069744110107422
generate_one_block  0.0038423538208007812
generate_one_block  0.0017015933990478516
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.0174560546875 GB
    Memory Allocated: 9.5367431640625e-07  GigaBytes
Max Memory Allocated: 9.5367431640625e-07  GigaBytes

connection checking time:  0
block generation total time  0
average batch blocks generation time:  0.0
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.0819091796875 GB
    Memory Allocated: 2.86102294921875e-06  GigaBytes
Max Memory Allocated: 2.86102294921875e-06  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 5.7220458984375e-06  GigaBytes
Max Memory Allocated: 6.198883056640625e-06  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 5.245208740234375e-06  GigaBytes
Max Memory Allocated: 6.198883056640625e-06  GigaBytes

torch.Size([2, 2])
input nodes number: 4
output nodes number: 2
edges number: 4
input nodes : tensor([3, 2, 1, 4], device='cuda:0')
output nodes : tensor([3, 2], device='cuda:0')
edges number: (tensor([2, 3, 2, 0], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 6.67572021484375e-06  GigaBytes
Max Memory Allocated: 6.67572021484375e-06  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 5.245208740234375e-06  GigaBytes
Max Memory Allocated: 9.059906005859375e-06  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 8.106231689453125e-06  GigaBytes
Max Memory Allocated: 9.059906005859375e-06  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 7.62939453125e-06  GigaBytes
Max Memory Allocated: 9.059906005859375e-06  GigaBytes

torch.Size([2, 2])
input nodes number: 3
output nodes number: 2
edges number: 3
input nodes : tensor([1, 0, 5], device='cuda:0')
output nodes : tensor([1, 0], device='cuda:0')
edges number: (tensor([1, 2, 0], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 8.58306884765625e-06  GigaBytes
Max Memory Allocated: 9.059906005859375e-06  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00024080276489257812 |0.18269717693328857 |0.37803709506988525 |0.00018787384033203125 |0.0014257431030273438 |0.0013976097106933594 |
----------------------------------------------------------pseudo_mini_loss sum 1.0820672512054443
 Run 0| Epoch 0 |
Number of nodes for computation during this epoch:  7
Number of first layer input nodes during this epoch:  7
----------------------------------------before generate_dataloader_block 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 9.059906005859375e-06  GigaBytes
Max Memory Allocated: 1.0967254638671875e-05  GigaBytes

tensor(indices=tensor([[0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 4, 1, 5],
                       [1, 0, 2, 3, 4, 1, 3, 4, 2, 4, 3, 5, 1]]),
       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),
       size=(6, 6), nnz=13, layout=torch.sparse_coo)
*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-
[Block(num_src_nodes=6, num_dst_nodes=4, num_edges=7)]
global src and dst nids
tensor([3, 0, 2, 1, 4, 5])
tensor([3, 0, 2, 1])
full batch blocks first block 
(tensor([4, 3, 3, 3, 0, 1, 5]), tensor([0, 0, 1, 2, 2, 3, 3]))
The real block id is  0
get_global_graph_edges_ids_block function  spend 0.0017821788787841797
src global
[3, 0, 2, 1, 4, 5]
dst local
[0, 1, 2, 3]
global_2_local spend time (sec) 4.673004150390625e-05
----------------------------  graph partition start---------------------
remove
[4, 5]
  (1, 0)	1
  (2, 0)	1
  (0, 1)	1
  (2, 1)	1
  (0, 2)	1
  (1, 2)	1
   source  target  weight  capacity
0       1       0       1         1
1       2       0       1         1
2       0       1       1         1
3       2       1       1         1
4       0       2       1         1
5       1       2       1         1

2
({0, 1}, {2})
after graph partition
graph partition algorithm spend time 0.0939943790435791
-----------------------------------------------global batched output nodes id----------------------------
[0, 3]
[1, 2]
partition_len_list
[4, 5]
shared_neighbor_graph_partition selection method range initialization spend 0.09424543380737305
time for parepare:  6.67572021484375e-06
local_output_nid generation:  1.6689300537109375e-06
local_in_edges_tensor generation:  0.00011920928955078125
mini_batch_src_global generation:  2.384185791015625e-05
r_  generation:  5.125999450683594e-05
local_output_nid generation:  1.430511474609375e-06
local_in_edges_tensor generation:  0.00011754035949707031
mini_batch_src_global generation:  1.52587890625e-05
r_  generation:  1.9311904907226562e-05
----------------------check_connections_block total spend ----------------------------- 0.0005071163177490234
generate_one_block  0.0028214454650878906
generate_one_block  0.001306295394897461
-----------------------------------------after block dataloader generation 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 9.059906005859375e-06  GigaBytes
Max Memory Allocated: 1.0967254638671875e-05  GigaBytes

connection checking time:  0
block generation total time  0
average batch blocks generation time:  0.0
block dataloader generation time/epoch 0.35907506942749023
----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 6.198883056640625e-06  GigaBytes
Max Memory Allocated: 1.0967254638671875e-05  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 9.059906005859375e-06  GigaBytes
Max Memory Allocated: 1.0967254638671875e-05  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 8.58306884765625e-06  GigaBytes
Max Memory Allocated: 1.0967254638671875e-05  GigaBytes

torch.Size([2, 2])
input nodes number: 4
output nodes number: 2
edges number: 3
input nodes : tensor([3, 0, 4, 1], device='cuda:0')
output nodes : tensor([3, 0], device='cuda:0')
edges number: (tensor([2, 3, 3], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 9.5367431640625e-06  GigaBytes
Max Memory Allocated: 1.0967254638671875e-05  GigaBytes

----------------------------------------before batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 7.152557373046875e-06  GigaBytes
Max Memory Allocated: 1.1920928955078125e-05  GigaBytes

----------------------------------------after rst
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 1.0013580322265625e-05  GigaBytes
Max Memory Allocated: 1.1920928955078125e-05  GigaBytes

----------------------------------------end of model layers  after x = self.layers[-1](blocks[-1], x)
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 9.5367431640625e-06  GigaBytes
Max Memory Allocated: 1.1920928955078125e-05  GigaBytes

torch.Size([2, 2])
input nodes number: 5
output nodes number: 2
edges number: 4
input nodes : tensor([2, 1, 3, 0, 5], device='cuda:0')
output nodes : tensor([2, 1], device='cuda:0')
edges number: (tensor([1, 2, 3, 4], device='cuda:0', dtype=torch.int32), tensor([0, 0, 1, 1], device='cuda:0', dtype=torch.int32))
-----------------------------------------batch_pred = model(blocks, batch_inputs) 
 Nvidia-smi: 1.2420654296875 GB
    Memory Allocated: 1.049041748046875e-05  GigaBytes
Max Memory Allocated: 1.1920928955078125e-05  GigaBytes

times | data loading | block to device | model prediction | loss calculation | loss backward |  optimizer step |
      |0.00019550323486328125 |0.00028204917907714844 |0.00488126277923584 |0.00013458728790283203 |0.0006990432739257812 |0.0007264614105224609 |
----------------------------------------------------------pseudo_mini_loss sum 0.9844117760658264
Total (block generation + training)time/epoch 0.37573790550231934
Training time/epoch 0.016390323638916016
Training time without block to device /epoch 0.01582622528076172
Training time without total dataloading part /epoch 0.012156248092651367
load block tensor time/epoch 0.0003910064697265625
block to device time/epoch 0.0005640983581542969
input features size transfer per epoch 2.682209014892578e-07
blocks size to device per epoch 1.7881393432617188e-07
 Run 0| Epoch 1 |
Number of nodes for computation during this epoch:  9
Number of first layer input nodes during this epoch:  9
