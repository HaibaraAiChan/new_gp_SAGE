+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| arxiv sage fan-out 25,35,40 hidden 256          |   full batch  |     pseudo  |     pseudo  |     pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |      25,35,40 |   2 batches |   4 batches |   8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |               |    25,35,40 |    25,35,40 |    25,35,40 |         25,35,40 |         25,35,40 |         25,35,40 |
+=================================================+===============+=============+=============+=============+==================+==================+==================+
| final layer output nodes/pure train time        |           nan |         nan |         nan |         nan |   7384.56        |   4026.12        |   2052.67        |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         |           nan |         nan |         nan |         nan | 211453           | 175066           | 131023           |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average train time per epoch                    |           nan |         nan |         nan |         nan |     12.315       |     22.5877      |     44.3038      |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average number of nodes for computation         |           nan |         nan |         nan |         nan |      2.60404e+06 |      3.95434e+06 |      5.80481e+06 |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average first layer num of input nodes          |           nan |         nan |         nan |         nan |      1.52333e+06 |      2.48789e+06 |      3.92282e+06 |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| redundancy rate I (First Layer Input)           |             1 |         nan |         nan |         nan |      9.08303     |     14.8343      |     23.3902      |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| redundancy rate O (First Layer Output)          |             1 |         nan |         nan |         nan |      4.72504     |      6.77625     |      9.32918     |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average load block input feature time per epoch |           nan |         nan |         nan |         nan |      0.306283    |      0.466165    |      0.963874    |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average block to device time per epoch          |           nan |         nan |         nan |         nan |      0.140519    |      0.200951    |      0.32065     |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average dataloading time per epoch              |           nan |         nan |         nan |         nan |      0.446802    |      0.667115    |      1.28452     |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| average first layer num of output nodes         |           nan |         nan |         nan |         nan | 787348           |      1.12915e+06 |      1.55455e+06 |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+
| CUDA max memory consumption                     |           nan |         nan |         nan |         nan |     18.6182      |     14.8788      |     11.7623      |
+-------------------------------------------------+---------------+-------------+-------------+-------------+------------------+------------------+------------------+