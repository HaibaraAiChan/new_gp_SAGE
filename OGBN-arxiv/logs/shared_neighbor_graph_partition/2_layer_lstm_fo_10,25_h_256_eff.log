computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| arxiv sage fan-out 10,25 hidden 256             |     full batch  |         pseudo  |        pseudo  |        pseudo  |        pseudo  |         pseudo  |          pseudo  |
|                                                 |           10,25 |       2 batches |      4 batches |      8 batches |     16 batches |      32 batches |       64 batches |
|                                                 |                 |           10,25 |          10,25 |          10,25 |          10,25 |           10,25 |            10,25 |
+=================================================+=================+=================+================+================+================+=================+==================+
| final layer output nodes/pure train time        | 186399          | 144757          | 101742         |  57312.2       |  29210         |  14751.8        |   7440.31        |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| all layers input nodes//pure train time         | 653518          | 614491          | 553168         | 416916         | 280124         | 182408          | 112872           |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average train time per epoch                    |      0.487883   |      0.628232   |      0.893838  |      1.58676   |      3.11336   |      6.16475    |     12.2227      |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average number of nodes for computation         | 318840          | 386042          | 494443         | 661548         | 872126         |      1.1245e+06 |      1.37961e+06 |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average first layer num of input nodes          | 164246          | 215768          | 296605         | 425877         | 590758         | 807047          |      1.03042e+06 |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average first layer num of output nodes         | 154584          | 171756          | 196575         | 236190         | 276569         | 318938          | 351224           |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| CUDA max memory consumption                     |     20.0331     |     12.2264     |      8.45138   |      4.9652    |      3.19396   |      1.9229     |      1.21389     |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| redundancy rate I (First Layer Input)           |      1          |      1.31369    |      1.80586   |      2.59292   |      3.59679   |      4.91365    |      6.27364     |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| redundancy rate O (First Layer Output)          |      1          |      1.11109    |      1.27164   |      1.52791   |      1.78912   |      2.0632     |      2.27206     |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| pure graph partition spend time                 |      0          |     17.3069     |     16.1597    |     15.3017    |     14.6238    |     14.5186     |     14.8886      |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average load block input feature time per epoch |      0.032885   |      0.111748   |      0.170412  |      0.17361   |      0.186489  |      0.254626   |      0.377406    |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average block to device time per epoch          |      0.00685859 |      0.00980461 |      0.0119221 |      0.0199145 |      0.0298213 |      0.0599221  |      0.0871454   |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
| average dataloading time per epoch              |      0.0397435  |      0.121553   |      0.182334  |      0.193524  |      0.21631   |      0.314548   |      0.464552    |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+-----------------+------------------+
