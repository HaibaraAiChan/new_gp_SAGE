computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| arxiv sage fan-out 100 hidden 256               |     full batch  |         pseudo  |        pseudo  |        pseudo  |        pseudo  |        pseudo  |        pseudo  |
|                                                 |             100 |       2 batches |      4 batches |      8 batches |     16 batches |     32 batches |     64 batches |
|                                                 |                 |             100 |            100 |            100 |            100 |            100 |            100 |
+=================================================+=================+=================+================+================+================+================+================+
| final layer output nodes/pure train time        |  66858          |  33676.1        |  18516.3       |   9424.08      |   5461.41      |   3252.89      |   2035.32      |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| all layers input nodes//pure train time         | 117812          |  65268.7        |  43742.2       |  27770.4       |  19445.3       |  14305.4       |  10257.8       |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average train time per epoch                    |      1.36021    |      2.70046    |      4.91139   |      9.64986   |     16.6516    |     27.957     |     44.6814    |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average number of nodes for computation         | 160249          | 176256          | 214835         | 267980         | 323794         | 399936         | 458332         |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average first layer num of input nodes          | 160235          | 177562          | 215465         | 269671         | 323699         | 402473         | 457436         |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average first layer num of output nodes         |  90941          |  90941          |  90941         |  90941         |  90941         |  90941         |  90941         |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| CUDA max memory consumption                     |      8.14       |      5.18528    |      3.51928   |      1.9122    |      1.19214   |      0.540314  |      0.298836  |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| redundancy rate I (First Layer Input)           |      1          |      1.10814    |      1.34469   |      1.68298   |      2.02016   |      2.51178   |      2.8548    |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| redundancy rate O (First Layer Output)          |      1          |      1          |      1         |      1         |      1         |      1         |      1         |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| pure graph partition spend time                 |      0          |     25.86       |     23.7137    |     21.7054    |     21.1127    |     20.6873    |     21.5525    |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average load block input feature time per epoch |      0.0463986  |      0.0685807  |      0.069241  |      0.110426  |      0.131055  |      0.191987  |      0.300733  |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average block to device time per epoch          |      0.00438011 |      0.00656641 |      0.0086205 |      0.0166023 |      0.0149908 |      0.0206411 |      0.0290056 |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
| average dataloading time per epoch              |      0.0507787  |      0.0751472  |      0.0778615 |      0.127028  |      0.146046  |      0.212628  |      0.329738  |
+-------------------------------------------------+-----------------+-----------------+----------------+----------------+----------------+----------------+----------------+
