computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| arxiv sage fan-out 10,25 hidden 256             |     full batch  |        pseudo  |        pseudo  |        pseudo  |        pseudo  |          pseudo  |          pseudo  |
|                                                 |           10,25 |      2 batches |      4 batches |      8 batches |     16 batches |       32 batches |       64 batches |
|                                                 |                 |          10,25 |          10,25 |          10,25 |          10,25 |            10,25 |            10,25 |
+=================================================+=================+================+================+================+================+==================+==================+
| final layer output nodes/pure train time        | 186114          | 144896         | 103544         |  57575.5       |  29399         |  15219.1         |   6714.57        |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| all layers input nodes//pure train time         | 652517          | 614478         | 562515         | 416996         | 276991         | 186776           | 102193           |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average train time per epoch                    |      0.488632   |      0.627629  |      0.878284  |      1.57951   |      3.09334   |      5.97544     |     13.5438      |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average number of nodes for computation         | 318840          | 385664         | 494048         | 658648         | 856826         |      1.11607e+06 |      1.38408e+06 |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average first layer num of input nodes          | 164246          | 215635         | 297924         | 424897         | 583319         | 802742           |      1.03102e+06 |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average first layer num of output nodes         | 154584          | 171637         | 196924         | 235300         | 273809         | 317622           | 351888           |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| CUDA max memory consumption                     |     20.0331     |     12.2264    |      8.48324   |      4.97372   |      3.29023   |      1.9229      |      1.16315     |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| redundancy rate I (First Layer Input)           |      1          |      1.31288   |      1.81389   |      2.58695   |      3.55149   |      4.88744     |      6.27727     |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| redundancy rate O (First Layer Output)          |      1          |      1.11031   |      1.2739    |      1.52215   |      1.77126   |      2.05469     |      2.27635     |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| pure graph partition spend time                 |      0          |     17.8109    |     16.2206    |     15.3217    |     15.1687    |     14.5881      |     14.8507      |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average load block input feature time per epoch |      0.0337591  |      0.108355  |      0.179789  |      0.169467  |      0.159684  |      0.264585    |      0.341623    |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average block to device time per epoch          |      0.00687039 |      0.0082866 |      0.0144104 |      0.0184639 |      0.0402113 |      0.0479126   |      0.0973272   |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
| average dataloading time per epoch              |      0.0406295  |      0.116642  |      0.1942    |      0.187931  |      0.199895  |      0.312498    |      0.43895     |
+-------------------------------------------------+-----------------+----------------+----------------+----------------+----------------+------------------+------------------+
