computation info data collection start ...... 
full batch vs pseudo minibatch  compute efficiency (output nodes/time, input nodes /time):
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| arxiv sage fan-out 10,25 hidden 256             |     full batch  |        pseudo  |         pseudo  |          pseudo  |          pseudo  |          pseudo  |          pseudo  |
|                                                 |           10,25 |      2 batches |       4 batches |        8 batches |       16 batches |       32 batches |       64 batches |
|                                                 |                 |          10,25 |           10,25 |            10,25 |            10,25 |            10,25 |            10,25 |
+=================================================+=================+================+=================+==================+==================+==================+==================+
| final layer output nodes/pure train time        | 184682          | 133829         |  93849.6        |  54627.1         |  28401.2         |  14778.8         |   7298.4         |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| all layers input nodes//pure train time         | 647499          | 842353         | 985418          | 893088           | 676172           | 477693           | 298647           |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average train time per epoch                    |      0.492419   |      0.679533  |      0.969008   |      1.66476     |      3.20202     |      6.15347     |     12.4604      |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average number of nodes for computation         | 318840          | 572406         | 954878          |      1.48678e+06 |      2.16511e+06 |      2.93947e+06 |      3.72125e+06 |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average first layer num of input nodes          | 164246          | 313068         | 572425          | 983725           |      1.56076e+06 |      2.25909e+06 |      2.98573e+06 |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average first layer num of output nodes         | 154584          | 259432         | 382575          | 502928           | 604350           | 680527           | 734050           |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| CUDA max memory consumption                     |     20.0331     |     13.0433    |      8.53611    |      5.35295     |      3.18318     |      1.8163      |      1.00195     |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| redundancy rate I (First Layer Input)           |      1          |      1.90609   |      3.48517    |      5.98934     |      9.5026      |     13.7543      |     18.1784      |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| redundancy rate O (First Layer Output)          |      1          |      1.67826   |      2.47487    |      3.25343     |      3.90953     |      4.40231     |      4.74855     |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| pure graph partition spend time                 |      0          |      0.0059553 |      0.00653267 |      0.00727185  |      0.00560792  |      0.00660276  |      0.00625984  |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average load block input feature time per epoch |      0.0337477  |      0.149761  |      0.274101   |      0.352894    |      0.413036    |      0.583527    |      0.673428    |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average block to device time per epoch          |      0.00703418 |      0.0123845 |      0.0209939  |      0.0371739   |      0.0488393   |      0.0649579   |      0.121944    |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
| average dataloading time per epoch              |      0.0407819  |      0.162145  |      0.295095   |      0.390068    |      0.461876    |      0.648485    |      0.795372    |
+-------------------------------------------------+-----------------+----------------+-----------------+------------------+------------------+------------------+------------------+
