+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| arxiv sage fan-out 10 hidden 256                |      full batch  |          pseudo  |          pseudo  |          pseudo  |         pseudo  |       pseudo  |        pseudo  |
|                                                 |               10 |        2 batches |        4 batches |        8 batches |      16 batches |    32 batches |     64 batches |
|                                                 |                  |               10 |               10 |               10 |              10 |            10 |             10 |
+=================================================+==================+==================+==================+==================+=================+===============+================+
| final layer output nodes/pure train time        |      1.33026e+06 | 799353           | 449247           | 242793           | 115341          |  57797.9      |  28504.2       |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| all layers input nodes//pure train time         |      2.12155e+06 |      2.02852e+06 |      1.59291e+06 |      1.08144e+06 | 596204          | 328402        | 171872         |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average train time per epoch                    |      0.0683635   |      0.113768    |      0.20243     |      0.374561    |      0.788457   |      1.57343  |      3.19044   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average number of nodes for computation         | 145037           | 230781           | 322452           | 405064           | 470081          | 516718        | 548348         |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average first layer num of input nodes          | 145041           | 230819           | 322497           | 405065           | 470225          | 516842        | 548432         |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average first layer num of output nodes         |  90941           |  90941           |  90941           |  90941           |  90941          |  90941        |  90941         |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| CUDA max memory consumption                     |      4.3287      |      2.21074     |      1.11425     |      0.561749    |      0.287946   |      0.146563 |      0.0752172 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| redundancy rate I (First Layer Input)           |      1           |      1.59141     |      2.22349     |      2.79276     |      3.24202    |      3.56342  |      3.78122   |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| redundancy rate O (First Layer Output)          |      1           |      1           |      1           |      1           |      1          |      1        |      1         |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average load block input feature time per epoch |      0.0250045   |      0.0593181   |      0.0717041   |      0.0810974   |      0.133381   |      0.214011 |      0.263706  |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average block to device time per epoch          |      0.00227821  |      0.00321662  |      0.00425744  |      0.00440037  |      0.00786138 |      0.012786 |      0.0241259 |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+
| average dataloading time per epoch              |      0.0272827   |      0.0625347   |      0.0759616   |      0.0854977   |      0.141243   |      0.226797 |      0.287832  |
+-------------------------------------------------+------------------+------------------+------------------+------------------+-----------------+---------------+----------------+